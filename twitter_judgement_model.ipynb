{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 極性判定とDoc２Vecを使ったTwitterネガポジ予測\n",
    "＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝\n",
    "### 【このnotebookについて】\n",
    "2019年7〜10月までフルタイムで通っていたスクールの卒業課題テーマを、機械学習の勉強のために発展させたものです<br>\n",
    "卒業発表スライド　https://www.slideshare.net/secret/y0m7g1nZdxpVYP<br>\n",
    "＊当初は炎上予測がテーマだったので、このnotebookの内容とはややズレます<br>\n",
    "＊表紙スライドの字が見えない場合は２枚目から戻ると見えます<br>\n",
    "\n",
    "＊ちなみに…<br>\n",
    "スクールで取り組んだ課題のリポジトリ \n",
    "https://github.com/kaorisugi/diveintocode-ml<br>\n",
    "論文読解課題のスライドシェア \n",
    "https://www.slideshare.net/secret/qGmdiwl4uGS20O<br>\n",
    "\n",
    "### 【ゴール】\n",
    "これからツイートする予定の文章に対し、過去の類似ツイートを探し、反応のネガポジスコア付きで上位１０位まで提示する。<br>\n",
    "### 【モデルの仕組み】\n",
    "１）ツイートデータセットを取得<br>\n",
    "　・TwitterAPIを使ってツイートを取得<br>\n",
    "　・各ツイートに対する反応ツイート（リプライ、引用RT）を取得<br>\n",
    "　・反応ツイートの極性表現数をカウントしてネガポジスコアとpositive/negative/fire!!!判定を得る<br>\n",
    " 　（positive/negativeの判定基準：極性表現数が多い方、fire!!!(炎上）の判定基準：極性表現の７０％以上がnegative）\n",
    "２）データセットの前処理<br>\n",
    "　・正規表現、ストップワード除去など<br>\n",
    "３）予測モデルを生成<br>\n",
    "　・データセットをDoc２vecで学習<br>\n",
    "４）ツイート予定文章のネガポジ予測を返す<br>\n",
    "　・データセットから、ツイート予定文書と似ている文書を探す<br>\n",
    " ・ネガポジスコア付きで、類似ツイート上位１０個を返す\n",
    "### 【結果】\n",
    "類似度確認用にデータセット内にあるものと同じ文を入力したところ、類似度1位で返ってきた。また、２位、３位にもマスクに関する似た話題のツイートが提示されたので類似ツイートの抽出は成功。ネガポジスコアもデータズレなどなく正確に表示され、目的は達成できた。<br>\n",
    "ツイッターAPI制限により、まだサンプルが少ない（完成時２００件程度）が、データを蓄積できる仕様にしているので、ツイート文のバリエーションを増やしていけば、様々な入力文に対応できるようになると思う。<br>\n",
    "ネガポジ判定については、ネガティブなテーマへの言及に共感したコメントでネガ判定が出ているケースも多く、必ずしもツイート主へのネガ感情ではないことに注意が必要。<br>\n",
    "\n",
    "### 【その他試みたこと】\n",
    "１）文章ベクトルを特徴量としたネガポジ予測モデル<br>\n",
    "　・文章ベクトルとフォロワー数を特徴量X、ネガポジスコアを目的変数yとしたデータを学習<br>\n",
    "　・文章ベクトルはDoc２vecとTf-idfの２種を作成<br>\n",
    "　・ツイート予定文書を入力してネガポジスコアを予測する<br>\n",
    "　・試した予測モデル<br>\n",
    "　・MultiOutputRegressor、SVRのrbf と　SVRの線形、lightgbm、ランダムフォレスト<br>\n",
    "　  　→精度が低すぎて断念<br>\n",
    "２）ツイッターAPI制限への挑戦（データセットの拡大）<br>\n",
    "　・古いツイートを大量取得できるパッケージを発見（通常は１週間程度しか遡れない）<br>\n",
    "　　　→取得データから反応ツイートの取得を試みたができなかった<br>\n",
    "   \n",
    "### 【利用するには】\n",
    "・config.py ファイルにツイッターAPIトークンを記入<br>\n",
    "・インストールが必要なツールは、notebook内にマジックコマンドにて記載してあります<br>\n",
    "・jupyternotebook上でのMeCabの利用で詰まる場合は、下記のDockerイメージを使うとうまくいくかと思います。<br>\n",
    "Docker Japanese NLP<br>\n",
    "https://github.com/hoto17296/docker-japanese-nlp<br>\n",
    "＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## １）ツイートデータセットを取得\n",
    "・TwitterAPIでツイートを取得<br>\n",
    "・各ツイートに対するリプライ、引用RTを取得<br>\n",
    "・極性表現数をカウントしてネガポジスコアを得る<br>\n",
    "\n",
    "#### 参考サイト\n",
    "【Python】tweepyでTwitterのツイートを検索して取得<br>\n",
    "https://vatchlog.com/tweepy-search/<br>\n",
    "【Python】tweepyで期間指定してツイートを検索する<br>\n",
    "https://vatchlog.com/tweepy-search-time/<br>\n",
    "バズったツイートへのリアクションを感情分析してみる<br>【Google Natural Language API / Python】<br>\n",
    "https://qiita.com/matsuri0828/items/029b4d0d510dcfb5c5dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /opt/conda/lib/python3.6/site-packages (19.3.1)\n",
      "Requirement already satisfied: tweepy in /opt/conda/lib/python3.6/site-packages (3.8.0)\n",
      "Requirement already satisfied: requests>=2.11.1 in /opt/conda/lib/python3.6/site-packages (from tweepy) (2.18.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.6/site-packages (from tweepy) (1.3.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from tweepy) (1.11.0)\n",
      "Requirement already satisfied: PySocks>=1.5.7 in /opt/conda/lib/python3.6/site-packages (from tweepy) (1.6.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.11.1->tweepy) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.11.1->tweepy) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.11.1->tweepy) (2018.1.18)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n",
      "Requirement already satisfied: oseti in /opt/conda/lib/python3.6/site-packages (0.2)\n",
      "Requirement already satisfied: mecab-python3 in /opt/conda/lib/python3.6/site-packages (from oseti) (0.7)\n",
      "Requirement already satisfied: neologdn in /opt/conda/lib/python3.6/site-packages (from oseti) (0.2.1)\n",
      "Requirement already satisfied: sengiri in /opt/conda/lib/python3.6/site-packages (from oseti) (0.2.1)\n",
      "Requirement already satisfied: emoji in /opt/conda/lib/python3.6/site-packages (from sengiri->oseti) (0.5.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (2.18.4)\n",
      "Requirement already satisfied: requests_oauthlib in /opt/conda/lib/python3.6/site-packages (1.3.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests) (2018.1.18)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from requests_oauthlib) (3.1.0)\n",
      "Requirement already satisfied: sengiri in /opt/conda/lib/python3.6/site-packages (0.2.1)\n",
      "Requirement already satisfied: emoji in /opt/conda/lib/python3.6/site-packages (from sengiri) (0.5.4)\n"
     ]
    }
   ],
   "source": [
    "#必要なツールをインストール（初回のみ実行）\n",
    "! pip install --upgrade pip\n",
    "! pip install tweepy\n",
    "! pip install oseti\n",
    "! pip install requests requests_oauthlib\n",
    "! pip install sengiri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import re\n",
    "import emoji\n",
    "import oseti\n",
    "from datetime import datetime, date, timedelta\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import config\n",
    "\n",
    "class Get_Twitter():\n",
    "\n",
    "    def __init__(self, day, reload, print_rep = False, exclud_words = \"配信スタート ＃キャンペーン　リツイートキャンペーン\", RT_count = 5000):\n",
    "        self.oseti_analyzer = oseti.Analyzer()  #極性判定\n",
    "        self.CK = config.CONSUMER_KEY\n",
    "        self.CS = config.CONSUMER_SECRET\n",
    "        self.AT = config.ACCESS_TOKEN\n",
    "        self.AS = config.ACCESS_TOKEN_SECRET\n",
    "        self.ew = exclud_words\n",
    "        self.print_rep = print_rep\n",
    "        self.rt = str(RT_count)\n",
    "        self.columns = [\n",
    "            \"Id\", \"Date\", \"Name\", \"Full_text\",\n",
    "            \"Judge\", \"Posi_score\", \"Nega_score\", \"Followers\", \"link\"\n",
    "        ]\n",
    "        self.posi_pd = pd.DataFrame([], columns = self.columns)\n",
    "        self.nega_pd = pd.DataFrame([], columns = self.columns)\n",
    "        self.fire_pd = pd.DataFrame([], columns = self.columns)\n",
    "        self.wait = 0\n",
    "        self.reload = reload\n",
    "        day = datetime.strptime(day, '%Y-%m-%d')\n",
    "        self.day = day.strftime('%Y-%m-%d')\n",
    "\n",
    "    def main(self):\n",
    "        self._Make_Dir() # データ格納ファイルの準備\n",
    "\n",
    "        #ツイートを取得、センチメント判定\n",
    "        try:\n",
    "            status = self.Get_Buzz() #バズったツイート取得\n",
    "            for i in status:            \n",
    "                if self.wait == 10:\n",
    "                    print(\"10回待機したため終了\")\n",
    "                    break\n",
    "                self.Status(i)\n",
    "                if self.Exclude_Word(self.buzz_full_text) == True:# 除外ワードを含むツイートは除外\n",
    "                    continue\n",
    "                if self.Text_Count() == True: #30W以下のツイートは除外\n",
    "                    continue\n",
    "                self.Get_Rep() #リプライを取得\n",
    "                self.Get_RT() #RTコメントを取得\n",
    "                if self.Min_Rep() == False: # コメントが少ないツイートは除外\n",
    "                    continue\n",
    "                self.Get_Senti() #コメントをセンチメント判定\n",
    "                self._Get_Analysis() #ツイートをセンチメント判定\n",
    "        #エラー時はスキップして次のツイート取得\n",
    "        except (ValueError,  KeyError, TypeError, tweepy.TweepError) as e:\n",
    "            pass\n",
    "        #リクエスト回数が上限に達した場合はリセット時間まで待機して継続\n",
    "        except tweepy.RateLimitError as e:\n",
    "            if self.reload:\n",
    "                self.wait += 1\n",
    "                print(\"==========\")\n",
    "                print('get_buzzのリクエスト回数が上限に達しました。リセット時間まで待機')\n",
    "                print('Wait 15min...')\n",
    "                print()\n",
    "                for _ in tqdm(range(15 * 60)):\n",
    "                    time.sleep(1)\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        #生成したデータをprint\n",
    "        print()\n",
    "        print(\"↓↓↓positiveサンプル↓↓↓\")\n",
    "        display(self.posi_pd.head())\n",
    "        print()            \n",
    "        print(\"↓↓↓negativeサンプル↓↓↓\")\n",
    "        display(self.nega_pd.head())\n",
    "        print()\n",
    "        print(\"↓↓↓fire_tweetサンプル↓↓↓\")\n",
    "        display(self.fire_pd.head())\n",
    "        print()\n",
    "        print()\n",
    "        \n",
    "        #生成したPandasDataFrameをcsvで書き出す\n",
    "        total_pd = pd.concat([self.posi_pd, self.nega_pd, self.fire_pd], ignore_index=True)\n",
    "        buzz_old = pd.read_csv('./output/buzz_tweet.csv')\n",
    "        buzz_new = pd.concat([buzz_old, total_pd])#既存データと連結\n",
    "        buzz_new.drop_duplicates(subset=\"Id\",inplace=True)#重複ID行を削除            \n",
    "        buzz_new.to_csv('./output/buzz_tweet.csv', index = False, header = True)\n",
    "        print(\"csvへの書き出しが完了しました。新規データ数{}、全データ数：{}\".format(len(buzz_new) - len(buzz_old), len(buzz_new)))\n",
    "        print(\"サンプルが0件の場合は、15分後に再度実行すると取得できる場合があります。\") \n",
    "        print(\"fire_tweetは出現率が非常に低いです。\")\n",
    "\n",
    "    #Api認証\n",
    "    def _Auth(self):\n",
    "        auth = tweepy.OAuthHandler(self.CK, self.CS)\n",
    "        auth.set_access_token(self.AT, self.AS)\n",
    "        api = tweepy.API(auth)\n",
    "        return api\n",
    "\n",
    "    #出力用ディレクトリとcsvファイルを作成（存在しない場合のみ）\n",
    "    def _Make_Dir(self):\n",
    "        new_dir_path = 'output'\n",
    "        try:\n",
    "            os.makedirs(new_dir_path)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        if (os.path.isfile('./output/buzz_tweet.csv')) == False:\n",
    "            self.posi_pd.to_csv('./output/buzz_tweet.csv', index = False)  \n",
    "\n",
    "    #絵文字削除\n",
    "    def _remove_emoji(self, text):\n",
    "        return ''.join(c for c in text if c not in emoji.UNICODE_EMOJI)\n",
    "\n",
    "    #テキストを正規表現処理、絵文字削除\n",
    "    def _format_text(self, text):\n",
    "        text=re.sub(r'https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-…]+', \"\", text)\n",
    "        text=re.sub('\\n', \"\", text)\n",
    "        text=re.sub(r'@?[!-~]+', \"\", text)\n",
    "        text=self._remove_emoji(text)\n",
    "        return text\n",
    "    \n",
    "    #　日付表記を整える、日本時間に修正\n",
    "    def _date_format(self, date):\n",
    "        date = datetime.strptime(str(date), '%a %b %d %H:%M:%S %z %Y')\n",
    "        date = date + timedelta(hours=9)\n",
    "        return datetime.strftime(date, '%Y-%m-%d %H:%M')\n",
    "\n",
    "    def Status(self, status): \n",
    "        self.buzz_id = status._json['id']\n",
    "        self.buzz_id_str = status._json['id_str']\n",
    "        self.buzz_name = status._json['user']['screen_name']\n",
    "        self.buzz_full_text = status._json['full_text']\n",
    "        self.date = status._json['created_at']\n",
    "        self.date = self._date_format(self.date)\n",
    "        self.favo = status._json['favorite_count']\n",
    "        self.rt_count = status._json['retweet_count']\n",
    "        api = self._Auth()\n",
    "        self.followers = status._json['user']['followers_count']\n",
    "        #self.followers = len(api.followers(status._json['user']['screen_name']))\n",
    "    \n",
    "    #除外ワード\n",
    "    def Exclude_Word(self, text):                        \n",
    "        if self.ew in str(text):\n",
    "            print(\"==========\")\n",
    "            print(\"除外ワード\")\n",
    "            print()\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    #ツイート内にリンクがあれば分割\n",
    "    def Text_Count(self):\n",
    "        if re.search(\"(https://t.co/\\w+)\", self.buzz_full_text) == None:\n",
    "            self.link = None\n",
    "        else:                   \n",
    "            self.buzz_full_text = re.split(\"(https://t.co/\\w+)\", self.buzz_full_text)\n",
    "            self.link = self.buzz_full_text[1]\n",
    "            self.buzz_full_text = self.buzz_full_text[0]\n",
    "        if len(self.buzz_full_text) < 30:\n",
    "            return True\n",
    "\n",
    "    #リプライ＋引用RTコメントが100未満のツイートは除外\n",
    "    def Min_Rep(self):\n",
    "        reply_texts_rows = []\n",
    "        if self.rep_cnt + self.RTcomme_cnt > 100:\n",
    "            reply_texts_rows.append(self.rep_row)\n",
    "            reply_texts_rows.append(self.rt_row)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    #sentiment_listを一次元にし、ツイートごとの極性表現の総和の辞書にする\n",
    "    def Get_Senti(self):\n",
    "        self.sentiment_list = sum(self.sentiment_list, [])#１次元にする\n",
    "        self.sentiment = dict((key, sum(d[key] for d in self.sentiment_list)) for key in self.sentiment_list[0])\n",
    "\n",
    "    #バズったツイートを取得(デフォルト：5000RT以上)\n",
    "    def Get_Buzz(self):\n",
    "        api = self._Auth()\n",
    "        try:       \n",
    "            status = api.search(q = 'filter:safe min_retweets:' + self.rt + ' exclude:retweets until:' + self.day,\n",
    "                lang ='ja', count =100, tweet_mode = 'extended', result_type = 'recent')\n",
    "            return status\n",
    "        #エラー時はスキップして次のツイート取得\n",
    "        except (ValueError,  KeyError) as e:\n",
    "            pass\n",
    "        #リクエスト回数が上限に達した場合はリセット時間まで待機して継続\n",
    "        except (tweepy.RateLimitError, tweepy.TweepError) as e:\n",
    "            if self.reload:\n",
    "                self.wait += 1\n",
    "                print(\"==========\")\n",
    "                print('get_buzzのリクエスト回数が上限に達しました。リセット時間まで待機')\n",
    "                print('Wait 15min...')\n",
    "                print()\n",
    "                for _ in tqdm(range(15 * 60)):\n",
    "                    time.sleep(1)\n",
    "            else:\n",
    "                pass\n",
    "        #return status\n",
    "    \n",
    "    #リプライを取得\n",
    "    def Get_Rep(self):\n",
    "        api = self._Auth()     \n",
    "        query_reply = '@' + self.buzz_name + ' exclude:retweets'\n",
    "        self.rep_row = []\n",
    "        self.sentiment_list = []\n",
    "        self.rep_cnt =0\n",
    "        wait_cnt = 0\n",
    "        try:\n",
    "            for status_reply in api.search(q=query_reply, lang='ja', count=100):\n",
    "                if status_reply._json['in_reply_to_status_id_str'] == self.buzz_id_str:\n",
    "                    row = self._format_text(status_reply._json['text'])\n",
    "                    #極性判定\n",
    "                    sentiment_score = self.oseti_analyzer.count_polarity(str(row))#strにする\n",
    "                    self.sentiment_list.append(sentiment_score)\n",
    "                    self.rep_row.append(row)\n",
    "                    self.rep_cnt += 1\n",
    "                else:\n",
    "                    pass\n",
    "        #エラーはスキップして次のツイート取得\n",
    "        except (ValueError,  KeyError, tweepy.TweepError) as e:\n",
    "            pass\n",
    "        #リクエスト回数が上限に達した場合はリセット時間まで待機して継続\n",
    "        except tweepy.RateLimitError as e:\n",
    "            self.wait += 1\n",
    "            if self.reload:\n",
    "                print(\"==========\")\n",
    "                print('get_repのリクエスト回数が上限に達しました。リセット時間まで待機')\n",
    "                print('Wait 15min...')\n",
    "                print()\n",
    "                for _ in tqdm(range(15 * 60)):\n",
    "                    time.sleep(1)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    # 引用RTを取得\n",
    "    def Get_RT(self):\n",
    "        api = self._Auth()\n",
    "        query_quote = self.buzz_id_str + ' exclude:retweets'\n",
    "        self.RTcomme_cnt = 0\n",
    "        self.rt_row = []\n",
    "        try:\n",
    "            for status_quote in api.search(q=query_quote, lang='ja', count=100):\n",
    "                if status_quote._json['id_str'] == self.buzz_id_str:\n",
    "                    continue\n",
    "                else:\n",
    "                    row = self._format_text(status_quote._json['text'])\n",
    "                #極性判定\n",
    "                sentiment_score = self.oseti_analyzer.count_polarity(str(row))#strにする\n",
    "                self.sentiment_list.append(sentiment_score)\n",
    "                self.rt_row.append(row)\n",
    "                self.RTcomme_cnt += 1\n",
    "        #エラーはスキップして次のツイート取得\n",
    "        except (ValueError,  KeyError, tweepy.TweepError) as e:\n",
    "            pass\n",
    "        #リクエスト回数が上限に達した場合はリセット時間まで待機して継続\n",
    "        except tweepy.RateLimitError as e:\n",
    "            self.wait += 1\n",
    "            if self.reload:\n",
    "                print(\"==========\")\n",
    "                print('get_rtのリクエスト回数が上限に達しました。リセット時間まで待機')\n",
    "                print('Wait 15min...')\n",
    "                print()\n",
    "                for _ in tqdm(range(15 * 60)):\n",
    "                    time.sleep(1)\n",
    "            else:\n",
    "                pass        \n",
    "\n",
    "    #取得したTweetをprint\n",
    "    def _Print(self):\n",
    "        print(\"name：\", self.buzz_name, \"／フォロワー数：\", self.followers)\n",
    "        print(\"date：\", self.date, \"／ツイートID：\", self.buzz_id_str)\n",
    "        print(\"RT数：\", self.rt_count, \"／favorite数：\", self.favo)\n",
    "        print(\"リプライ数：\", self.rep_cnt, \"／RTコメント数(上限１００）：\", self.RTcomme_cnt)\n",
    "        if self.print_rep == True:\n",
    "            print(\"リプライ\\n\", self.rep_row)\n",
    "            print(\"RTコメント\\n\", self.rt_row)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    #センチメント判定結果を取得\n",
    "    def _Get_Analysis(self):\n",
    "        total = self.sentiment[\"positive\"] + self.sentiment[\"negative\"]\n",
    "        if self.sentiment[\"positive\"] >= self.sentiment[\"negative\"]:\n",
    "            print(\"==========\")\n",
    "            print(self.buzz_full_text)\n",
    "            print()\n",
    "            print(\"【判定:positive】　　極性表現数\", self.sentiment)\n",
    "            self._Print()\n",
    "            s = pd.Series([self.buzz_id, self.date, self.buzz_name, self.buzz_full_text, \"positive\", self.sentiment[\"positive\"], self.sentiment[\"negative\"], self.followers, self.link], index = self.columns)\n",
    "            self.posi_pd = self.posi_pd.append(s, ignore_index=True)\n",
    "        elif self.sentiment[\"negative\"]/total >= 0.7:\n",
    "            print(\"==========\")\n",
    "            print(self.buzz_full_text)\n",
    "            print()\n",
    "            print(\"【判定:fire!!!】　　極性表現数\", self.sentiment)\n",
    "            print(\"ネガ表現の割合{:.3g}\".format(self.sentiment[\"negative\"]/total))\n",
    "            self._Print()\n",
    "            s = pd.Series([self.buzz_id, self.date, self.buzz_name, self.buzz_full_text, \"fire\", self.sentiment[\"positive\"], self.sentiment[\"negative\"], self.followers, self.link], index = self.columns)\n",
    "            self.fire_pd = self.fire_pd.append(s, ignore_index=True)\n",
    "        else:\n",
    "            print(\"==========\")\n",
    "            print(self.buzz_full_text)\n",
    "            print()\n",
    "            print(\"【判定:negative】　　極性表現数\", self.sentiment)\n",
    "            self._Print()\n",
    "            s = pd.Series([self.buzz_id, self.date, self.buzz_name, self.buzz_full_text, \"negative\", self.sentiment[\"positive\"], self.sentiment[\"negative\"], self.followers, self.link], index = self.columns)\n",
    "            self.nega_pd = self.nega_pd.append(s, ignore_index=True)\n",
    "        print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ツイートデータセット取得　実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "【鬼滅の刃コラボ中！】\n",
      "ローソン国際展示場駅前店では1日限定で「鬼滅の刃」コラボを実施中です！\n",
      "\n",
      "キャラクタースタンディやポスターの展示、また入店音が炭治郎・禰豆子・善逸・伊之助のボイス（ランダム）となっておりますのでぜひチェックしてください！\n",
      "\n",
      "#鬼滅の刃 \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 19, 'negative': 19}\n",
      "name： kimetsu_off ／フォロワー数： 962989\n",
      "date： 2019-12-28 08:56 ／ツイートID： 1210710961771859968\n",
      "RT数： 7096 ／favorite数： 40235\n",
      "リプライ数： 1 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "どなたかが呟かれてましたけど、成人のADHDでは「何か思いつくと、それをタスクの一番最後に追加するのではなく、現在行っているタスクの一番上に常に置いてしまい、それに注意を占有されてしまうことから、その結果スケジュールが崩壊して死ぬ」という状態になる人が多い気がしますな。\n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 61, 'negative': 59}\n",
      "name： noooooooorth ／フォロワー数： 15678\n",
      "date： 2019-12-28 08:45 ／ツイートID： 1210708419159609344\n",
      "RT数： 6443 ／favorite数： 23513\n",
      "リプライ数： 24 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "若月健矢選手、立花理香さん\n",
      "\n",
      "ご結婚おめでとうございます！\n",
      "末長くお幸せに✨\n",
      "\n",
      "バファローズ㊗️ポンタ\n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 71, 'negative': 3}\n",
      "name： bs_ponta ／フォロワー数： 288623\n",
      "date： 2019-12-28 08:34 ／ツイートID： 1210705650491113472\n",
      "RT数： 7019 ／favorite数： 13577\n",
      "リプライ数： 59 ／RTコメント数(上限１００）： 51\n",
      "\n",
      "==========\n",
      "【ご報告】この度、みなさまにご報告したいことができました。ぜひご覧いただけますと幸いです。 \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 149, 'negative': 23}\n",
      "name： RiccaTachibana ／フォロワー数： 175428\n",
      "date： 2019-12-28 08:22 ／ツイートID： 1210702646509588480\n",
      "RT数： 45555 ／favorite数： 85001\n",
      "リプライ数： 81 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "【#本日12月28日は竈門禰豆子の誕生日!!】\n",
      "本日は、鬼でありながら鬼殺隊に所属する\n",
      "炭治郎自慢の妹・竈門禰豆子の誕生日です！\n",
      "\n",
      "この特別な日を祝して、\n",
      "禰豆子の魅力が詰まったヘッダーをプレゼント！\n",
      "\n",
      "人を守るために鬼の力を使う\n",
      "禰豆子のヘッダー、ぜひご活用ください！ \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 76, 'negative': 12}\n",
      "name： kimetsu_off ／フォロワー数： 962989\n",
      "date： 2019-12-28 08:00 ／ツイートID： 1210696997839110144\n",
      "RT数： 39976 ／favorite数： 134091\n",
      "リプライ数： 23 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "【注意喚起！】寝ている人から財布等を抜き取る犯罪が発生しているという連絡が警察からありました。待機列などで、皆さん声を掛け合って、注意してください。残念ながらコミケでは、4会期連続でスリの現行犯逮捕が起きています。お宝資金はしっかりと管理を。#C97\n",
      "\n",
      "【判定:negative】　　極性表現数 {'positive': 62, 'negative': 111}\n",
      "name： comiketofficial ／フォロワー数： 221676\n",
      "date： 2019-12-28 07:27 ／ツイートID： 1210688744660975616\n",
      "RT数： 10193 ／favorite数： 7486\n",
      "リプライ数： 5 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "「鬼滅の刃」グッズプレゼント🎉\n",
      "\n",
      "大好評のため第2段\n",
      "シリーズ累計2500万部記念\n",
      "鬼滅の刃 全18巻セット\n",
      "を10名様にプレゼント🎁\n",
      "\n",
      "応募方法\n",
      "・フォロー&amp;リツィート\n",
      "・「応募」とリプ\n",
      "\n",
      "応募期間\n",
      "・12月31日\n",
      "\n",
      "当選した方にはDMにてお知らせ！ \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 26, 'negative': 15}\n",
      "name： kimetsu_goods ／フォロワー数： 15932\n",
      "date： 2019-12-28 07:10 ／ツイートID： 1210684401157206016\n",
      "RT数： 8845 ／favorite数： 5525\n",
      "リプライ数： 99 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "アニメーター始めてから初めてキャベツを描いた、妙なプレッシャーがあった\n",
      "#炎炎ノ消防隊 \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 89, 'negative': 39}\n",
      "name： varon666 ／フォロワー数： 3640\n",
      "date： 2019-12-28 02:49 ／ツイートID： 1210618724517990400\n",
      "RT数： 20342 ／favorite数： 62600\n",
      "リプライ数： 72 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "🔥“弐ノ章”制作＆2020年夏放送決定🔥\n",
      "\n",
      "壱ノ章の続編となるTVアニメ『炎炎ノ消防隊 弐ノ章』の制作が決定しました！\n",
      "\n",
      "さらに“弐ノ章ティザービジュアル”も発表！\n",
      "\n",
      "2020年も炎炎の炎はますます燃え続けます🔥🔥\n",
      "\n",
      "『炎炎ノ消防隊 弐ノ章』ご期待ください！！\n",
      "\n",
      "#fireforce #炎炎ノ消防隊 #弐ノ章 \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 105, 'negative': 33}\n",
      "name： FireForce_PR ／フォロワー数： 80030\n",
      "date： 2019-12-28 02:07 ／ツイートID： 1210608126434500608\n",
      "RT数： 8431 ／favorite数： 19499\n",
      "リプライ数： 63 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "【祝】12月28日は「竈門禰豆子の誕生日」\n",
      "\n",
      "『鬼滅の刃』の登場キャラクターで、主人公・竈門炭治郎の妹。物語開始時12歳→14歳。家族と慎ましくも幸せな生活を送っていたが、突然の惨劇により鬼に変貌してしまう。人を喰らう鬼としての衝動を抑え込みながら、炭治郎や仲間のために行動する。 \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 73, 'negative': 9}\n",
      "name： livedoornews ／フォロワー数： 993015\n",
      "date： 2019-12-28 00:15 ／ツイートID： 1210579841025789952\n",
      "RT数： 7148 ／favorite数： 30363\n",
      "リプライ数： 1 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "コミケ会場で「プライスカードを忘れた😭」となった場合、落ち着いて机の上にあるチラシ類を見てみて下さい。\n",
      "全てのサークルさんの机の上に、プライスカードを置いてきましたから😋\n",
      "\n",
      "＊不要でしたらごめんなさい \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 137, 'negative': 41}\n",
      "name： ShimayaTokyo ／フォロワー数： 7794\n",
      "date： 2019-12-27 22:54 ／ツイートID： 1210559641823793152\n",
      "RT数： 17607 ／favorite数： 23939\n",
      "リプライ数： 56 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "チュートリアルでお世話になったキャラが実は最強の裏ボスっていうゲーム \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 60, 'negative': 34}\n",
      "name： black_sabasu ／フォロワー数： 86523\n",
      "date： 2019-12-27 22:26 ／ツイートID： 1210552542595178498\n",
      "RT数： 6890 ／favorite数： 27555\n",
      "リプライ数： 64 ／RTコメント数(上限１００）： 48\n",
      "\n",
      "==========\n",
      "Mステ #ウルトラSUPERLIVE \n",
      "11時間生放送中🎤\n",
      "\n",
      "女々しくての10周年のお祝いに駆けつけてくれたのはなんと\n",
      "#ボボボーボ・ボーボボ\n",
      "でした‼️\n",
      "\n",
      "#ボボボーボ\n",
      "#ボーボボ\n",
      "#ウルトラタモリ\n",
      "#Mステ \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 32, 'negative': 22}\n",
      "name： Mst_com ／フォロワー数： 1247726\n",
      "date： 2019-12-27 22:12 ／ツイートID： 1210549021443379200\n",
      "RT数： 12423 ／favorite数： 20446\n",
      "リプライ数： 4 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "クソワロ\n",
      "\n",
      "女々しくて発売10年で人気キャラが駆けつける・・・\n",
      "\n",
      "ボボボーボ・ボーボボｗｗｗｗｗｗｗｗ\n",
      "\n",
      "#Mステ\n",
      "#金爆 \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 31, 'negative': 18}\n",
      "name： k3po7gouki ／フォロワー数： 7124\n",
      "date： 2019-12-27 22:04 ／ツイートID： 1210547002594840577\n",
      "RT数： 5713 ／favorite数： 13473\n",
      "リプライ数： 14 ／RTコメント数(上限１００）： 93\n",
      "\n",
      "==========\n",
      "なにわ男子「2019年ありがとうございました！」\n",
      "アオハルツアー愛知公演でしたー！\n",
      "2019年のコンサートを締めくくることができました！\n",
      "\n",
      "なにふぁむのみなさんへ\n",
      "\n",
      "｢最高な1年をありがとう♡｣\n",
      "\n",
      "なにわ男子からの報告事も！\n",
      "\n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 133, 'negative': 37}\n",
      "name： islandtv_up ／フォロワー数： 192258\n",
      "date： 2019-12-27 21:50 ／ツイートID： 1210543508886441985\n",
      "RT数： 8532 ／favorite数： 19875\n",
      "リプライ数： 1 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "今日で仕事納めの方が多いみたいなので良かったらこれ見て疲れを癒してください。 \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 80, 'negative': 15}\n",
      "name： jirosan77 ／フォロワー数： 203205\n",
      "date： 2019-12-27 21:46 ／ツイートID： 1210542380153065472\n",
      "RT数： 6104 ／favorite数： 31001\n",
      "リプライ数： 66 ／RTコメント数(上限１００）： 35\n",
      "\n",
      "==========\n",
      "昨日は恩師であり、恩人であり、ホンモノの小栗旬さんのお誕生日だったので、夜中に正装で会いに行きました。\n",
      "\n",
      "おめでとうございまーきのっ！ \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 53, 'negative': 15}\n",
      "name： hinode_obt ／フォロワー数： 173268\n",
      "date： 2019-12-27 21:36 ／ツイートID： 1210539839268913152\n",
      "RT数： 6615 ／favorite数： 101848\n",
      "リプライ数： 71 ／RTコメント数(上限１００）： 59\n",
      "\n",
      "==========\n",
      "＃嵐 松潤さんに、\n",
      "\n",
      "「ゴーちゃんってオス？」\n",
      "\n",
      "とも聞かれたブイ！\n",
      "\n",
      "松潤さんが思うほうでOKブイ\n",
      "\n",
      "＃ウルトラSUPERLIVE   \n",
      "＃Mステ\n",
      "＃ウルトラゴーちゃん\n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 83, 'negative': 23}\n",
      "name： gochan_V ／フォロワー数： 73976\n",
      "date： 2019-12-27 21:11 ／ツイートID： 1210533697167867906\n",
      "RT数： 8380 ／favorite数： 31313\n",
      "リプライ数： 2 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "東京スカイツリー駅近くにあるお店「まんまる」の、お好みできなことあんこと黒蜜をつけて食べる「あったか白玉」✨\n",
      "\n",
      "白玉が6個ついて500円とリーズナブルで、味も抜群の美味しさです！ \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 44, 'negative': 12}\n",
      "name： sweetroad5 ／フォロワー数： 355716\n",
      "date： 2019-12-27 21:08 ／ツイートID： 1210532793383411713\n",
      "RT数： 5953 ／favorite数： 28749\n",
      "リプライ数： 6 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "『ノンストップ・ストーリー』ライブキービジュアル用にホロライブメンバー23名を描かせていただきました。おるだんさんデザインの衣装が素敵すぎる😭✨ライブ今から楽しみだ～！ \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 119, 'negative': 20}\n",
      "name： naru_quadrille ／フォロワー数： 25886\n",
      "date： 2019-12-27 21:06 ／ツイートID： 1210532392407977984\n",
      "RT数： 5757 ／favorite数： 14884\n",
      "リプライ数： 82 ／RTコメント数(上限１００）： 55\n",
      "\n",
      "==========\n",
      "＃嵐 松潤さんは、\n",
      "\n",
      "「いつも同じ人が入ってる？」\n",
      "「何人かいるの？」\n",
      "「暑くない？」\n",
      "\n",
      "とか話しかけてくれたブイ！正直質問の意味はよく分からなかったけど、とにかくお話できて本当にうれしかったブイ！\n",
      "\n",
      "＃ウルトラSUPERLIVE   \n",
      "＃Mステ\n",
      "＃ウルトラゴーちゃん\n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 88, 'negative': 9}\n",
      "name： gochan_V ／フォロワー数： 73976\n",
      "date： 2019-12-27 21:00 ／ツイートID： 1210530972006936576\n",
      "RT数： 14195 ／favorite数： 49486\n",
      "リプライ数： 3 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "【🎉 重 大 発 表 🎉】\n",
      "\n",
      "「hololive 1st fes.『ノンストップ・ストーリー』」\n",
      "出演タレント23名のアイドル衣装＆メインヴィジュアル解禁✨\n",
      "\n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 64, 'negative': 24}\n",
      "name： hololivetv ／フォロワー数： 107967\n",
      "date： 2019-12-27 21:00 ／ツイートID： 1210530770474950657\n",
      "RT数： 5177 ／favorite数： 9706\n",
      "リプライ数： 2 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "King &amp; Princeのみなさんが #Mステカメラ 📹初登場～🤣\n",
      "\n",
      "今日のテーマは\n",
      "『今年一番盛り上がったこと』です😎Ⓜ\n",
      "”あるナゾナゾ”からメンバーを巻き込んだ一大事に😂\n",
      "答えは「森」なので「木が3本」でした🌲🌲🌲\n",
      "\n",
      "今日は『koi-wazurai』を披露してくれます😍😍\n",
      "#ウルトラSUPERLIVE #Mステ \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 122, 'negative': 24}\n",
      "name： Mst_com ／フォロワー数： 1247726\n",
      "date： 2019-12-27 20:23 ／ツイートID： 1210521643577040896\n",
      "RT数： 17098 ／favorite数： 54026\n",
      "リプライ数： 4 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "【刀剣乱舞★１月１１日発売】次号は特集「刀剣乱舞」。５周年を記念し、あの刀剣&amp;現主の撮りおろしグラビア、天野喜孝ら豪華執筆陣によるアンソロジー、山姥切国広・長義（絵/⑪）、鶴丸国永(絵/Izumi)の特別描きおろしまで盛りだくさん。全国書店・ウェブ書店にて予約受付中！\n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 38, 'negative': 23}\n",
      "name： BRUTUS_mag ／フォロワー数： 127717\n",
      "date： 2019-12-27 20:20 ／ツイートID： 1210520848508936193\n",
      "RT数： 9039 ／favorite数： 12678\n",
      "リプライ数： 9 ／RTコメント数(上限１００）： 92\n",
      "\n",
      "==========\n",
      "可愛い可愛い\n",
      "かずま。ふじお。\n",
      "お疲れちゃん。\n",
      "\n",
      "#HiGH_LOW_THE_WORST\n",
      "#ハイロー\n",
      "#THERAMPAGE \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 136, 'negative': 30}\n",
      "name： jun_shison0305 ／フォロワー数： 483928\n",
      "date： 2019-12-27 20:13 ／ツイートID： 1210519062096138240\n",
      "RT数： 8226 ／favorite数： 43260\n",
      "リプライ数： 74 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "✨ディズニー限定デザインPRESENT✨\n",
      "\n",
      "@lovemaybelline をフォロー&amp;\n",
      "この投稿をリツイートで、\n",
      "\n",
      "❤ラッシュニスタ N\n",
      "❤ハイパーシャープ ライナー R\n",
      "❤パウダーインペンシル BR2\n",
      "\n",
      "のミッキーマウスデザイン３itemsが抽選で10名様に当たるチャンス！\n",
      "\n",
      "応募は12/31まで🆗\n",
      "\n",
      "#メイベリン\n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 194, 'negative': 19}\n",
      "name： LoveMaybelline ／フォロワー数： 205766\n",
      "date： 2019-12-27 20:00 ／ツイートID： 1210515669101338625\n",
      "RT数： 7058 ／favorite数： 1267\n",
      "リプライ数： 95 ／RTコメント数(上限１００）： 9\n",
      "\n",
      "\n",
      "↓↓↓positiveサンプル↓↓↓\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Name</th>\n",
       "      <th>Full_text</th>\n",
       "      <th>Judge</th>\n",
       "      <th>Posi_score</th>\n",
       "      <th>Nega_score</th>\n",
       "      <th>Followers</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1210710961771859968</td>\n",
       "      <td>2019-12-28 08:56</td>\n",
       "      <td>kimetsu_off</td>\n",
       "      <td>【鬼滅の刃コラボ中！】\\nローソン国際展示場駅前店では1日限定で「鬼滅の刃」コラボを実施中で...</td>\n",
       "      <td>positive</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>962989</td>\n",
       "      <td>https://t.co/TgagYYCcAU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1210708419159609344</td>\n",
       "      <td>2019-12-28 08:45</td>\n",
       "      <td>noooooooorth</td>\n",
       "      <td>どなたかが呟かれてましたけど、成人のADHDでは「何か思いつくと、それをタスクの一番最後に追...</td>\n",
       "      <td>positive</td>\n",
       "      <td>61</td>\n",
       "      <td>59</td>\n",
       "      <td>15678</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1210705650491113472</td>\n",
       "      <td>2019-12-28 08:34</td>\n",
       "      <td>bs_ponta</td>\n",
       "      <td>若月健矢選手、立花理香さん\\n\\nご結婚おめでとうございます！\\n末長くお幸せに✨\\n\\nバ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>288623</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1210702646509588480</td>\n",
       "      <td>2019-12-28 08:22</td>\n",
       "      <td>RiccaTachibana</td>\n",
       "      <td>【ご報告】この度、みなさまにご報告したいことができました。ぜひご覧いただけますと幸いです。</td>\n",
       "      <td>positive</td>\n",
       "      <td>149</td>\n",
       "      <td>23</td>\n",
       "      <td>175428</td>\n",
       "      <td>https://t.co/hR8m5IHoBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1210696997839110144</td>\n",
       "      <td>2019-12-28 08:00</td>\n",
       "      <td>kimetsu_off</td>\n",
       "      <td>【#本日12月28日は竈門禰豆子の誕生日!!】\\n本日は、鬼でありながら鬼殺隊に所属する\\n...</td>\n",
       "      <td>positive</td>\n",
       "      <td>76</td>\n",
       "      <td>12</td>\n",
       "      <td>962989</td>\n",
       "      <td>https://t.co/gOF5Qp6woi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Id              Date            Name  \\\n",
       "0  1210710961771859968  2019-12-28 08:56     kimetsu_off   \n",
       "1  1210708419159609344  2019-12-28 08:45    noooooooorth   \n",
       "2  1210705650491113472  2019-12-28 08:34        bs_ponta   \n",
       "3  1210702646509588480  2019-12-28 08:22  RiccaTachibana   \n",
       "4  1210696997839110144  2019-12-28 08:00     kimetsu_off   \n",
       "\n",
       "                                           Full_text     Judge Posi_score  \\\n",
       "0  【鬼滅の刃コラボ中！】\\nローソン国際展示場駅前店では1日限定で「鬼滅の刃」コラボを実施中で...  positive         19   \n",
       "1  どなたかが呟かれてましたけど、成人のADHDでは「何か思いつくと、それをタスクの一番最後に追...  positive         61   \n",
       "2  若月健矢選手、立花理香さん\\n\\nご結婚おめでとうございます！\\n末長くお幸せに✨\\n\\nバ...  positive         71   \n",
       "3     【ご報告】この度、みなさまにご報告したいことができました。ぜひご覧いただけますと幸いです。   positive        149   \n",
       "4  【#本日12月28日は竈門禰豆子の誕生日!!】\\n本日は、鬼でありながら鬼殺隊に所属する\\n...  positive         76   \n",
       "\n",
       "  Nega_score Followers                     link  \n",
       "0         19    962989  https://t.co/TgagYYCcAU  \n",
       "1         59     15678                     None  \n",
       "2          3    288623                     None  \n",
       "3         23    175428  https://t.co/hR8m5IHoBD  \n",
       "4         12    962989  https://t.co/gOF5Qp6woi  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "↓↓↓negativeサンプル↓↓↓\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Name</th>\n",
       "      <th>Full_text</th>\n",
       "      <th>Judge</th>\n",
       "      <th>Posi_score</th>\n",
       "      <th>Nega_score</th>\n",
       "      <th>Followers</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1210688744660975616</td>\n",
       "      <td>2019-12-28 07:27</td>\n",
       "      <td>comiketofficial</td>\n",
       "      <td>【注意喚起！】寝ている人から財布等を抜き取る犯罪が発生しているという連絡が警察からありました...</td>\n",
       "      <td>negative</td>\n",
       "      <td>62</td>\n",
       "      <td>111</td>\n",
       "      <td>221676</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Id              Date             Name  \\\n",
       "0  1210688744660975616  2019-12-28 07:27  comiketofficial   \n",
       "\n",
       "                                           Full_text     Judge Posi_score  \\\n",
       "0  【注意喚起！】寝ている人から財布等を抜き取る犯罪が発生しているという連絡が警察からありました...  negative         62   \n",
       "\n",
       "  Nega_score Followers  link  \n",
       "0        111    221676  None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "↓↓↓fire_tweetサンプル↓↓↓\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Name</th>\n",
       "      <th>Full_text</th>\n",
       "      <th>Judge</th>\n",
       "      <th>Posi_score</th>\n",
       "      <th>Nega_score</th>\n",
       "      <th>Followers</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Id, Date, Name, Full_text, Judge, Posi_score, Nega_score, Followers, link]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "csvへの書き出しが完了しました。新規データ数1、全データ数：314\n",
      "サンプルが0件の場合は、15分後に再度実行すると取得できる場合があります。\n",
      "fire_tweetは出現率が非常に低いです。\n"
     ]
    }
   ],
   "source": [
    "# 指定日のツイートを取得（API制限のため取得できるのは約一週間前のものまで）\n",
    "day = '2019-12-28'\n",
    "# リクエスト制限対応：True:リクエスト上限に達したら15分待機ののちツイート取得続行/ False:待機せずcsv取得\n",
    "reload = True\n",
    "\n",
    "#除外ワード\n",
    "exclud_words = \"配信スタート ＃キャンペーン　リツイートキャンペーン WWWWWWWWW\"\n",
    "\n",
    "#その他設定可能パラメータ\n",
    "#リプライをprint（print_rep = True/Fals), 最低RT数(RT_count = 5000)\n",
    "\n",
    "GT = Get_Twitter(day, reload, exclud_words)\n",
    "GT.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ２）データセットの前処理\n",
    "　・正規表現、ストップワード除去など\n",
    " \n",
    " #### 参考サイト\n",
    "Pythonで全角・半角記号をまとめて消し去る<br>　http://prpr.hatenablog.jp/entry/2016/11/23/Python%E3%81%A7%E5%85%A8%E8%A7%92%E3%83%BB%E5%8D%8A%E8%A7%92%E8%A8%98%E5%8F%B7%E3%82%92%E3%81%BE%E3%81%A8%E3%82%81%E3%81%A6%E6%B6%88%E3%81%97%E5%8E%BB%E3%82%8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.6/site-packages (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.6/site-packages (from gensim) (1.13.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.6/site-packages (from gensim) (0.19.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.6/site-packages (from gensim) (1.11.0)\n",
      "Requirement already satisfied: smart_open>=1.2.1 in /opt/conda/lib/python3.6/site-packages (from gensim) (1.5.3)\n",
      "Requirement already satisfied: boto>=2.32 in /opt/conda/lib/python3.6/site-packages (from smart_open>=1.2.1->gensim) (2.48.0)\n",
      "Requirement already satisfied: bz2file in /opt/conda/lib/python3.6/site-packages (from smart_open>=1.2.1->gensim) (0.98)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from smart_open>=1.2.1->gensim) (2.18.4)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->smart_open>=1.2.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->smart_open>=1.2.1->gensim) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->smart_open>=1.2.1->gensim) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->smart_open>=1.2.1->gensim) (2018.1.18)\n",
      "Requirement already satisfied: natto-py in /opt/conda/lib/python3.6/site-packages (0.9.0)\n",
      "Requirement already satisfied: cffi in /opt/conda/lib/python3.6/site-packages (from natto-py) (1.10.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi->natto-py) (2.18)\n",
      "Requirement already satisfied: emoji in /opt/conda/lib/python3.6/site-packages (0.5.4)\n"
     ]
    }
   ],
   "source": [
    "#必要なツールをインストール(初回のみ実行)\n",
    "! pip install gensim\n",
    "! pip install natto-py\n",
    "! pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ツイートデータを学習用に整形\n",
    "#from natto import MeCab\n",
    "import MeCab\n",
    "import re\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import emoji\n",
    "import neologdn\n",
    "import urllib.request\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "class For_Model():\n",
    "    \n",
    "    def __init__(self, data, columns, out_file, mode, text, similar = None):\n",
    "        self.mecab = MeCab.Tagger(\"-Owakati\")\n",
    "        self.data = data\n",
    "        self.columns = columns\n",
    "        self.out_file = out_file\n",
    "        self.mode = mode\n",
    "        self.text = text\n",
    "        self.similar = str(similar)\n",
    "\n",
    "    #データを読み込む\n",
    "    def Load_tweets(self):        \n",
    "        df = pd.read_csv(self.data, usecols = self.columns)\n",
    "        print(\"読み込んだツイート\", df.shape)\n",
    "        \n",
    "        #３０w以下のtweet行を削除\n",
    "        index = []\n",
    "        for i in range(len(df)):\n",
    "            line = df.iloc[i]\n",
    "            text = str(line[\"Full_text\"])\n",
    "            text = re.sub('https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-…]+', \"\", text)\n",
    "            text = re.sub('http?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-…]+', \"\", text)\n",
    "            line[\"Full_text\"] = text\n",
    "            if len(text) < 30:\n",
    "                index.append(i)\n",
    "        df_tweet = df.drop(df.index[index])\n",
    "        df_tweet = df_tweet.reset_index(drop=True)\n",
    "        print(\"30w以下削除後のツイート数\", df_tweet.shape)\n",
    "        display(df_tweet.head())\n",
    "        \n",
    "        #判定用テキストをリストの最後に追加\n",
    "        tweets = []\n",
    "        for i in df_tweet[self.text]:\n",
    "            tweets.append(i)\n",
    "        if self.similar == None:\n",
    "            pass\n",
    "        else:\n",
    "            tweets.append(self.similar)\n",
    "        return df_tweet, tweets\n",
    "\n",
    "    def Stop_Words(self):\n",
    "        # ストップワードをダウンロード\n",
    "        url = 'http://svn.sourceforge.jp/svnroot/slothlib/CSharp/Version1/SlothLib/NLP/Filter/StopWord/word/Japanese.txt'\n",
    "        urllib.request.urlretrieve(url, './output/stop_word.txt')\n",
    "\n",
    "        with open('./output/stop_word.txt', 'r', encoding='utf-8') as file:\n",
    "            stopwords = [word.replace('\\n', '') for word in file.readlines()]\n",
    "\n",
    "        #追加ストップワードを設定（助詞や意味のない平仮名１文字）\n",
    "        add_words = ['あ','い','う','え','お','か','き','く','け','こ','さ','し','す','せ','そ','た','ち','つ','て','と',\n",
    "                     'な','に','ぬ','ね','の','は','ひ','ふ','へ','ほ','ま','み','む','め','も','や','ゆ','よ',\n",
    "                     'ら','り','る','れ','ろ','わ','を','ん','が','ぎ','ぐ','げ','ご','ざ','じ','ず','ぜ','ぞ',\n",
    "                     'だ','ぢ','づ','で','ど','ば','び','ぶ','べ','ぼ','ぱ','ぴ','ぷ','ぺ','ぽ',\n",
    "                     'くん','です','ます','ました','そして','でも','だから','だが','くらい','その','それ','かも',\n",
    "                     'あれ','あの','あっ','そんな','この','これ','とか','とも','する','という','ござい',\n",
    "                     'ので','なんて','たら', 'られ','たい','さて','てる','ください','なる','けど','でし',\n",
    "                     'じゃん','だっ','なっ','でしょ', 'ある','って','こんな','ねえ'\n",
    "                    ]\n",
    "        stopwords = stopwords + add_words\n",
    "        return stopwords\n",
    "\n",
    "    def Tokenizer(self, text, stopwords):\n",
    "\n",
    "        words = []\n",
    "        text = self.mecab.parse(text)\n",
    "        text = text.split(' ')\n",
    "        for j in range(len(text)):\n",
    "            if text[j] not in stopwords:\n",
    "                words.append(text[j])\n",
    "        return words\n",
    "\n",
    "    def remove_emoji(self, text):\n",
    "        return ''.join(c for c in text if c not in emoji.UNICODE_EMOJI)\n",
    "\n",
    "    #記号削除\n",
    "    def format_text(self, text):\n",
    "        text = unicodedata.normalize(\"NFKC\", text)  # 全角記号を半角へ置換\n",
    "        # 記号を消し去るための魔法のテーブル作成\n",
    "        table = str.maketrans(\"\", \"\", string.punctuation  + \"「」、。・*`+-|?#!()\\[]<>=~/\")\n",
    "        text = text.translate(table)\n",
    "        return text\n",
    "\n",
    "    def main(self):\n",
    "        tweets_num = 0\n",
    "        stopwords = self.Stop_Words()\n",
    "        df_tweet, tweets = self.Load_tweets()\n",
    "        #ツイートを分かち書きしてcsvに出力(モード'a'はデータ追加、モード'w'は新規作成)\n",
    "        with open('./output/' + self.out_file, self.mode) as f:\n",
    "            for i in tweets:\n",
    "                tweets_num += 1\n",
    "                i = neologdn.normalize(i)\n",
    "                i = re.sub('\\n', \"\", i)\n",
    "                i = re.sub(r'[!-~]', \"\", i)#半角記号,数字,英字\n",
    "                i = re.sub(r'[︰-＠]', \"\", i)#全角記号\n",
    "                i = self.format_text(i)#記号削除\n",
    "                i = re.sub(r'[【】●ㅅ●Ф☆✩︎♡→←▼①②③④⑤『』ω《》∠∇∩♪∀◞ཀCщ≧≦ ́◤◢■◆★※↑↓〇◯○◎⇒▽◉Θ♫♬〃“”◇ᄉ⊂⊃д°]', \"\", i)\n",
    "                #i = re.sub(r'[!-~、。‥…？！〜「」｢｣:：“”【】※♪♩♫♬『』→↓↑《》〈〉[]≧∇≦・゜・●ㅅ●´Д´°ω°•ω•★＊☆♡（）✔Θ∀´∀｀˘ω˘‼бωб￣▽￣◉→←▼①②③④⑤]', \"\", i)\n",
    "                i = self.remove_emoji(i)\n",
    "                i = self.Tokenizer(i, stopwords)\n",
    "                i = ' '.join(i) #リストを文字列に変換\n",
    "                i = str(i)\n",
    "                f.write(i)\n",
    "\n",
    "        print('CSV出力完了：'+ self.out_file)\n",
    "        with open('./output/' + self.out_file) as f:\n",
    "             wakati = f.read()\n",
    "\n",
    "        print(\"学習用データに書き込んだツイート数（判定用ツイート含む）：\", tweets_num)\n",
    "        print()\n",
    "        print(\"分かち書きサンプル\\n\", wakati[:500])\n",
    "        return df_tweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前処理の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "読み込んだツイート (314, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30w以下削除後のツイート数 (259, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Followers</th>\n",
       "      <th>Full_text</th>\n",
       "      <th>Judge</th>\n",
       "      <th>Nega_score</th>\n",
       "      <th>Posi_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1564.0</td>\n",
       "      <td>絶対断らないと評判の病児保育室、助成金下りず2億円の赤字を出し閉鎖\\n\\n全国に2886カ所...</td>\n",
       "      <td>positive</td>\n",
       "      <td>148.0</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2217.0</td>\n",
       "      <td>全国の皆さんへ\\nどうか皆様のお力を貸してください。\\n\\n１日も早く娘を助けたいです。\\n...</td>\n",
       "      <td>positive</td>\n",
       "      <td>50.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3756.0</td>\n",
       "      <td>o0( 歴史上、さんざん他国の料理を魔改造してきた我が国が「寿司ポリス」などどは片腹痛い！あ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>85.0</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10999.0</td>\n",
       "      <td>これすんごい。GABAのフォースリープ、ツイッターで人気だったから半信半疑で夜に3粒食べてみ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>78.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56685.0</td>\n",
       "      <td>TVアニメ「Ｄｒ．ＳＴＯＮＥ」第2期制作が決定いたしました！第1期をご視聴・応援くださってい...</td>\n",
       "      <td>positive</td>\n",
       "      <td>20.0</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Followers                                          Full_text     Judge  \\\n",
       "0     1564.0  絶対断らないと評判の病児保育室、助成金下りず2億円の赤字を出し閉鎖\\n\\n全国に2886カ所...  positive   \n",
       "1     2217.0  全国の皆さんへ\\nどうか皆様のお力を貸してください。\\n\\n１日も早く娘を助けたいです。\\n...  positive   \n",
       "2     3756.0  o0( 歴史上、さんざん他国の料理を魔改造してきた我が国が「寿司ポリス」などどは片腹痛い！あ...  positive   \n",
       "3    10999.0  これすんごい。GABAのフォースリープ、ツイッターで人気だったから半信半疑で夜に3粒食べてみ...  positive   \n",
       "4    56685.0  TVアニメ「Ｄｒ．ＳＴＯＮＥ」第2期制作が決定いたしました！第1期をご視聴・応援くださってい...  positive   \n",
       "\n",
       "   Nega_score  Posi_score  \n",
       "0       148.0       168.0  \n",
       "1        50.0       129.0  \n",
       "2        85.0       137.0  \n",
       "3        78.0        97.0  \n",
       "4        20.0       156.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV出力完了：train_buzz.txt\n",
      "学習用データに書き込んだツイート数： 260\n",
      "\n",
      "分かち書きサンプル\n",
      " 絶対 断ら ない 評判 病児保育 助成金 下り 赤字 出し 閉鎖 全国 病児保育 赤字 運営 おり 東海 キッズケア 助成金 求め 署名 集め 助成金 下りる あり ませ 社会保障 税金 使わ ませ \n",
      "全国 皆さん どうか 皆様 お力 貸し 早く 娘 助け 家族 揃っ 笑顔 クリスマス 新年 迎え 娘 目撃 情報 娘 繋がる 些細なこと 連絡 連絡先 大月 警察 暑 電話 もしくは 最寄り 警察 署 拡散希望 小倉 美咲 \n",
      "歴史 さんざん 他国 料理 魔 改造 我が国 寿司 ポリス どど 片腹痛い あらゆる 文化 文化 独自 解釈 いい イノベーション 生む 思っ しかし ヘルシンキ 〈 クリスマス トッピング • バナナ 巻き寿司 〉 寛容 試さ いる \n",
      "すん ごい フォースリープツイッター 人気 半信半疑 夜 粒 食べ 昨日 めちゃ ぐっすり 眠れ 例える なら 旅行 気持ち良く 遊び 疲れ 夜 睡眠 クオリティ しかも 味 まろやか ミルク チョコ 好み すぎる 目安 一日 粒 摂 れる \n",
      "アニメ 期 制作 決定 いたし 期 視聴 応援 くださっ いる 皆様 本当に ありがとう \n"
     ]
    }
   ],
   "source": [
    "#パラメータの設定\n",
    "\n",
    "#取得したデータのパス\n",
    "data = './output/buzz_tweet.csv'\n",
    "#取得したい列名\n",
    "columns = [\"Followers\", \"Full_text\",\"Posi_score\", \"Nega_score\",\"Judge\"]\n",
    "#出力ファイル名\n",
    "out_file = \"train_buzz.txt\"\n",
    "#学習データの保存モード　'a'：追加／'w'：上書き\n",
    "mode = 'w'\n",
    "#ツイートテキストの列を指定\n",
    "text = \"Full_text\"\n",
    "#判定させたいツイート予定文書（類似度確認のため、データセット内にあるツイート文を使用）\n",
    "similar = \"イオンマスク禁止従業員の人嫌がるのわかるわ。\\\n",
    "インフルで出校停止中なんだけど薬効いて体元気だからイオン遊ばせに来た。みたいな事凄く多いんだよ。\\\n",
    "『店員が媒介にならないよう全店でマスク奨励してます。ご理解下さい』\\\n",
    "ってアナウンスされる方が余程良いのでイオンさん、マスク禁止撤回して\"\n",
    "\n",
    "FM = For_Model(data, columns, out_file, mode, text, similar)\n",
    "df_tweet = FM.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ３）予測モデルを生成\n",
    "　・データセットをDoc２vecで学習<br>\n",
    "\n",
    "#### 参考サイト\n",
    "fastTextとDoc2Vecのモデルを作成してニュース記事の多クラス分類の精度を比較する<br> https://qiita.com/kazuki_hayakawa/items/ca5d4735b9514895e197<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc２vec文書ベクトル用モデルに学習させたツイート数 260\n"
     ]
    }
   ],
   "source": [
    "#Doc2Vecモデルの学習\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "f = open('./output/train_buzz.txt','r')#空白で単語を区切り、改行で文書を区切っているテキストデータ\n",
    "\n",
    "#１文書ずつ、単語に分割してリストに入れていく[([単語1,単語2,単語3],文書id),...]こんなイメージ\n",
    "#words：文書に含まれる単語のリスト（単語の重複あり）\n",
    "# tags：文書の識別子（リストで指定．1つの文書に複数のタグを付与できる）\n",
    "#fにテキスト データをいれる\n",
    "trainings = [TaggedDocument(words = data.split(),tags = [i]) for i,data in enumerate(f)]\n",
    "#print(type(trainings))\n",
    "print(\"Doc２vec文書ベクトル用モデルに学習させたツイート数\",len(trainings))\n",
    "# print(trainings[:20])\n",
    "\n",
    "#文書ベクトル用ツイートテキストの学習\n",
    "model = Doc2Vec(\n",
    "    documents= trainings, \n",
    "    dm = 1, \n",
    "    vector_size=300, \n",
    "    window=10, \n",
    "    alpha = 0.05, \n",
    "    min_count=1, \n",
    "    sample = 0, \n",
    "    workers=4, \n",
    "    epochs = 50\n",
    ")\n",
    "\n",
    "#出力用ディレクトリ作成（存在しない場合のみ）\n",
    "def Make_Dir():\n",
    "    new_dir_path = 'model'\n",
    "    try:\n",
    "        os.makedirs(new_dir_path)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "# モデルのセーブ\n",
    "Make_Dir()\n",
    "model.save(\"./model/doc2vec.model\")\n",
    "\n",
    "# モデルのロード(モデルが用意してあれば、ここからで良い)\n",
    "m = Doc2Vec.load('./model/doc2vec.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ４）ツイート予定文章のネガポジ予測を返す\n",
    "　・データセットから、入力しておいたツイート予定文書と似ている文書を探す<br>\n",
    "・ネガポジスコア付きで、類似ツイート上位１０個を返す<br>\n",
    "#### 結果：成功。入力文書と同じツイート文が類似度１位に。ネガポジもデータズレなく表示できた"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== 判定したいツイート ===========\n",
      "\n",
      "イオンマスク禁止従業員の人嫌がるのわかるわ。インフルで出校停止中なんだけど薬効いて体元気だからイオン遊ばせに来た。みたいな事凄く多いんだよ。『店員が媒介にならないよう全店でマスク奨励してます。ご理解下さい』ってアナウンスされる方が余程良いのでイオンさん、マスク禁止撤回して\n",
      "\n",
      "======= 類似度上位１０（全260ツイート中） =======\n",
      "\n",
      "…………　類似ツイート1位：類似度 0.9956　…………\n",
      "\n",
      "イオンマスク禁止従業員の人嫌がるのわかるわ。\n",
      "\n",
      "インフルで出校停止中なんだけど薬効いて体元気だからイオン遊ばせに来た。\n",
      "みたいな事凄く多いんだよ。\n",
      "\n",
      "『店員が媒介にならないよう全店でマスク奨励してます。ご理解下さい』\n",
      "ってアナウンスされる方が余程良いのでイオンさん、マスク禁止撤回して\n",
      "\n",
      "【極性】： negative\n",
      "posi_score： 219.0 ／ nega_score： 257.0\n",
      "\n",
      "…………　類似ツイート2位：類似度 0.9705　…………\n",
      "\n",
      "マスクせずに咳してる人見ると、\n",
      "「感染者だ！撃ち殺せ！」\n",
      "「ですが！アイツはまだ人間じゃないですか！」\n",
      "「馬鹿野郎！ここで殺らなきゃ、俺達の大事な奴まで感染者にされる可能性だってあるんだ！迷うな！引き金を引け！」\n",
      "「畜生！感染者め！」\n",
      "みたいな気持ちになる。マスクしやがり下さい。\n",
      "\n",
      "【極性】： negative\n",
      "posi_score： 119.0 ／ nega_score： 213.0\n",
      "\n",
      "…………　類似ツイート3位：類似度 0.9566　…………\n",
      "\n",
      "ご飯が出てくるのをいい子にして待ってますみたいな顔してるけど、そもそもそこはあなたの席ではありません https://t.co/o67uS6sBAq\n",
      "\n",
      "【極性】： positive\n",
      "posi_score： 84.0 ／ nega_score： 24.0\n",
      "\n",
      "…………　類似ツイート4位：類似度 0.9501　…………\n",
      "\n",
      "コミックマーケットでは深夜来場は認めておりません。絶対に深夜来場をしないようにお願いします。すみやかにお帰り下さい。 #C97 \n",
      "\n",
      "【極性】： negative\n",
      "posi_score： 70.0 ／ nega_score： 99.0\n",
      "\n",
      "…………　類似ツイート5位：類似度 0.9481　…………\n",
      "\n",
      "スマホに慣れてないお年寄りはiPhoneを選んだほうがいいです。楽々スマホとか買われると、僕らが使い方分からないので使い方を聞かれても教えてあげられません。設定とかアプリ一覧を出すのにも一苦労でした。マジで楽々スマホはやめて。使い方を誰かに聞くつもりなら絶対買っちゃダメ。\n",
      "\n",
      "【極性】： positive\n",
      "posi_score： 190.0 ／ nega_score： 157.0\n",
      "\n",
      "…………　類似ツイート6位：類似度 0.9447　…………\n",
      "\n",
      "詩織さんに関して「もう女と酒を飲まない方が良い。これで少子化が進みそう」とリプしたおじさん、限界過ぎ。\n",
      "女と酒飲む＝性行為という認識が誤りだし、合意の無い性行為＝強姦だと理解してなさそうなのも危険。全てを間違えているが、君が”もう女と酒を飲まない方が良い”という決意だけは正しいよ。\n",
      "\n",
      "【極性】： negative\n",
      "posi_score： 123.0 ／ nega_score： 139.0\n",
      "\n",
      "…………　類似ツイート7位：類似度 0.9336　…………\n",
      "\n",
      "お客様に言いたいのは、店員にマスクをしてほしくないなら、お客様がしてくれと言うことと、ポイントカードの有無も答えず、キャッシュ決済で払も無言でスマホだけレジ台に置く、会計時イヤホン外さない、こういう人は、「何言ってるか聞こえない」なんて言う権利ないからな！\n",
      "＃マスク禁止\n",
      "\n",
      "【極性】： negative\n",
      "posi_score： 105.0 ／ nega_score： 118.0\n",
      "\n",
      "…………　類似ツイート8位：類似度 0.9303　…………\n",
      "\n",
      "「この小学生の体力が低下（特に小5男子）」っていうニュース、役所は原因を「スマホ」「ゲーム」に求めているけど、そもそも公園での子供の声が「騒音」扱いされるような不寛容な社会で、わざわざ外で遊ぼうって思わないよね。球技も禁止の公園も多いし。 \n",
      "\n",
      "【極性】： positive\n",
      "posi_score： 126.0 ／ nega_score： 124.0\n",
      "\n",
      "…………　類似ツイート9位：類似度 0.9179　…………\n",
      "\n",
      "いまテレビで『子どもが泣いてる→妻は家事で手が離せない→こんな時、夫は「子どもが泣いてるよ」ではなく「こういう時ママじゃないと泣き止まないんだよね〜」と言えば、妻をイラッとさせません』とか言ってるんですが！いや、めちゃめちゃイラッとするわ！泣き止まなくてもやるんだよ！！！！！！\n",
      "\n",
      "【極性】： negative\n",
      "posi_score： 115.0 ／ nega_score： 124.0\n",
      "\n",
      "…………　類似ツイート10位：類似度 0.9167　…………\n",
      "\n",
      "夫の胃がんを治すために医学的根拠のない治療に多額のお金を注ぎ込んだ轟さんの言葉。\n",
      "\n",
      "「子どもの頃から『新聞を読みなさい』『本を読みなさい』と言われて育ちました。そこに信頼できない情報が溢れているとは思ってもみませんでした」\n",
      "\n",
      "これは本当に、重く受け止めるべきだと思う。\n",
      "\n",
      "【極性】： positive\n",
      "posi_score： 283.0 ／ nega_score： 219.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#類似判定と類似している上位10件の文書を出力\n",
    "\n",
    "top10 = m.docvecs.most_similar(len(trainings) - 1)\n",
    "\n",
    "print(\"=========== 判定したいツイート ===========\\n\")\n",
    "print(similar)\n",
    "\n",
    "print()\n",
    "print(\"======= 類似度上位１０（全{}ツイート中） =======\".format(len(trainings)))\n",
    "print()\n",
    "for i in range(len(top10)):\n",
    "    score = top10[i]\n",
    "    index = int(score[0])\n",
    "    similar_score = score[1]\n",
    "    tweet = df_tweet[\"Full_text\"]\n",
    "    judge = df_tweet[\"Judge\"]\n",
    "    posi_score = df_tweet[\"Posi_score\"]\n",
    "    nega_score = df_tweet[\"Nega_score\"]\n",
    "    print(\"…………　類似ツイート{}位：類似度 {:.4g}　…………\".format((i+1), similar_score))\n",
    "    print()\n",
    "    print(tweet[index])\n",
    "    print()\n",
    "    print(\"【極性】：\", judge[index])\n",
    "    print(\"posi_score：\",posi_score[index], \"／\", \"nega_score：\", nega_score[index])\n",
    "\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# その他試みたこと\n",
    "断念、または精度が全く良くない。覚書として記録"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## １）文章ベクトルを特徴量としたネガポジ予測モデル\n",
    "　・文章ベクトルとフォロワー数を特徴量X、ネガポジスコアを目的変数yとしたデータを学習<br>\n",
    "　・文章ベクトルはDoc２vecとTf-idfの２種を作成<br>\n",
    "　・ツイート予定文書を入力してネガポジスコアを予測する<br>\n",
    "　・試した予測モデル<br>\n",
    "　・MultiOutputRegressor、SVRのrbf と　SVRの線形、lightgbm、ランダムフォレスト<br>\n",
    "#### 結果：精度が低すぎて断念<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2vecで文章ベクトル取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ベクトル化するセンチメントスコア付きデータ数： 314\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Followers</th>\n",
       "      <th>Full_text</th>\n",
       "      <th>Nega_score</th>\n",
       "      <th>Posi_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6800.0</td>\n",
       "      <td>君、すごい食い方やな\\n https://t.co/yRTGvd43wT</td>\n",
       "      <td>31.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1564.0</td>\n",
       "      <td>絶対断らないと評判の病児保育室、助成金下りず2億円の赤字を出し閉鎖\\n\\n全国に2886カ所...</td>\n",
       "      <td>148.0</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2217.0</td>\n",
       "      <td>全国の皆さんへ\\nどうか皆様のお力を貸してください。\\n\\n１日も早く娘を助けたいです。\\n...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3756.0</td>\n",
       "      <td>o0( 歴史上、さんざん他国の料理を魔改造してきた我が国が「寿司ポリス」などどは片腹痛い！あ...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7363.0</td>\n",
       "      <td>百合関係図です。 https://t.co/hZxIYOsSag</td>\n",
       "      <td>58.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Followers                                          Full_text  Nega_score  \\\n",
       "0     6800.0               君、すごい食い方やな\\n https://t.co/yRTGvd43wT        31.0   \n",
       "1     1564.0  絶対断らないと評判の病児保育室、助成金下りず2億円の赤字を出し閉鎖\\n\\n全国に2886カ所...       148.0   \n",
       "2     2217.0  全国の皆さんへ\\nどうか皆様のお力を貸してください。\\n\\n１日も早く娘を助けたいです。\\n...        50.0   \n",
       "3     3756.0  o0( 歴史上、さんざん他国の料理を魔改造してきた我が国が「寿司ポリス」などどは片腹痛い！あ...        85.0   \n",
       "4     7363.0                   百合関係図です。 https://t.co/hZxIYOsSag        58.0   \n",
       "\n",
       "   Posi_score  \n",
       "0        75.0  \n",
       "1       168.0  \n",
       "2       129.0  \n",
       "3       137.0  \n",
       "4        82.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Doc2vecでベクトル化\n",
    "from natto import MeCab\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df_buzz = pd.read_csv('./output/buzz_tweet.csv',\n",
    "                      usecols = [\"Full_text\", \"Posi_score\", \"Nega_score\", \"Followers\"])\n",
    "#.to_csv('./output/for_training.csv', mode = \"a\", index = False, header = None)\n",
    "#pd.read_csv('./output/fire_buzz_tweet.csv', usecols = [\"Full_text\", \"Judge\", \"Sentiment\"]).to_csv('./output/for_training.csv', mode = \"a\", index = False, header = None)\n",
    "print(\"ベクトル化するセンチメントスコア付きデータ数：\", len(df_buzz))\n",
    "display(df_buzz.head())\n",
    "\n",
    "#doc2vecでベクトル化\n",
    "for_training = df_buzz['Full_text']\n",
    "#print(for_training)\n",
    "vector_tweet = []\n",
    "for i in for_training:\n",
    "    i = m.infer_vector(i)\n",
    "    vector_tweet.append(i)\n",
    "\n",
    "df_vector = pd.DataFrame(data = vector_tweet)\n",
    "\n",
    "# print(\"Doc2vecベクトル\")\n",
    "# display(df_vector.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idfでベクトル取得\n",
    "#### 参考サイト\n",
    "\n",
    "機械学習_サポートベクターマシーン_pythonで実装<br>\n",
    "https://dev.classmethod.jp/machine-learning/2017ad_20171214_svm_python/<br>\n",
    "Tf-idfベクトルってなんだ？<br> https://qiita.com/MasatoTsutsumi/items/5b0a140b1ecbdd0396e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(314, 2080)\n",
      "次元削減後の特徴量が5の時の説明できる分散の割合合計は0.04です\n",
      "次元削減後の特徴量が10の時の説明できる分散の割合合計は0.06です\n",
      "次元削減後の特徴量が50の時の説明できる分散の割合合計は0.19です\n",
      "次元削減後の特徴量が100の時の説明できる分散の割合合計は0.35です\n",
      "次元削減後の特徴量が500の時の説明できる分散の割合合計は1.0です\n",
      "次元削減後の特徴量が1000の時の説明できる分散の割合合計は1.0です\n",
      "\n",
      "次元削減後Tf-idf\n",
      " (314, 314)\n"
     ]
    }
   ],
   "source": [
    "# 2-1.tf-idf計算\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def Stop_Words():\n",
    "    # ストップワードをダウンロード\n",
    "    url = 'http://svn.sourceforge.jp/svnroot/slothlib/CSharp/Version1/SlothLib/NLP/Filter/StopWord/word/Japanese.txt'\n",
    "    urllib.request.urlretrieve(url, './output/stop_word.txt')\n",
    "\n",
    "    with open('./output/stop_word.txt', 'r', encoding='utf-8') as file:\n",
    "        stopwords = [word.replace('\\n', '') for word in file.readlines()]\n",
    "\n",
    "    #追加ストップワードを設定（助詞や意味のない平仮名１文字）\n",
    "    add_words = ['あ','い','う','え','お','か','き','く','け','こ','さ','し','す','せ','そ','た','ち','つ','て','と',\n",
    "                 'な','に','ぬ','ね','の','は','ひ','ふ','へ','ほ','ま','み','む','め','も','や','ゆ','よ',\n",
    "                 'ら','り','る','れ','ろ','わ','を','ん','が','ぎ','ぐ','げ','ご','ざ','じ','ず','ぜ','ぞ',\n",
    "                 'だ','ぢ','づ','で','ど','ば','び','ぶ','べ','ぼ','ぱ','ぴ','ぷ','ぺ','ぽ',\n",
    "                 'くん','です','ます','ました','そして','でも','だから','だが','くらい','その','それ','かも',\n",
    "                 'あれ','あの','あっ','そんな','この','これ','とか','とも','する','という','ござい',\n",
    "                 'ので','なんて','たら', 'られ','たい','さて','てる','ください','なる','けど','でし',\n",
    "                 'じゃん','だっ','なっ','でしょ', 'ある','って','こんな','ねえ'\n",
    "                ]\n",
    "    stopwords = stopwords + add_words\n",
    "    return stopwords\n",
    "\n",
    "stopwords = Stop_Words()\n",
    "tfidfv = TfidfVectorizer(lowercase=True, stop_words=stopwords) # stop words処理\n",
    " \n",
    "tfv_vector_fit = tfidfv.fit(for_training)\n",
    "tfv_vector = tfv_vector_fit.transform(for_training)\n",
    "print(tfv_vector.shape) \n",
    "\n",
    "# 2-2.次元削減(「lsa」を使って次元削減を行う)\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# 2-2-1.パラメータの調整\n",
    "list_n_comp = [5,10,50,100,500,1000] # 特徴量を何個に削減するか、というパラメータです。できるだけ情報量を欠損しないで、かつ次元数は少なくしたいですね。\n",
    "for i in list_n_comp:\n",
    "    lsa = TruncatedSVD(n_components=i,n_iter=5, random_state = 0)\n",
    "    lsa.fit(tfv_vector) \n",
    "    tfv_vector_lsa = lsa.transform(tfv_vector)\n",
    "    print('次元削減後の特徴量が{0}の時の説明できる分散の割合合計は{1}です'.format(i,round((sum(lsa.explained_variance_ratio_)),2)))\n",
    "\n",
    "# 2-2-2.次元削減した状態のデータを作成\n",
    "# 上記で確認した「n_components」に指定した上で、次元削減（特徴抽出）を行う\n",
    "lsa = TruncatedSVD(n_components=1000, n_iter=5, random_state = 0) # 今回は次元数を1000に指定\n",
    "lsa.fit(tfv_vector)\n",
    "X_tf = lsa.transform(tfv_vector)\n",
    "print()\n",
    "print(\"次元削減後Tf-idf\\n\", X_tf.shape)\n",
    "# print(X_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "欠損値削除前データ (314, 4)\n",
      "\n",
      "Doc2vecベクトル\n",
      "X.shape (313, 301)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Followers</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6800.0</td>\n",
       "      <td>0.044237</td>\n",
       "      <td>0.006614</td>\n",
       "      <td>-0.004481</td>\n",
       "      <td>0.002282</td>\n",
       "      <td>0.006894</td>\n",
       "      <td>-0.020148</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>-0.004062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004183</td>\n",
       "      <td>0.001240</td>\n",
       "      <td>-0.002830</td>\n",
       "      <td>-0.013471</td>\n",
       "      <td>-0.004763</td>\n",
       "      <td>-0.005556</td>\n",
       "      <td>-0.000695</td>\n",
       "      <td>0.018570</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.013421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1564.0</td>\n",
       "      <td>0.021653</td>\n",
       "      <td>0.013749</td>\n",
       "      <td>-0.009543</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>-0.005357</td>\n",
       "      <td>-0.013252</td>\n",
       "      <td>0.006427</td>\n",
       "      <td>-0.009228</td>\n",
       "      <td>-0.011012</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014017</td>\n",
       "      <td>0.011406</td>\n",
       "      <td>-0.008416</td>\n",
       "      <td>-0.024405</td>\n",
       "      <td>0.006039</td>\n",
       "      <td>0.017866</td>\n",
       "      <td>-0.006516</td>\n",
       "      <td>0.029692</td>\n",
       "      <td>0.010832</td>\n",
       "      <td>-0.000753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2217.0</td>\n",
       "      <td>0.017007</td>\n",
       "      <td>-0.009793</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>0.007482</td>\n",
       "      <td>-0.005318</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.015223</td>\n",
       "      <td>0.004249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005082</td>\n",
       "      <td>-0.005141</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.004736</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>-0.011970</td>\n",
       "      <td>0.007723</td>\n",
       "      <td>0.003055</td>\n",
       "      <td>-0.001900</td>\n",
       "      <td>0.005666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3756.0</td>\n",
       "      <td>0.034133</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>-0.020453</td>\n",
       "      <td>0.009534</td>\n",
       "      <td>0.005748</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>-0.001702</td>\n",
       "      <td>-0.012427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006745</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>-0.012102</td>\n",
       "      <td>-0.006678</td>\n",
       "      <td>0.006020</td>\n",
       "      <td>0.004849</td>\n",
       "      <td>-0.003342</td>\n",
       "      <td>0.043429</td>\n",
       "      <td>0.013293</td>\n",
       "      <td>-0.020528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7363.0</td>\n",
       "      <td>0.037321</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>-0.004327</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>-0.011221</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>-0.003090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000518</td>\n",
       "      <td>-0.002960</td>\n",
       "      <td>-0.002879</td>\n",
       "      <td>-0.005011</td>\n",
       "      <td>-0.000959</td>\n",
       "      <td>-0.006872</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.008270</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.010751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Followers         0         1         2         3         4         5  \\\n",
       "0     6800.0  0.044237  0.006614 -0.004481  0.002282  0.006894 -0.020148   \n",
       "1     1564.0  0.021653  0.013749 -0.009543  0.000559 -0.005357 -0.013252   \n",
       "2     2217.0  0.017007 -0.009793  0.001088 -0.000226  0.007482 -0.005318   \n",
       "3     3756.0  0.034133  0.007313  0.003982 -0.020453  0.009534  0.005748   \n",
       "4     7363.0  0.037321  0.001495 -0.004327  0.002138  0.000906 -0.011221   \n",
       "\n",
       "          6         7         8    ...          290       291       292  \\\n",
       "0  0.007267  0.002130 -0.004062    ...    -0.004183  0.001240 -0.002830   \n",
       "1  0.006427 -0.009228 -0.011012    ...    -0.014017  0.011406 -0.008416   \n",
       "2  0.000894  0.015223  0.004249    ...     0.005082 -0.005141  0.001650   \n",
       "3  0.013575 -0.001702 -0.012427    ...     0.006745  0.000688 -0.012102   \n",
       "4  0.003346  0.004739 -0.003090    ...    -0.000518 -0.002960 -0.002879   \n",
       "\n",
       "        293       294       295       296       297       298       299  \n",
       "0 -0.013471 -0.004763 -0.005556 -0.000695  0.018570  0.001780  0.013421  \n",
       "1 -0.024405  0.006039  0.017866 -0.006516  0.029692  0.010832 -0.000753  \n",
       "2  0.004736  0.002359 -0.011970  0.007723  0.003055 -0.001900  0.005666  \n",
       "3 -0.006678  0.006020  0.004849 -0.003342  0.043429  0.013293 -0.020528  \n",
       "4 -0.005011 -0.000959 -0.006872  0.000163  0.008270  0.002082  0.010751  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tf-idfベクトル\n",
      "X_tf_idf.shape (313, 315)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Followers</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>304</th>\n",
       "      <th>305</th>\n",
       "      <th>306</th>\n",
       "      <th>307</th>\n",
       "      <th>308</th>\n",
       "      <th>309</th>\n",
       "      <th>310</th>\n",
       "      <th>311</th>\n",
       "      <th>312</th>\n",
       "      <th>313</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6800.0</td>\n",
       "      <td>0.291749</td>\n",
       "      <td>-0.000446</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>-0.002688</td>\n",
       "      <td>-5.854492e-17</td>\n",
       "      <td>-0.005929</td>\n",
       "      <td>-0.011303</td>\n",
       "      <td>-0.006528</td>\n",
       "      <td>-0.012403</td>\n",
       "      <td>...</td>\n",
       "      <td>1.418343e-16</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>-0.003893</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>-0.000123</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-3.550105e-17</td>\n",
       "      <td>-0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1564.0</td>\n",
       "      <td>0.174048</td>\n",
       "      <td>-0.000272</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>-0.001692</td>\n",
       "      <td>2.058179e-16</td>\n",
       "      <td>-0.003940</td>\n",
       "      <td>-0.007557</td>\n",
       "      <td>-0.004394</td>\n",
       "      <td>-0.008351</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.474998e-16</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-1.640593e-17</td>\n",
       "      <td>-0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2217.0</td>\n",
       "      <td>0.108983</td>\n",
       "      <td>-0.000176</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-0.001153</td>\n",
       "      <td>4.200301e-16</td>\n",
       "      <td>-0.002961</td>\n",
       "      <td>-0.005744</td>\n",
       "      <td>-0.003388</td>\n",
       "      <td>-0.006440</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.162642e-17</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>-0.001072</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>3.606252e-17</td>\n",
       "      <td>-0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3756.0</td>\n",
       "      <td>0.111211</td>\n",
       "      <td>-0.000175</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.001101</td>\n",
       "      <td>-1.461114e-16</td>\n",
       "      <td>-0.002614</td>\n",
       "      <td>-0.005025</td>\n",
       "      <td>-0.002930</td>\n",
       "      <td>-0.005568</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.293239e-16</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>-0.001245</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>4.578045e-17</td>\n",
       "      <td>-0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7363.0</td>\n",
       "      <td>0.291749</td>\n",
       "      <td>-0.000446</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>-0.002688</td>\n",
       "      <td>-1.506355e-16</td>\n",
       "      <td>-0.005929</td>\n",
       "      <td>-0.011303</td>\n",
       "      <td>-0.006528</td>\n",
       "      <td>-0.012403</td>\n",
       "      <td>...</td>\n",
       "      <td>3.806199e-17</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>-0.003893</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>-0.000123</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>1.248560e-16</td>\n",
       "      <td>-0.000026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 315 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Followers         0         1         2         3             4         5  \\\n",
       "0     6800.0  0.291749 -0.000446 -0.000145 -0.002688 -5.854492e-17 -0.005929   \n",
       "1     1564.0  0.174048 -0.000272 -0.000091 -0.001692  2.058179e-16 -0.003940   \n",
       "2     2217.0  0.108983 -0.000176 -0.000061 -0.001153  4.200301e-16 -0.002961   \n",
       "3     3756.0  0.111211 -0.000175 -0.000059 -0.001101 -1.461114e-16 -0.002614   \n",
       "4     7363.0  0.291749 -0.000446 -0.000145 -0.002688 -1.506355e-16 -0.005929   \n",
       "\n",
       "          6         7         8    ...              304       305       306  \\\n",
       "0 -0.011303 -0.006528 -0.012403    ...     1.418343e-16 -0.000029 -0.000063   \n",
       "1 -0.007557 -0.004394 -0.008351    ...    -2.474998e-16 -0.000015 -0.000032   \n",
       "2 -0.005744 -0.003388 -0.006440    ...    -1.162642e-17 -0.000007 -0.000017   \n",
       "3 -0.005025 -0.002930 -0.005568    ...    -2.293239e-16 -0.000009 -0.000020   \n",
       "4 -0.011303 -0.006528 -0.012403    ...     3.806199e-17 -0.000029 -0.000063   \n",
       "\n",
       "        307       308       309       310       311           312       313  \n",
       "0  0.000957 -0.003893  0.000312 -0.000123  0.000033 -3.550105e-17 -0.000026  \n",
       "1  0.000496 -0.002028  0.000165 -0.000066  0.000018 -1.640593e-17 -0.000014  \n",
       "2  0.000261 -0.001072  0.000089 -0.000036  0.000010  3.606252e-17 -0.000008  \n",
       "3  0.000304 -0.001245  0.000102 -0.000041  0.000011  4.578045e-17 -0.000009  \n",
       "4  0.000957 -0.003893  0.000312 -0.000123  0.000033  1.248560e-16 -0.000026  \n",
       "\n",
       "[5 rows x 315 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "y.shape (313, 2)\n"
     ]
    }
   ],
   "source": [
    "#X、yデータを作成\n",
    "\n",
    "#Doc2vecのベクトルデータ\n",
    "print(\"欠損値削除前データ\", df_buzz.shape)\n",
    "print()\n",
    "\n",
    "#文書ベクトルを含んだdf\n",
    "df_buzz_vec = pd.concat([df_buzz, df_vector], axis=1)\n",
    "df_buzz_vec = df_buzz_vec.dropna(subset = [\"Followers\"])#欠損値行削除\n",
    "df_buzz_vec = df_buzz_vec.drop([ \"Full_text\", \"Nega_score\", \"Posi_score\"], axis=1)\n",
    "X = df_buzz_vec.values\n",
    "print(\"Doc2vecベクトル\")\n",
    "print(\"X.shape\", X.shape)\n",
    "display(df_buzz_vec.head())\n",
    "\n",
    "#tf-idfのベクトルデータ\n",
    "tf_df = pd.DataFrame(data = X_tf)\n",
    "tf_df = pd.concat([df_buzz, tf_df], axis=1)\n",
    "tf_df = tf_df.dropna(subset = [\"Followers\"])#欠損値行削除\n",
    "tf_df = tf_df.drop([ \"Full_text\", \"Nega_score\", \"Posi_score\"], axis=1)\n",
    "X_tf_idf = tf_df.values\n",
    "print(\"Tf-idfベクトル\")\n",
    "print(\"X_tf_idf.shape\", tf_df.shape)\n",
    "display(tf_df.head())\n",
    "\n",
    "#yデータ作成\n",
    "df_buzz = df_buzz.dropna(subset = [\"Followers\"])#y用に\"Followers\"の欠損行削除\n",
    "y = df_buzz.loc[:,['Posi_score', 'Nega_score']]#できればDateも特徴量に入れたい\n",
    "y_p = df_buzz['Posi_score']\n",
    "y_n = df_buzz['Nega_score']\n",
    "y = y.values\n",
    "print()\n",
    "print(\"y.shape\", y.shape)\n",
    "y_p = y_p.values\n",
    "y_n = y_n.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiOutputRegressorで複数の回帰¶\n",
    "#### 結果：D2vベクトルよりTf-idfがややマシ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正解\n",
      " [[  18.   46.]\n",
      " [  93.  125.]\n",
      " [  38.   41.]\n",
      " [ 110.   15.]\n",
      " [ 190.  157.]\n",
      " [ 140.  120.]\n",
      " [ 283.  219.]\n",
      " [  39.   48.]\n",
      " [ 114.   43.]\n",
      " [  21.    3.]\n",
      " [  59.   54.]\n",
      " [  13.    1.]\n",
      " [ 102.   81.]\n",
      " [ 180.   46.]\n",
      " [  73.  119.]\n",
      " [  71.   58.]\n",
      " [  35.   23.]\n",
      " [ 127.   89.]\n",
      " [  44.   30.]\n",
      " [  37.   49.]\n",
      " [  55.   61.]\n",
      " [ 122.   38.]\n",
      " [ 146.   61.]\n",
      " [  97.   78.]\n",
      " [  48.   37.]\n",
      " [ 160.  144.]\n",
      " [  94.   22.]\n",
      " [ 149.   50.]\n",
      " [  52.   15.]\n",
      " [  48.   39.]\n",
      " [ 247.   91.]\n",
      " [ 171.  121.]\n",
      " [ 125.   36.]\n",
      " [  68.   42.]\n",
      " [  73.   59.]\n",
      " [  94.   62.]\n",
      " [ 168.  197.]\n",
      " [  64.  143.]\n",
      " [  22.    4.]\n",
      " [  89.   95.]\n",
      " [  65.   79.]\n",
      " [ 205.   45.]\n",
      " [  50.   14.]\n",
      " [  44.   31.]\n",
      " [  19.   12.]\n",
      " [ 116.  142.]\n",
      " [  50.   19.]\n",
      " [  77.    5.]\n",
      " [ 126.  124.]\n",
      " [ 210.  169.]\n",
      " [ 103.   46.]\n",
      " [ 156.   20.]\n",
      " [  25.   27.]\n",
      " [  65.   43.]\n",
      " [ 118.  227.]\n",
      " [ 171.  214.]\n",
      " [  56.   23.]\n",
      " [ 114.  173.]\n",
      " [ 123.  139.]\n",
      " [  61.   46.]\n",
      " [ 117.   26.]\n",
      " [ 100.   79.]\n",
      " [  72.   42.]\n",
      " [  38.   42.]\n",
      " [ 166.  107.]\n",
      " [  88.   24.]\n",
      " [  85.   15.]\n",
      " [ 119.  150.]\n",
      " [ 141.   39.]\n",
      " [ 186.  106.]\n",
      " [  81.   14.]\n",
      " [  79.   49.]\n",
      " [  87.   16.]\n",
      " [ 266.   76.]\n",
      " [  95.   57.]\n",
      " [  53.   15.]\n",
      " [ 214.   86.]\n",
      " [  76.   46.]\n",
      " [ 120.   98.]\n",
      " [ 147.   72.]\n",
      " [  70.   99.]\n",
      " [ 122.   24.]\n",
      " [  45.   35.]\n",
      " [  44.   12.]\n",
      " [ 162.   81.]\n",
      " [ 128.   23.]\n",
      " [ 116.   83.]\n",
      " [ 116.   21.]\n",
      " [ 197.    9.]\n",
      " [  92.   76.]\n",
      " [ 345.  151.]\n",
      " [  63.   29.]\n",
      " [  90.  147.]\n",
      " [  84.   24.]]\n",
      "\n",
      "[[ 119.15244114  121.67927045]\n",
      " [  83.24055731   50.47490432]\n",
      " [ 128.78680807  110.56769648]\n",
      " [ 118.64701739   67.0857058 ]\n",
      " [  96.99954996   52.07172825]\n",
      " [ 121.25666793   52.42749802]\n",
      " [ 137.09384059   98.9866524 ]\n",
      " [ 154.54475172   56.68928863]\n",
      " [ 108.89686942   45.59549652]\n",
      " [  74.17869357   27.29400132]\n",
      " [  93.16979639   90.39608654]\n",
      " [ 136.50567471  101.7498277 ]\n",
      " [ 105.80605754   82.91530715]\n",
      " [  86.95234287   51.05168768]\n",
      " [  72.28709316   34.35302997]\n",
      " [ 102.03682726   37.4949765 ]\n",
      " [  68.25736342   36.2669656 ]\n",
      " [  52.88145696   51.14017729]\n",
      " [ 114.53630215  112.74432217]\n",
      " [  76.91333821   93.60644455]\n",
      " [ 102.57733508   61.27483579]\n",
      " [ 134.34043248   74.01036944]\n",
      " [ 103.74501078   37.11069309]\n",
      " [  98.47127142   42.62744428]\n",
      " [ 111.42253377   85.91986212]\n",
      " [ 162.47668927  173.12244154]\n",
      " [ 108.73847862   36.80654163]\n",
      " [ 165.6817818    26.30064684]\n",
      " [  93.16532811   59.85501711]\n",
      " [  74.30076      55.6488022 ]\n",
      " [  85.10957166   69.07430079]\n",
      " [ 107.40761305   57.11537381]\n",
      " [  80.03602888   55.48788843]\n",
      " [  90.48754876  115.08412757]\n",
      " [ 104.42902216   64.22328006]\n",
      " [  58.49434282   40.59109821]\n",
      " [ 116.80040754   97.91467825]\n",
      " [  97.2459128    56.53073364]\n",
      " [ 161.26116582   23.97000812]\n",
      " [  99.12848048   53.68938038]\n",
      " [ 114.52369886  100.17957394]\n",
      " [ 114.49668559   40.50719265]\n",
      " [ 117.15390742   32.72674619]\n",
      " [ 112.23112865  191.95118316]\n",
      " [  92.73355349   70.57673528]\n",
      " [  99.81223737   42.55855671]\n",
      " [  95.57205567   80.46686954]\n",
      " [ 157.72728719   92.72431738]\n",
      " [  58.90097296   44.40486886]\n",
      " [  86.36844274   54.61724423]\n",
      " [ 124.57428454   44.95927419]\n",
      " [ 116.37134191   61.39998456]\n",
      " [ 116.22856657   42.75074726]\n",
      " [  94.66533582   64.02645098]\n",
      " [ 109.42906064   64.68996867]\n",
      " [  79.61610574   75.03942488]\n",
      " [ 125.17901984   51.9727222 ]\n",
      " [ 133.84951094   98.3593404 ]\n",
      " [ 115.15080698  165.63836904]\n",
      " [ 190.06734429  151.68665444]\n",
      " [  77.41916555   40.47473191]\n",
      " [  90.29580249   42.25828511]\n",
      " [ 138.008774     90.51058524]\n",
      " [ 135.26020105   87.10232396]\n",
      " [ 156.19430451   77.58827633]\n",
      " [ 109.96777378  101.74210128]\n",
      " [ 101.25583172  120.48250012]\n",
      " [ 103.88349549   43.61599348]\n",
      " [  96.29280427   19.96308244]\n",
      " [ 125.40982561   55.79268118]\n",
      " [ 104.78141919   53.08246076]\n",
      " [  90.24095583   53.11411168]\n",
      " [  85.09560964   50.30192916]\n",
      " [ 101.37742053   34.06671392]\n",
      " [ 105.39169875   57.99856869]\n",
      " [  81.76003467   46.83462535]\n",
      " [ 146.82252083   44.10761257]\n",
      " [ 130.31087452   76.72147917]\n",
      " [ 125.79960394   61.55544523]\n",
      " [ 131.48093486   78.86537191]\n",
      " [  96.83521489  101.95921861]\n",
      " [ 100.34052166   61.41785765]\n",
      " [ 120.04680802   32.21895015]\n",
      " [ 111.41589983   52.32868541]\n",
      " [ 101.00397454   65.05689833]\n",
      " [ 152.86628016   71.83997983]\n",
      " [ 121.53775511   93.21036525]\n",
      " [ 101.73047454   46.11832119]\n",
      " [ 100.70295138   27.11986355]\n",
      " [ 101.16858309   92.8428081 ]\n",
      " [  98.92942459   85.4301724 ]\n",
      " [ 105.13921857   57.50451467]\n",
      " [  88.5175172    51.73997499]\n",
      " [ 104.97762881  100.95366616]]\n",
      "R ^ 2_score(1に近いほど良い）： -0.191147570038\n",
      "\n",
      "[[ 130.58206333   54.57539106]\n",
      " [ 112.45074221   60.76867342]\n",
      " [ 140.24574556   72.00124324]\n",
      " [  94.72026991   30.1093057 ]\n",
      " [ 109.5905981    73.4942852 ]\n",
      " [ 104.43046814   44.55384142]\n",
      " [  99.96902414   95.10916193]\n",
      " [ 102.74646303   74.97358073]\n",
      " [  93.46382228   25.16045617]\n",
      " [  90.65679214   41.52996232]\n",
      " [ 111.72136308   72.13143499]\n",
      " [  90.65679214   41.52996232]\n",
      " [ 123.05929063   54.09145556]\n",
      " [  90.59025187   49.05281791]\n",
      " [  83.21155964  130.08939643]\n",
      " [ 102.62503722   45.80450537]\n",
      " [ 105.52675506   32.46684625]\n",
      " [ 138.14502421  123.2939004 ]\n",
      " [ 137.36161482   54.69584086]\n",
      " [  90.61349698   25.60148723]\n",
      " [  94.50767427   81.99947708]\n",
      " [  64.0277682    67.56784995]\n",
      " [ 124.68266664   64.70925841]\n",
      " [  83.99522815   80.06695948]\n",
      " [ 147.11315357   70.82559832]\n",
      " [ 102.19497593   98.2803182 ]\n",
      " [  95.53035925   41.60921612]\n",
      " [ 114.30151923   52.93510379]\n",
      " [  85.88786833   46.60211921]\n",
      " [ 127.81312419   62.43968835]\n",
      " [  90.7685037    38.58325227]\n",
      " [ 112.4245039   126.06259727]\n",
      " [ 133.90560064   59.8988903 ]\n",
      " [  93.638733     44.32686288]\n",
      " [ 138.24054108   31.77992925]\n",
      " [  83.21053919   44.5202385 ]\n",
      " [  66.79260303   48.57791124]\n",
      " [ 103.7521299    67.55605879]\n",
      " [  90.65679214   41.52996232]\n",
      " [ 109.37972402   32.69369005]\n",
      " [  90.27182403   49.5652837 ]\n",
      " [  76.93328631   56.9615835 ]\n",
      " [  76.5601186    57.41817246]\n",
      " [  82.00353646   45.6750775 ]\n",
      " [  99.17275724  115.27004669]\n",
      " [  68.04405359   64.97486251]\n",
      " [ 107.44302254   90.26786054]\n",
      " [  90.24084299   56.1863666 ]\n",
      " [ 134.82823637   66.14768219]\n",
      " [ 120.3075979    64.18568788]\n",
      " [ 130.71354719   77.24489793]\n",
      " [ 100.66984523   35.47449539]\n",
      " [ 130.17918928   91.21011092]\n",
      " [ 105.83772629   97.61225167]\n",
      " [  89.3092944    35.49550685]\n",
      " [  86.59812662   70.42051571]\n",
      " [ 113.06732058   64.22359996]\n",
      " [  84.21898908   88.90059896]\n",
      " [ 133.95866273   60.80340238]\n",
      " [  92.09400472  108.64635158]\n",
      " [  91.48854671   49.73604529]\n",
      " [ 103.1457212    66.89113414]\n",
      " [ 116.76021603   37.78982646]\n",
      " [  86.07727779   71.24532924]\n",
      " [ 130.14487743  102.12994368]\n",
      " [  96.02839433   36.31400583]\n",
      " [  89.13260445   32.37425823]\n",
      " [ 104.48605781   65.22340592]\n",
      " [ 153.00713928   28.08350439]\n",
      " [ 106.25687324   44.99193441]\n",
      " [ 123.64725636   70.47240975]\n",
      " [  95.24420283   58.18687983]\n",
      " [  54.38279681   49.47624002]\n",
      " [  71.80514366   60.02015883]\n",
      " [ 105.72358783   43.43052303]\n",
      " [  79.2581444    63.56195635]\n",
      " [ 157.09518739   58.59001203]\n",
      " [  87.38720852  103.47094991]\n",
      " [ 119.13997679   93.12563141]\n",
      " [  80.47423748   91.09278111]\n",
      " [  90.65679214   43.51246578]\n",
      " [  70.32854464   21.28554516]\n",
      " [  95.48575333   42.76636749]\n",
      " [ 115.22162552   55.89764666]\n",
      " [  89.0455939    48.05156298]\n",
      " [ 119.41316076   33.59756354]\n",
      " [ 106.18231091   51.73549487]\n",
      " [ 142.42842063   58.07898312]\n",
      " [ 142.06804769  129.30191722]\n",
      " [ 117.5871007   115.58912183]\n",
      " [  96.108604     85.8360315 ]\n",
      " [  80.20685579   41.82087859]\n",
      " [  87.04344074   95.8441783 ]\n",
      " [  88.74794674   78.86370113]]\n",
      "R ^ 2_score(1に近いほど良い）： -0.0594342505577\n"
     ]
    }
   ],
   "source": [
    "#MultiOutputRegressorで複数の回帰\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#D2vベクトル\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.7, test_size=0.3, random_state=0)\n",
    "\n",
    "#X, y = make_regression(n_samples=10, n_targets=3, random_state=1)\n",
    "MOR = MultiOutputRegressor(GradientBoostingRegressor(random_state=0)).fit(X_train, y_train)\n",
    "y_pred = MOR.predict(X_test)\n",
    "score = MOR.score(X_test, y_test)\n",
    "\n",
    "print(\"正解\\n\", y_test)\n",
    "print()\n",
    "print(y_pred)\n",
    "print(\"R ^ 2_score(1に近いほど良い）：\", score)\n",
    "print()\n",
    "\n",
    "#X_tf tf-idfベクトルを使った予測\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tf_idf, y, train_size=0.7, test_size=0.3, random_state=0)\n",
    "\n",
    "MOR = MultiOutputRegressor(GradientBoostingRegressor(random_state=0)).fit(X_train, y_train)\n",
    "y_pred = MOR.predict(X_test)\n",
    "score = MOR.score(X_test, y_test)\n",
    "print(y_pred)\n",
    "print(\"R ^ 2_score(1に近いほど良い）：\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVRのrbf と　SVRの線形で予測\n",
    "#### 結果：予測値が全くダメ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF: RMSE（０に近いほど良い） 63.28208955684835 \n",
      "Linear: RMSE（０に近いほど良い） 635.1003506204574\n",
      "\n",
      "正解 [  18.   93.   38.  110.  190.  140.  283.   39.  114.   21.   59.   13.\n",
      "  102.  180.   73.   71.   35.  127.   44.   37.   55.  122.  146.   97.\n",
      "   48.  160.   94.  149.   52.   48.  247.  171.  125.   68.   73.   94.\n",
      "  168.   64.   22.   89.   65.  205.   50.   44.   19.  116.   50.   77.\n",
      "  126.  210.  103.  156.   25.   65.  118.  171.   56.  114.  123.   61.\n",
      "  117.  100.   72.   38.  166.   88.   85.  119.  141.  186.   81.   79.\n",
      "   87.  266.   95.   53.  214.   76.  120.  147.   70.  122.   45.   44.\n",
      "  162.  128.  116.  116.  197.   92.  345.   63.   90.   84.]\n",
      "rbf推定 [ 91.18305705  91.58561873  91.58561873  91.58561873  90.68690313\n",
      "  91.58561873  91.58561873  91.58561873  91.58561873  91.58561873\n",
      "  91.58561872  91.58561873  91.58561873  91.99073469  91.66711441\n",
      "  91.58561873  91.58561873  93.12698319  91.61286514  91.58561873\n",
      "  91.58557377  91.58561873  91.58561873  91.58561873  91.58561873\n",
      "  91.58561873  91.58561873  91.58561873  91.58561873  91.8995833\n",
      "  91.58561873  91.58561873  91.5930527   91.66756372  91.58561873\n",
      "  91.58561873  91.58561931  91.58557357  91.58561873  91.58561873\n",
      "  91.58561873  91.58561873  91.58561873  90.9215229   91.58561873\n",
      "  91.58561873  91.58561873  91.58561873  91.58561873  91.58561873\n",
      "  91.58561873  91.58561873  91.58561873  91.58561873  91.58561873\n",
      "  91.58561868  91.58561873  91.58561873  91.58561873  90.92515097\n",
      "  91.58561873  91.58561873  91.58561819  90.68423431  92.48247459\n",
      "  91.58721432  90.60403736  91.58561873  92.48338533  91.58561873\n",
      "  91.58561873  90.92412298  91.58561873  91.58561873  91.58561873\n",
      "  91.58561873  91.58561873  91.58585449  90.93441431  91.58561873\n",
      "  90.61295448  91.58434165  91.58561873  91.58561873  91.58561873\n",
      "  91.58561873  91.58561873  91.58561873  91.58561873  91.58561873\n",
      "  91.58561873  91.58561873  91.58561873  91.58561873]\n",
      "lin推定 [  7.39250125e+01   7.34432296e+01   5.60973271e+01   7.32658873e+01\n",
      "   6.07050383e+01  -9.53617488e+02  -4.88872633e+01   6.61777826e+01\n",
      "  -7.42939033e+02  -5.58039963e+02   7.62540957e+01  -5.57671663e+02\n",
      "   7.30505914e+01   7.42331312e+01   7.64277203e+01  -1.92914900e+02\n",
      "   1.62189243e-01   7.55970451e+01   7.63252846e+01  -1.41007037e+01\n",
      "   7.45640166e+01   2.60534903e+01  -2.32421904e+02   5.18711407e+01\n",
      "   7.35410456e+01   4.59399183e+01  -4.10894515e+02  -1.06097038e+03\n",
      "   7.22882330e+01   4.84977379e+01  -1.85886327e+02   2.86753784e+01\n",
      "   6.29673416e+01   7.71361853e+01  -4.81913829e+01  -7.95951282e+02\n",
      "   7.49769059e+01   7.24962619e+01  -5.57637771e+02  -5.20410161e+02\n",
      "   2.89288005e+01   6.04482433e+01  -3.33352993e+02   7.45792267e+01\n",
      "  -2.25889781e+02   4.36579934e+01   6.39965327e+01  -1.13128593e+03\n",
      "   6.76594641e+01   3.23530771e+01  -6.35157313e+01  -5.73621593e+01\n",
      "  -2.26466116e+03   6.39437667e+01   7.62481456e+01   7.12664270e+01\n",
      "  -1.73887443e+03   6.60537930e+01   1.54536712e+01   7.73503329e+01\n",
      "   4.67850269e+01   6.75274555e+01   7.56540230e+01   7.54456647e+01\n",
      "   7.29382227e+01  -1.12418388e+02  -2.18920043e+03   6.54342445e+01\n",
      "  -5.74075035e+02   2.88420749e+01  -4.03144147e+02   6.03072785e+01\n",
      "   7.68535788e+01  -4.45167275e+02  -8.68136610e+02   3.90507964e+01\n",
      "  -3.85124674e+02   7.50705834e+01   7.81841544e+01   6.33430072e+01\n",
      "  -4.46686641e+02  -2.87253674e+03  -1.14208744e+02  -7.63121244e+02\n",
      "   7.02344300e+01  -2.08612496e+02   3.05183926e+01  -1.66861607e+03\n",
      "  -6.57950687e+01   4.35706633e+01   6.39303623e+01  -1.98956368e+01\n",
      "   7.51636500e+01   7.50098994e+01]\n"
     ]
    }
   ],
   "source": [
    "#ポジ、ネガ別々で予測する\n",
    "#SVRのrbf と　SVRの線形\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "#D2vベクトル(ポジのみ)\n",
    "X_train, X_test, y_p_train, y_p_test = train_test_split(\n",
    "    X, y_p, train_size=0.7, test_size=0.3, random_state=0)\n",
    "\n",
    "svr_rbf = SVR(kernel='rbf', C=1, gamma=0.1)\n",
    "svr_lin = SVR(kernel='linear', C=1)\n",
    "y_rbf = svr_rbf.fit(X_train, y_p_train)\n",
    "y_lin = svr_lin.fit(X_train, y_p_train)\n",
    "\n",
    "pred_rbf = svr_rbf.predict(X_test)\n",
    "pred_lin = svr_lin.predict(X_test)\n",
    "\n",
    "#精度\n",
    "\n",
    "# 相関係数計算\n",
    "rbf_corr = np.corrcoef(y_p_test, pred_rbf)[0, 1]\n",
    "lin_corr = np.corrcoef(y_p_test, pred_lin)[0, 1]\n",
    "\n",
    "# RMSEを計算（０に近いほど良い）\n",
    "rbf_rmse = sqrt(mean_squared_error(pred_rbf, y_p_test))\n",
    "lin_rmse = sqrt(mean_squared_error(pred_lin, y_p_test))\n",
    "\n",
    "print(\"RBF: RMSE（０に近いほど良い） {} \".format(rbf_rmse))\n",
    "print(\"Linear: RMSE（０に近いほど良い） {}\" .format(lin_rmse))\n",
    "print()\n",
    "print(\"正解\", y_p_test)\n",
    "print(\"rbf推定\", pred_rbf)\n",
    "print(\"lin推定\", pred_lin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightgbm\n",
    "#### 参考サイト\n",
    "\n",
    "Mercari Price Challenge -機械学習を使ったメルカリの価格予測 Ridge回帰 LightGBM\n",
    "\n",
    "http://rautaku.hatenablog.com/entry/2017/12/22/195649\n",
    "\n",
    "#### 結果：RMSEが0には程遠い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /opt/conda/lib/python3.6/site-packages (2.3.1)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from lightgbm) (0.19.1)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from lightgbm) (0.19.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from lightgbm) (1.13.3)\r\n"
     ]
    }
   ],
   "source": [
    "#必要なツールをインストール(初回のみ実行)\n",
    "! pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5000 rounds\n",
      "[500]\tvalid_0's rmse: 62.2081\n",
      "[1000]\tvalid_0's rmse: 62.2405\n",
      "[1500]\tvalid_0's rmse: 62.2444\n",
      "[2000]\tvalid_0's rmse: 62.2453\n",
      "[2500]\tvalid_0's rmse: 62.2454\n",
      "[3000]\tvalid_0's rmse: 62.2454\n",
      "[3500]\tvalid_0's rmse: 62.2454\n",
      "[4000]\tvalid_0's rmse: 62.2454\n",
      "[4500]\tvalid_0's rmse: 62.2454\n",
      "[5000]\tvalid_0's rmse: 62.2454\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's rmse: 59.5933\n",
      "RMSE（０に近いほど良い） 59.5933203655\n"
     ]
    }
   ],
   "source": [
    "#LightGBM を使った回帰予測(D2Vベクトル)\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def main():\n",
    "    #D2vベクトル(ポジのみ)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_p, train_size=0.7, test_size=0.3, random_state=0)\n",
    "\n",
    "    # データセットを生成する\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "    # LightGBM のハイパーパラメータ\n",
    "    lgbm_params = {\n",
    "        # 回帰問題\n",
    "        'objective': 'regression',\n",
    "        # RMSE (平均二乗誤差平方根) の最小化を目指す\n",
    "        'metric': 'rmse',\n",
    "    }\n",
    "\n",
    "    # 上記のパラメータでモデルを学習する\n",
    "    model = lgb.train(lgbm_params, lgb_train, \n",
    "                      valid_sets=lgb_eval, num_boost_round=8000, \n",
    "                      early_stopping_rounds=5000, verbose_eval=500)\n",
    "\n",
    "    # テストデータを予測する\n",
    "    y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "    # RMSE を計算する\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(\"RMSE（０に近いほど良い）\", rmse)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5000 rounds\n",
      "[500]\tvalid_0's rmse: 67.0909\n",
      "[1000]\tvalid_0's rmse: 67.1183\n",
      "[1500]\tvalid_0's rmse: 67.1202\n",
      "[2000]\tvalid_0's rmse: 67.1205\n",
      "[2500]\tvalid_0's rmse: 67.1206\n",
      "[3000]\tvalid_0's rmse: 67.1206\n",
      "[3500]\tvalid_0's rmse: 67.1206\n",
      "[4000]\tvalid_0's rmse: 67.1206\n",
      "[4500]\tvalid_0's rmse: 67.1206\n",
      "[5000]\tvalid_0's rmse: 67.1206\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's rmse: 60.8126\n",
      "RMSE（０に近いほど良い） 60.8125701284\n"
     ]
    }
   ],
   "source": [
    "#LightGBM を使った回帰予測（Tfーidfベクトル）\n",
    "\n",
    "def main():\n",
    "\n",
    "    #X_tf tf-idfベクトルを使った予測(ポジのみ)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_tf_idf, y_p, train_size=0.7, test_size=0.3, random_state=0)\n",
    "\n",
    "    # データセットを生成する\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "    # LightGBM のハイパーパラメータ\n",
    "    lgbm_params = {\n",
    "        # 回帰問題\n",
    "        'objective': 'regression',\n",
    "        # RMSE (平均二乗誤差平方根) の最小化を目指す\n",
    "        'metric': 'rmse',\n",
    "    }\n",
    "    \n",
    "    # 上記のパラメータでモデルを学習する\n",
    "    model = lgb.train(lgbm_params, lgb_train, \n",
    "                      valid_sets=lgb_eval, num_boost_round=8000, \n",
    "                      early_stopping_rounds=5000, verbose_eval=500)\n",
    "#     model = lgb.LGBMRegressor()\n",
    "#     model.fit(X_train, y_train)\n",
    "\n",
    "    # テストデータを予測する\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # RMSE を計算する\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(\"RMSE（０に近いほど良い）\",rmse)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ランダムフォレスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2(1に近いほど良い）: -0.0938475289851\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#D2vベクトル\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.7, test_size=0.3, random_state=0)\n",
    "# ランダムフォレスト回帰オブジェクト生成\n",
    "rfr = RandomForestRegressor(n_estimators=100)\n",
    "# 学習の実行\n",
    "rfr.fit(X_train, y_train)\n",
    "# テストデータで予測実行\n",
    "predict_y = rfr.predict(X_test)\n",
    "# R2決定係数で評価\n",
    "r2_score = r2_score(y_test, predict_y)\n",
    "print(\"R^2(1に近いほど良い）:\", r2_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ２）ツイッターAPI制限への挑戦（データセットの拡大）\n",
    "　・古いツイートを大量取得できるパッケージを発見（通常は１週間程度しか遡れない）<br>\n",
    "#### 結果：取得データから反応ツイートの取得を試みたができなかった<br>\n",
    "\n",
    "### GetOldTweets3 0.0.11\n",
    "古いツイートをトークン申請なしで大量取得できるパッケージ<br>\n",
    "https://pypi.org/project/GetOldTweets3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: GetOldTweets3 in /opt/conda/lib/python3.6/site-packages (0.0.11)\r\n",
      "Requirement already satisfied: pyquery>=1.2.10 in /opt/conda/lib/python3.6/site-packages (from GetOldTweets3) (1.4.1)\r\n",
      "Requirement already satisfied: lxml>=3.5.0 in /opt/conda/lib/python3.6/site-packages (from GetOldTweets3) (4.1.0)\r\n",
      "Requirement already satisfied: cssselect>0.7.9 in /opt/conda/lib/python3.6/site-packages (from pyquery>=1.2.10->GetOldTweets3) (1.1.0)\r\n"
     ]
    }
   ],
   "source": [
    "#必要なツールをインストール(初回のみ実行)\n",
    "! pip install GetOldTweets3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading tweets...\n",
      "Saved 1800^C\n",
      "\n",
      "Interrupted.\n",
      "\n",
      "\n",
      "Done. Output file generated \"./output/toptweets.csv\".\n"
     ]
    }
   ],
   "source": [
    "#指定日のトップツイートを取得、'./output/toptweets.csv'に保存\n",
    "! GetOldTweets3 --lang ja  --toptweets  --querysearch \"\" --since 2019-2-10 --until 2019-2-11 --output './output/toptweets.csv'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
