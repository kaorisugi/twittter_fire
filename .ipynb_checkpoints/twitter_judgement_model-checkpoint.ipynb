{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 極性判定とDoc２Vecを使ったTwitterネガポジ予測\n",
    "＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝\n",
    "### 【このnotebookについて】\n",
    "2019年7〜10月までフルタイムで通っていたスクールの卒業課題テーマを、機械学習の勉強のために発展させたものです<br>\n",
    "卒業発表スライド　https://www.slideshare.net/secret/y0m7g1nZdxpVYP<br>\n",
    "＊当初は炎上予測がテーマだったので、このnotebookの内容とはややズレます<br>\n",
    "＊表紙スライドの字が見えない場合は２枚目から戻ると見えます<br>\n",
    "\n",
    "＊ちなみに…<br>\n",
    "スクールで取り組んだ課題のリポジトリ \n",
    "https://github.com/kaorisugi/diveintocode-ml<br>\n",
    "論文読解課題のスライドシェア \n",
    "https://www.slideshare.net/secret/qGmdiwl4uGS20O<br>\n",
    "\n",
    "### 【ゴール】\n",
    "これからツイートする予定の文章に対し、過去の類似ツイートを探し、反応のネガポジスコア付きで上位１０位まで提示する。<br>\n",
    "### 【モデルの仕組み】\n",
    "１）ツイートデータセットを取得<br>\n",
    "　・TwitterAPIを使ってツイートを取得<br>\n",
    "　・各ツイートに対する反応ツイート（リプライ、引用RT）を取得<br>\n",
    "　・反応ツイートの極性表現数をカウントしてネガポジスコアとpositive/negative/fire!!!判定を得る<br>\n",
    " 　（positive/negativeの判定基準：極性表現数が多い方、fire!!!(炎上）の判定基準：極性表現の７０％以上がnegative）\n",
    "２）データセットの前処理<br>\n",
    "　・正規表現、ストップワード除去など<br>\n",
    "３）予測モデルを生成<br>\n",
    "　・データセットをDoc２vecで学習<br>\n",
    "４）ツイート予定文章のネガポジ予測を返す<br>\n",
    "　・データセットから、ツイート予定文書と似ている文書を探す<br>\n",
    " ・ネガポジスコア付きで、類似ツイート上位１０個を返す\n",
    "### 【結果】\n",
    "類似度確認用にデータセット内にあるものと同じ文を入力したところ、類似度1位で返ってきた。また、２位、３位にもマスクに関する似た話題のツイートが提示されたので類似ツイートの抽出は成功。ネガポジスコアもデータズレなどなく正確に表示され、目的は達成できた。<br>\n",
    "ツイッターAPI制限により、まだサンプルが少ない（完成時２００件程度）が、データを蓄積できる仕様にしているので、ツイート文のバリエーションを増やしていけば、様々な入力文に対応できるようになると思う。<br>\n",
    "ネガポジ判定については、ネガティブなテーマへの言及に共感したコメントでネガ判定が出ているケースも多く、必ずしもツイート主へのネガ感情ではないことに注意が必要。<br>\n",
    "\n",
    "### 【その他試みたこと】\n",
    "１）文章ベクトルを特徴量としたネガポジ予測モデル<br>\n",
    "　・文章ベクトルとフォロワー数を特徴量X、ネガポジスコアを目的変数yとしたデータを学習<br>\n",
    "　・文章ベクトルはDoc２vecとTf-idfの２種を作成<br>\n",
    "　・ツイート予定文書を入力してネガポジスコアを予測する<br>\n",
    "　・試した予測モデル<br>\n",
    "　・MultiOutputRegressor、SVRのrbf と　SVRの線形、lightgbm、ランダムフォレスト<br>\n",
    "　  　→精度が低すぎて断念<br>\n",
    "２）ツイッターAPI制限への挑戦（データセットの拡大）<br>\n",
    "　・古いツイートを大量取得できるパッケージを発見（通常は１週間程度しか遡れない）<br>\n",
    "　　　→取得データから反応ツイートの取得を試みたができなかった<br>\n",
    "   \n",
    "### 【利用するには】\n",
    "・config.py ファイルにツイッターAPIトークンを記入<br>\n",
    "・インストールが必要なツールは、notebook内にマジックコマンドにて記載してあります<br>\n",
    "・import MeCab で詰まる場合は、MeCabバインディングのnatto-pyからimportするとうまくいきそうです。<br>\n",
    "（$ pip install natto-pyでインストールした上でfrom natto import MeCab) <br>\n",
    "＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## １）ツイートデータセットを取得\n",
    "・TwitterAPIでツイートを取得<br>\n",
    "・各ツイートに対するリプライ、引用RTを取得<br>\n",
    "・極性表現数をカウントしてネガポジスコアを得る<br>\n",
    "\n",
    "#### 参考サイト\n",
    "【Python】tweepyでTwitterのツイートを検索して取得<br>\n",
    "https://vatchlog.com/tweepy-search/<br>\n",
    "【Python】tweepyで期間指定してツイートを検索する<br>\n",
    "https://vatchlog.com/tweepy-search-time/<br>\n",
    "バズったツイートへのリアクションを感情分析してみる<br>【Google Natural Language API / Python】<br>\n",
    "https://qiita.com/matsuri0828/items/029b4d0d510dcfb5c5dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /opt/conda/lib/python3.6/site-packages (19.3.1)\n",
      "Requirement already satisfied: tweepy in /opt/conda/lib/python3.6/site-packages (3.8.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from tweepy) (1.11.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.6/site-packages (from tweepy) (1.3.0)\n",
      "Requirement already satisfied: PySocks>=1.5.7 in /opt/conda/lib/python3.6/site-packages (from tweepy) (1.6.7)\n",
      "Requirement already satisfied: requests>=2.11.1 in /opt/conda/lib/python3.6/site-packages (from tweepy) (2.18.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.11.1->tweepy) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.11.1->tweepy) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.11.1->tweepy) (2018.1.18)\n",
      "Requirement already satisfied: oseti in /opt/conda/lib/python3.6/site-packages (0.2)\n",
      "Requirement already satisfied: mecab-python3 in /opt/conda/lib/python3.6/site-packages (from oseti) (0.7)\n",
      "Requirement already satisfied: neologdn in /opt/conda/lib/python3.6/site-packages (from oseti) (0.2.1)\n",
      "Requirement already satisfied: sengiri in /opt/conda/lib/python3.6/site-packages (from oseti) (0.2.1)\n",
      "Requirement already satisfied: emoji in /opt/conda/lib/python3.6/site-packages (from sengiri->oseti) (0.5.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (2.18.4)\n",
      "Requirement already satisfied: requests_oauthlib in /opt/conda/lib/python3.6/site-packages (1.3.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests) (2018.1.18)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from requests_oauthlib) (3.1.0)\n",
      "Requirement already satisfied: sengiri in /opt/conda/lib/python3.6/site-packages (0.2.1)\n",
      "Requirement already satisfied: emoji in /opt/conda/lib/python3.6/site-packages (from sengiri) (0.5.4)\n"
     ]
    }
   ],
   "source": [
    "#必要なツールをインストール（初回のみ実行）\n",
    "! pip install --upgrade pip\n",
    "! pip install tweepy\n",
    "! pip install oseti\n",
    "! pip install requests requests_oauthlib\n",
    "! pip install sengiri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import re\n",
    "import emoji\n",
    "import oseti\n",
    "from datetime import datetime, date, timedelta\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import config\n",
    "\n",
    "class Get_Twitter():\n",
    "\n",
    "    def __init__(self, day, reload, print_rep = False, exclud_words = \"配信スタート ＃キャンペーン　リツイートキャンペーン\", RT_count = 5000):\n",
    "        self.oseti_analyzer = oseti.Analyzer()  #極性判定\n",
    "        self.CK = config.CONSUMER_KEY\n",
    "        self.CS = config.CONSUMER_SECRET\n",
    "        self.AT = config.ACCESS_TOKEN\n",
    "        self.AS = config.ACCESS_TOKEN_SECRET\n",
    "        self.ew = exclud_words\n",
    "        self.print_rep = print_rep\n",
    "        self.rt = str(RT_count)\n",
    "        self.columns = [\n",
    "            \"Id\", \"Date\", \"Name\", \"Full_text\", \n",
    "            \"Judge\", \"Posi_score\", \"Nega_score\", \"Followers\", \"link\"\n",
    "        ]\n",
    "        self.posi_pd = pd.DataFrame([], columns = self.columns)\n",
    "        self.nega_pd = pd.DataFrame([], columns = self.columns)\n",
    "        self.fire_pd = pd.DataFrame([], columns = self.columns)\n",
    "        self.wait = 0\n",
    "        self.reload = reload\n",
    "        day = datetime.strptime(day, '%Y-%m-%d')\n",
    "        self.day = day.strftime('%Y-%m-%d')\n",
    "\n",
    "    def main(self):\n",
    "        self._Make_Dir() # データ格納ファイルの準備\n",
    "\n",
    "        #ツイートを取得、センチメント判定\n",
    "        try:\n",
    "            status = self.Get_Buzz() #バズったツイート取得\n",
    "            for i in status:            \n",
    "                if self.wait == 10:\n",
    "                    print(\"10回待機したため終了\")\n",
    "                    break\n",
    "                self.Status(i)\n",
    "                if self.Exclude_Word(self.buzz_full_text) == True:# 除外ワードを含むツイートは除外\n",
    "                    continue\n",
    "                if self.Text_Count() == True: #30W以下のツイートは除外\n",
    "                    continue\n",
    "                self.Get_Rep() #リプライを取得\n",
    "                self.Get_RT() #RTコメントを取得\n",
    "                if self.Min_Rep() == False: # コメントが少ないツイートは除外\n",
    "                    continue\n",
    "                self.Get_Senti() #コメントをセンチメント判定\n",
    "                self._Get_Analysis() #ツイートをセンチメント判定\n",
    "        #エラー時はスキップして次のツイート取得\n",
    "        except (ValueError,  KeyError, TypeError, tweepy.TweepError) as e:\n",
    "            pass\n",
    "        #リクエスト回数が上限に達した場合はリセット時間まで待機して継続\n",
    "        except tweepy.RateLimitError as e:\n",
    "            if self.reload:\n",
    "                self.wait += 1\n",
    "                print(\"==========\")\n",
    "                print('get_buzzのリクエスト回数が上限に達しました。リセット時間まで待機')\n",
    "                print('Wait 15min...')\n",
    "                print()\n",
    "                for _ in tqdm(range(15 * 60)):\n",
    "                    time.sleep(1)\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        #生成したデータをprint\n",
    "        print()\n",
    "        print(\"↓↓↓positiveサンプル↓↓↓\")\n",
    "        display(self.posi_pd.head())\n",
    "        print()            \n",
    "        print(\"↓↓↓negativeサンプル↓↓↓\")\n",
    "        display(self.nega_pd.head())\n",
    "        print()\n",
    "        print(\"↓↓↓fire_tweetサンプル↓↓↓\")\n",
    "        display(self.fire_pd.head())\n",
    "        print()\n",
    "        print()\n",
    "        \n",
    "        #生成したPandasDataFrameをcsvで書き出す\n",
    "        total_pd = pd.concat([self.posi_pd, self.nega_pd, self.fire_pd], ignore_index=True)\n",
    "        buzz_old = pd.read_csv('./output/buzz_tweet.csv')\n",
    "        buzz_new = pd.concat([buzz_old, total_pd])#既存データと連結\n",
    "        buzz_new.drop_duplicates(subset=\"Id\",inplace=True)#重複ID行を削除            \n",
    "        buzz_new.to_csv('./output/buzz_tweet.csv', index = False, header = True)\n",
    "        print(\"csvへの書き出しが完了しました。新規データ数{}、全データ数：{}\".format(len(buzz_new) - len(buzz_old), len(buzz_new)))\n",
    "        print(\"サンプルが0件の場合は、15分後に再度実行すると取得できる場合があります。\") \n",
    "        print(\"fire_tweetは出現率が非常に低いです。\")\n",
    "\n",
    "    #Api認証\n",
    "    def _Auth(self):\n",
    "        auth = tweepy.OAuthHandler(self.CK, self.CS)\n",
    "        auth.set_access_token(self.AT, self.AS)\n",
    "        api = tweepy.API(auth)\n",
    "        return api\n",
    "\n",
    "    #出力用ディレクトリとcsvファイルを作成（存在しない場合のみ）\n",
    "    def _Make_Dir(self):\n",
    "        new_dir_path = 'output'\n",
    "        try:\n",
    "            os.makedirs(new_dir_path)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        if (os.path.isfile('./output/buzz_tweet.csv')) == False:\n",
    "            self.posi_pd.to_csv('./output/buzz_tweet.csv', index = False)  \n",
    "\n",
    "    #絵文字削除\n",
    "    def _remove_emoji(self, text):\n",
    "        return ''.join(c for c in text if c not in emoji.UNICODE_EMOJI)\n",
    "\n",
    "    #テキストを正規表現処理、絵文字削除\n",
    "    def _format_text(self, text):\n",
    "        text=re.sub(r'https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-…]+', \"\", text)\n",
    "        text=re.sub('\\n', \"\", text)\n",
    "        text=re.sub(r'@?[!-~]+', \"\", text)\n",
    "        text=self._remove_emoji(text)\n",
    "        return text\n",
    "    \n",
    "    #　日付表記を整える、日本時間に修正\n",
    "    def _date_format(self, date):\n",
    "        date = datetime.strptime(str(date), '%a %b %d %H:%M:%S %z %Y')\n",
    "        date = date + timedelta(hours=9)\n",
    "        return datetime.strftime(date, '%Y-%m-%d %H:%M')\n",
    "\n",
    "    def Status(self, status): \n",
    "        self.buzz_id = status._json['id']\n",
    "        self.buzz_id_str = status._json['id_str']\n",
    "        self.buzz_name = status._json['user']['screen_name']\n",
    "        self.buzz_full_text = status._json['full_text']\n",
    "        self.date = status._json['created_at']\n",
    "        self.date = self._date_format(self.date)\n",
    "        self.favo = status._json['favorite_count']\n",
    "        self.rt_count = status._json['retweet_count']\n",
    "        api = self._Auth()\n",
    "        self.followers = status._json['user']['followers_count']\n",
    "        #self.followers = len(api.followers(status._json['user']['screen_name']))\n",
    "    \n",
    "    #除外ワード\n",
    "    def Exclude_Word(self, text):                        \n",
    "        if self.ew in str(text):\n",
    "            print(\"==========\")\n",
    "            print(\"除外ワード\")\n",
    "            print()\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    #ツイート内にリンクがあれば分割\n",
    "    def Text_Count(self):\n",
    "        if re.search(\"(https://t.co/\\w+)\", self.buzz_full_text) == None:\n",
    "            self.link = None\n",
    "        else:                   \n",
    "            self.buzz_full_text = re.split(\"(https://t.co/\\w+)\", self.buzz_full_text)\n",
    "            self.link = self.buzz_full_text[1]\n",
    "            self.buzz_full_text = self.buzz_full_text[0]\n",
    "        if len(self.buzz_full_text) < 30:\n",
    "            return True\n",
    "\n",
    "    #リプライ＋引用RTコメントが100未満のツイートは除外\n",
    "    def Min_Rep(self):\n",
    "        reply_texts_rows = []\n",
    "        if self.rep_cnt + self.RTcomme_cnt > 100:\n",
    "            reply_texts_rows.append(self.rep_row)\n",
    "            reply_texts_rows.append(self.rt_row)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    #sentiment_listを一次元にし、ツイートごとの極性表現の総和の辞書にする\n",
    "    def Get_Senti(self):\n",
    "        self.sentiment_list = sum(self.sentiment_list, [])#１次元にする\n",
    "        self.sentiment = dict((key, sum(d[key] for d in self.sentiment_list)) for key in self.sentiment_list[0])\n",
    "\n",
    "    #バズったツイートを取得(デフォルト：5000RT以上)\n",
    "    def Get_Buzz(self):\n",
    "        api = self._Auth()\n",
    "        try:       \n",
    "            status = api.search(q = 'filter:safe min_retweets:' + self.rt + ' exclude:retweets until:' + self.day,\n",
    "                lang ='ja', count =100, tweet_mode = 'extended', result_type = 'recent')\n",
    "            return status\n",
    "        #エラー時はスキップして次のツイート取得\n",
    "        except (ValueError,  KeyError) as e:\n",
    "            pass\n",
    "        #リクエスト回数が上限に達した場合はリセット時間まで待機して継続\n",
    "        except (tweepy.RateLimitError, tweepy.TweepError) as e:\n",
    "            if self.reload:\n",
    "                self.wait += 1\n",
    "                print(\"==========\")\n",
    "                print('get_buzzのリクエスト回数が上限に達しました。リセット時間まで待機')\n",
    "                print('Wait 15min...')\n",
    "                print()\n",
    "                for _ in tqdm(range(15 * 60)):\n",
    "                    time.sleep(1)\n",
    "            else:\n",
    "                pass\n",
    "        #return status\n",
    "    \n",
    "    #リプライを取得\n",
    "    def Get_Rep(self):\n",
    "        api = self._Auth()     \n",
    "        query_reply = '@' + self.buzz_name + ' exclude:retweets'\n",
    "        self.rep_row = []\n",
    "        self.sentiment_list = []\n",
    "        self.rep_cnt =0\n",
    "        wait_cnt = 0\n",
    "        try:\n",
    "            for status_reply in api.search(q=query_reply, lang='ja', count=100):\n",
    "                if status_reply._json['in_reply_to_status_id_str'] == self.buzz_id_str:\n",
    "                    row = self._format_text(status_reply._json['text'])\n",
    "                    #極性判定\n",
    "                    sentiment_score = self.oseti_analyzer.count_polarity(str(row))#strにする\n",
    "                    self.sentiment_list.append(sentiment_score)\n",
    "                    self.rep_row.append(row)\n",
    "                    self.rep_cnt += 1\n",
    "                else:\n",
    "                    pass\n",
    "        #エラーはスキップして次のツイート取得\n",
    "        except (ValueError,  KeyError, tweepy.TweepError) as e:\n",
    "            pass\n",
    "        #リクエスト回数が上限に達した場合はリセット時間まで待機して継続\n",
    "        except tweepy.RateLimitError as e:\n",
    "            self.wait += 1\n",
    "            if self.reload:\n",
    "                print(\"==========\")\n",
    "                print('get_repのリクエスト回数が上限に達しました。リセット時間まで待機')\n",
    "                print('Wait 15min...')\n",
    "                print()\n",
    "                for _ in tqdm(range(15 * 60)):\n",
    "                    time.sleep(1)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    # 引用RTを取得\n",
    "    def Get_RT(self):\n",
    "        api = self._Auth()\n",
    "        query_quote = self.buzz_id_str + ' exclude:retweets'\n",
    "        self.RTcomme_cnt = 0\n",
    "        self.rt_row = []\n",
    "        try:\n",
    "            for status_quote in api.search(q=query_quote, lang='ja', count=100):\n",
    "                if status_quote._json['id_str'] == self.buzz_id_str:\n",
    "                    continue\n",
    "                else:\n",
    "                    row = self._format_text(status_quote._json['text'])\n",
    "                #極性判定\n",
    "                sentiment_score = self.oseti_analyzer.count_polarity(str(row))#strにする\n",
    "                self.sentiment_list.append(sentiment_score)\n",
    "                self.rt_row.append(row)\n",
    "                self.RTcomme_cnt += 1\n",
    "        #エラーはスキップして次のツイート取得\n",
    "        except (ValueError,  KeyError, tweepy.TweepError) as e:\n",
    "            pass\n",
    "        #リクエスト回数が上限に達した場合はリセット時間まで待機して継続\n",
    "        except tweepy.RateLimitError as e:\n",
    "            self.wait += 1\n",
    "            if self.reload:\n",
    "                print(\"==========\")\n",
    "                print('get_rtのリクエスト回数が上限に達しました。リセット時間まで待機')\n",
    "                print('Wait 15min...')\n",
    "                print()\n",
    "                for _ in tqdm(range(15 * 60)):\n",
    "                    time.sleep(1)\n",
    "            else:\n",
    "                pass        \n",
    "\n",
    "    #取得したTweetをprint\n",
    "    def _Print(self):\n",
    "        print(\"name：\", self.buzz_name, \"／フォロワー数：\", self.followers)\n",
    "        print(\"date：\", self.date, \"／ツイートID：\", self.buzz_id_str)\n",
    "        print(\"RT数：\", self.rt_count, \"／favorite数：\", self.favo)\n",
    "        print(\"リプライ数：\", self.rep_cnt, \"／RTコメント数(上限１００）：\", self.RTcomme_cnt)\n",
    "        if self.print_rep == True:\n",
    "            print(\"リプライ\\n\", self.rep_row)\n",
    "            print(\"RTコメント\\n\", self.rt_row)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    #センチメント判定結果を取得\n",
    "    def _Get_Analysis(self):\n",
    "        total = self.sentiment[\"positive\"] + self.sentiment[\"negative\"]\n",
    "        if self.sentiment[\"positive\"] >= self.sentiment[\"negative\"]:\n",
    "            print(\"==========\")\n",
    "            print(self.buzz_full_text)\n",
    "            print()\n",
    "            print(\"【判定:positive】　　極性表現数\", self.sentiment)\n",
    "            self._Print()\n",
    "            s = pd.Series([self.buzz_id, self.date, self.buzz_name, self.buzz_full_text, \"positive\", self.sentiment[\"positive\"], self.sentiment[\"negative\"], self.followers, self.link], index = self.columns)\n",
    "            self.posi_pd = self.posi_pd.append(s, ignore_index=True)\n",
    "        elif self.sentiment[\"negative\"]/total >= 0.7:\n",
    "            print(\"==========\")\n",
    "            print(self.buzz_full_text)\n",
    "            print()\n",
    "            print(\"【判定:fire!!!】　　極性表現数\", self.sentiment)\n",
    "            print(\"ネガ表現の割合{:.3g}\".format(self.sentiment[\"negative\"]/total))\n",
    "            self._Print()\n",
    "            s = pd.Series([self.buzz_id, self.date, self.buzz_name, self.buzz_full_text, \"fire\", self.sentiment[\"positive\"], self.sentiment[\"negative\"], self.followers, self.link], index = self.columns)\n",
    "            self.fire_pd = self.fire_pd.append(s, ignore_index=True)\n",
    "        else:\n",
    "            print(\"==========\")\n",
    "            print(self.buzz_full_text)\n",
    "            print()\n",
    "            print(\"【判定:negative】　　極性表現数\", self.sentiment)\n",
    "            self._Print()\n",
    "            s = pd.Series([self.buzz_id, self.date, self.buzz_name, self.buzz_full_text, \"negative\", self.sentiment[\"positive\"], self.sentiment[\"negative\"], self.followers, self.link], index = self.columns)\n",
    "            self.nega_pd = self.nega_pd.append(s, ignore_index=True)\n",
    "        print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ツイートデータセット取得　実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "【鬼滅の刃コラボ中！】\n",
      "ローソン国際展示場駅前店では1日限定で「鬼滅の刃」コラボを実施中です！\n",
      "\n",
      "キャラクタースタンディやポスターの展示、また入店音が炭治郎・禰豆子・善逸・伊之助のボイス（ランダム）となっておりますのでぜひチェックしてください！\n",
      "\n",
      "#鬼滅の刃 \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 20, 'negative': 16}\n",
      "name： kimetsu_off ／フォロワー数： 959187\n",
      "date： 2019-12-28 08:56 ／ツイートID： 1210710961771859968\n",
      "RT数： 6367 ／favorite数： 34919\n",
      "リプライ数： 3 ／RTコメント数(上限１００）： 99\n",
      "\n",
      "==========\n",
      "朝から気分悪くしてごめんなさい。\n",
      "はっきり申し上げます。\n",
      "飲み屋のモラルやマナーを知らない人が本当に多すぎる。\n",
      "文句があるなら来なくて大丈夫です。\n",
      "私たちはボランティアでもなんでもないので。\n",
      "年明けからこんなこと言いたくないから\n",
      "年明ける前に過去のまとめたのを置いておきます。 \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 182, 'negative': 130}\n",
      "name： takuya_hyon ／フォロワー数： 662586\n",
      "date： 2019-12-28 08:48 ／ツイートID： 1210709023726526464\n",
      "RT数： 13142 ／favorite数： 53839\n",
      "リプライ数： 72 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "若月健矢選手、立花理香さん\n",
      "\n",
      "ご結婚おめでとうございます！\n",
      "末長くお幸せに✨\n",
      "\n",
      "バファローズ㊗️ポンタ\n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 67, 'negative': 3}\n",
      "name： bs_ponta ／フォロワー数： 288626\n",
      "date： 2019-12-28 08:34 ／ツイートID： 1210705650491113472\n",
      "RT数： 6691 ／favorite数： 12497\n",
      "リプライ数： 58 ／RTコメント数(上限１００）： 48\n",
      "\n",
      "==========\n",
      "ONE PIECEと僕たち嵐がコラボレーションさせていただいた、新曲「A-RA-SHI：Reborn」のミュージックビデオは1週間後にリリース！\n",
      "The \"A-RA-SHI: Reborn\" music video, illustrated by One Piece, is out in ONE WEEK!\n",
      " #嵐 #ARASHI \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 118, 'negative': 36}\n",
      "name： arashi5official ／フォロワー数： 2221569\n",
      "date： 2019-12-28 08:25 ／ツイートID： 1210703193405046786\n",
      "RT数： 26661 ／favorite数： 136007\n",
      "リプライ数： 60 ／RTコメント数(上限１００）： 63\n",
      "\n",
      "==========\n",
      "【ご報告】この度、みなさまにご報告したいことができました。ぜひご覧いただけますと幸いです。 \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 117, 'negative': 13}\n",
      "name： RiccaTachibana ／フォロワー数： 175131\n",
      "date： 2019-12-28 08:22 ／ツイートID： 1210702646509588480\n",
      "RT数： 43349 ／favorite数： 77867\n",
      "リプライ数： 79 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "【#本日12月28日は竈門禰豆子の誕生日!!】\n",
      "本日は、鬼でありながら鬼殺隊に所属する\n",
      "炭治郎自慢の妹・竈門禰豆子の誕生日です！\n",
      "\n",
      "この特別な日を祝して、\n",
      "禰豆子の魅力が詰まったヘッダーをプレゼント！\n",
      "\n",
      "人を守るために鬼の力を使う\n",
      "禰豆子のヘッダー、ぜひご活用ください！ \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 85, 'negative': 15}\n",
      "name： kimetsu_off ／フォロワー数： 959187\n",
      "date： 2019-12-28 08:00 ／ツイートID： 1210696997839110144\n",
      "RT数： 34840 ／favorite数： 115833\n",
      "リプライ数： 35 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "【注意喚起！】寝ている人から財布等を抜き取る犯罪が発生しているという連絡が警察からありました。待機列などで、皆さん声を掛け合って、注意してください。残念ながらコミケでは、4会期連続でスリの現行犯逮捕が起きています。お宝資金はしっかりと管理を。#C97\n",
      "\n",
      "【判定:negative】　　極性表現数 {'positive': 61, 'negative': 104}\n",
      "name： comiketofficial ／フォロワー数： 221336\n",
      "date： 2019-12-28 07:27 ／ツイートID： 1210688744660975616\n",
      "RT数： 9295 ／favorite数： 6529\n",
      "リプライ数： 3 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "「鬼滅の刃」グッズプレゼント🎉\n",
      "\n",
      "大好評のため第2段\n",
      "シリーズ累計2500万部記念\n",
      "鬼滅の刃 全18巻セット\n",
      "を10名様にプレゼント🎁\n",
      "\n",
      "応募方法\n",
      "・フォロー&amp;リツィート\n",
      "・「応募」とリプ\n",
      "\n",
      "応募期間\n",
      "・12月31日\n",
      "\n",
      "当選した方にはDMにてお知らせ！ \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 30, 'negative': 16}\n",
      "name： kimetsu_goods ／フォロワー数： 12309\n",
      "date： 2019-12-28 07:10 ／ツイートID： 1210684401157206016\n",
      "RT数： 4877 ／favorite数： 2862\n",
      "リプライ数： 98 ／RTコメント数(上限１００）： 87\n",
      "\n",
      "==========\n",
      "アニメーター始めてから初めてキャベツを描いた、妙なプレッシャーがあった\n",
      "#炎炎ノ消防隊 \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 76, 'negative': 32}\n",
      "name： varon666 ／フォロワー数： 3398\n",
      "date： 2019-12-28 02:49 ／ツイートID： 1210618724517990400\n",
      "RT数： 15512 ／favorite数： 43610\n",
      "リプライ数： 74 ／RTコメント数(上限１００）： 97\n",
      "\n",
      "==========\n",
      "🔥“弐ノ章”制作＆2020年夏放送決定🔥\n",
      "\n",
      "壱ノ章の続編となるTVアニメ『炎炎ノ消防隊 弐ノ章』の制作が決定しました！\n",
      "\n",
      "さらに“弐ノ章ティザービジュアル”も発表！\n",
      "\n",
      "2020年も炎炎の炎はますます燃え続けます🔥🔥\n",
      "\n",
      "『炎炎ノ消防隊 弐ノ章』ご期待ください！！\n",
      "\n",
      "#fireforce #炎炎ノ消防隊 #弐ノ章 \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 88, 'negative': 24}\n",
      "name： FireForce_PR ／フォロワー数： 79744\n",
      "date： 2019-12-28 02:07 ／ツイートID： 1210608126434500608\n",
      "RT数： 7841 ／favorite数： 17719\n",
      "リプライ数： 50 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "【祝】12月28日は「竈門禰豆子の誕生日」\n",
      "\n",
      "『鬼滅の刃』の登場キャラクターで、主人公・竈門炭治郎の妹。物語開始時12歳→14歳。家族と慎ましくも幸せな生活を送っていたが、突然の惨劇により鬼に変貌してしまう。人を喰らう鬼としての衝動を抑え込みながら、炭治郎や仲間のために行動する。 \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 73, 'negative': 12}\n",
      "name： livedoornews ／フォロワー数： 992784\n",
      "date： 2019-12-28 00:15 ／ツイートID： 1210579841025789952\n",
      "RT数： 6130 ／favorite数： 24579\n",
      "リプライ数： 4 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "【グランブルーファンタジー】本日12/27 24:00より「GRANBLUE FANTASY The Animation Season 2」第12話放送！放送を記念して【宝晶石3000個】をプレゼント！ #グラブル #アニメグラブル \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 96, 'negative': 17}\n",
      "name： granbluefantasy ／フォロワー数： 851542\n",
      "date： 2019-12-27 23:00 ／ツイートID： 1210560983346737152\n",
      "RT数： 13018 ／favorite数： 15987\n",
      "リプライ数： 79 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "コミケ会場で「プライスカードを忘れた😭」となった場合、落ち着いて机の上にあるチラシ類を見てみて下さい。\n",
      "全てのサークルさんの机の上に、プライスカードを置いてきましたから😋\n",
      "\n",
      "＊不要でしたらごめんなさい \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 135, 'negative': 40}\n",
      "name： ShimayaTokyo ／フォロワー数： 7769\n",
      "date： 2019-12-27 22:54 ／ツイートID： 1210559641823793152\n",
      "RT数： 16518 ／favorite数： 21431\n",
      "リプライ数： 51 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "「ボーボボって何？何なのあのアフロ？」って人のために分かりやすいスターターセットを貼っておきますね \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 56, 'negative': 37}\n",
      "name： Ponzu_SHT ／フォロワー数： 1689\n",
      "date： 2019-12-27 22:54 ／ツイートID： 1210559549230305280\n",
      "RT数： 7939 ／favorite数： 15404\n",
      "リプライ数： 55 ／RTコメント数(上限１００）： 47\n",
      "\n",
      "==========\n",
      "チュートリアルでお世話になったキャラが実は最強の裏ボスっていうゲーム \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 53, 'negative': 31}\n",
      "name： black_sabasu ／フォロワー数： 86413\n",
      "date： 2019-12-27 22:26 ／ツイートID： 1210552542595178498\n",
      "RT数： 6416 ／favorite数： 25322\n",
      "リプライ数： 60 ／RTコメント数(上限１００）： 42\n",
      "\n",
      "==========\n",
      "Mステ #ウルトラSUPERLIVE \n",
      "11時間生放送中🎤\n",
      "\n",
      "女々しくての10周年のお祝いに駆けつけてくれたのはなんと\n",
      "#ボボボーボ・ボーボボ\n",
      "でした‼️\n",
      "\n",
      "#ボボボーボ\n",
      "#ボーボボ\n",
      "#ウルトラタモリ\n",
      "#Mステ \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 28, 'negative': 21}\n",
      "name： Mst_com ／フォロワー数： 1247806\n",
      "date： 2019-12-27 22:12 ／ツイートID： 1210549021443379200\n",
      "RT数： 12276 ／favorite数： 19877\n",
      "リプライ数： 2 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "クソワロ\n",
      "\n",
      "女々しくて発売10年で人気キャラが駆けつける・・・\n",
      "\n",
      "ボボボーボ・ボーボボｗｗｗｗｗｗｗｗ\n",
      "\n",
      "#Mステ\n",
      "#金爆 \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 31, 'negative': 18}\n",
      "name： k3po7gouki ／フォロワー数： 7109\n",
      "date： 2019-12-27 22:04 ／ツイートID： 1210547002594840577\n",
      "RT数： 5286 ／favorite数： 12064\n",
      "リプライ数： 14 ／RTコメント数(上限１００）： 87\n",
      "\n",
      "==========\n",
      "なにわ男子「2019年ありがとうございました！」\n",
      "アオハルツアー愛知公演でしたー！\n",
      "2019年のコンサートを締めくくることができました！\n",
      "\n",
      "なにふぁむのみなさんへ\n",
      "\n",
      "｢最高な1年をありがとう♡｣\n",
      "\n",
      "なにわ男子からの報告事も！\n",
      "\n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 296, 'negative': 61}\n",
      "name： islandtv_up ／フォロワー数： 192109\n",
      "date： 2019-12-27 21:50 ／ツイートID： 1210543508886441985\n",
      "RT数： 8345 ／favorite数： 19258\n",
      "リプライ数： 61 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "昨日は恩師であり、恩人であり、ホンモノの小栗旬さんのお誕生日だったので、夜中に正装で会いに行きました。\n",
      "\n",
      "おめでとうございまーきのっ！ \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 50, 'negative': 14}\n",
      "name： hinode_obt ／フォロワー数： 173147\n",
      "date： 2019-12-27 21:36 ／ツイートID： 1210539839268913152\n",
      "RT数： 5450 ／favorite数： 85259\n",
      "リプライ数： 64 ／RTコメント数(上限１００）： 50\n",
      "\n",
      "==========\n",
      "＃嵐 松潤さんに、\n",
      "\n",
      "「ゴーちゃんってオス？」\n",
      "\n",
      "とも聞かれたブイ！\n",
      "\n",
      "松潤さんが思うほうでOKブイ\n",
      "\n",
      "＃ウルトラSUPERLIVE   \n",
      "＃Mステ\n",
      "＃ウルトラゴーちゃん\n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 88, 'negative': 24}\n",
      "name： gochan_V ／フォロワー数： 73883\n",
      "date： 2019-12-27 21:11 ／ツイートID： 1210533697167867906\n",
      "RT数： 8215 ／favorite数： 30136\n",
      "リプライ数： 10 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "『ノンストップ・ストーリー』ライブキービジュアル用にホロライブメンバー23名を描かせていただきました。おるだんさんデザインの衣装が素敵すぎる😭✨ライブ今から楽しみだ～！ \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 119, 'negative': 20}\n",
      "name： naru_quadrille ／フォロワー数： 25816\n",
      "date： 2019-12-27 21:06 ／ツイートID： 1210532392407977984\n",
      "RT数： 5636 ／favorite数： 14363\n",
      "リプライ数： 82 ／RTコメント数(上限１００）： 55\n",
      "\n",
      "==========\n",
      "＃嵐 松潤さんは、\n",
      "\n",
      "「いつも同じ人が入ってる？」\n",
      "「何人かいるの？」\n",
      "「暑くない？」\n",
      "\n",
      "とか話しかけてくれたブイ！正直質問の意味はよく分からなかったけど、とにかくお話できて本当にうれしかったブイ！\n",
      "\n",
      "＃ウルトラSUPERLIVE   \n",
      "＃Mステ\n",
      "＃ウルトラゴーちゃん\n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 87, 'negative': 11}\n",
      "name： gochan_V ／フォロワー数： 73883\n",
      "date： 2019-12-27 21:00 ／ツイートID： 1210530972006936576\n",
      "RT数： 13843 ／favorite数： 47705\n",
      "リプライ数： 5 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "King &amp; Princeのみなさんが #Mステカメラ 📹初登場～🤣\n",
      "\n",
      "今日のテーマは\n",
      "『今年一番盛り上がったこと』です😎Ⓜ\n",
      "”あるナゾナゾ”からメンバーを巻き込んだ一大事に😂\n",
      "答えは「森」なので「木が3本」でした🌲🌲🌲\n",
      "\n",
      "今日は『koi-wazurai』を披露してくれます😍😍\n",
      "#ウルトラSUPERLIVE #Mステ \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 122, 'negative': 24}\n",
      "name： Mst_com ／フォロワー数： 1247806\n",
      "date： 2019-12-27 20:23 ／ツイートID： 1210521643577040896\n",
      "RT数： 16872 ／favorite数： 52947\n",
      "リプライ数： 4 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "可愛い可愛い\n",
      "かずま。ふじお。\n",
      "お疲れちゃん。\n",
      "\n",
      "#HiGH_LOW_THE_WORST\n",
      "#ハイロー\n",
      "#THERAMPAGE \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 133, 'negative': 28}\n",
      "name： jun_shison0305 ／フォロワー数： 483854\n",
      "date： 2019-12-27 20:13 ／ツイートID： 1210519062096138240\n",
      "RT数： 7994 ／favorite数： 41516\n",
      "リプライ数： 73 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "✨ディズニー限定デザインPRESENT✨\n",
      "\n",
      "@lovemaybelline をフォロー&amp;\n",
      "この投稿をリツイートで、\n",
      "\n",
      "❤ラッシュニスタ N\n",
      "❤ハイパーシャープ ライナー R\n",
      "❤パウダーインペンシル BR2\n",
      "\n",
      "のミッキーマウスデザイン３itemsが抽選で10名様に当たるチャンス！\n",
      "\n",
      "応募は12/31まで🆗\n",
      "\n",
      "#メイベリン\n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 190, 'negative': 21}\n",
      "name： LoveMaybelline ／フォロワー数： 205712\n",
      "date： 2019-12-27 20:00 ／ツイートID： 1210515669101338625\n",
      "RT数： 6537 ／favorite数： 1173\n",
      "リプライ数： 95 ／RTコメント数(上限１００）： 9\n",
      "\n",
      "==========\n",
      "V6のみなさんが #Mステカメラ 📹初登場～🤣\n",
      "\n",
      "今日のテーマは\n",
      "『今年一番盛り上がったこと』です😎Ⓜ\n",
      "”ある後輩グループ\"の話から乱入に発展!?😠\n",
      "方向性を改める!?V6の来年は期待大です🤣\n",
      "\n",
      "今日は『ある日願いが叶ったんだ』を披露してくださいました🕺\n",
      "#ウルトラSUPERLIVE #Mステ \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 100, 'negative': 27}\n",
      "name： Mst_com ／フォロワー数： 1247806\n",
      "date： 2019-12-27 19:43 ／ツイートID： 1210511532645158913\n",
      "RT数： 13596 ／favorite数： 36111\n",
      "リプライ数： 2 ／RTコメント数(上限１００）： 100\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "「鬼の手」袋を編みました。\n",
      "\n",
      "・左手にジャストフィット！\n",
      "・厚手の生地であったかい！\n",
      "・妖怪退治にも使える！\n",
      "・今冬のマストアイテム！ \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 70, 'negative': 22}\n",
      "name： bon_66 ／フォロワー数： 1271\n",
      "date： 2019-12-27 19:41 ／ツイートID： 1210511013507784705\n",
      "RT数： 23397 ／favorite数： 57095\n",
      "リプライ数： 81 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "「刀剣乱舞 大演練」2020年8月 東京ドームにて開催決定！\n",
      "\n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 50, 'negative': 44}\n",
      "name： stage_touken ／フォロワー数： 251499\n",
      "date： 2019-12-27 19:17 ／ツイートID： 1210505051136856064\n",
      "RT数： 15045 ／favorite数： 23168\n",
      "リプライ数： 43 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "先輩がうざい後輩の話を描きました。【97】\n",
      "\n",
      "#先輩がうざい後輩の話 \n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 56, 'negative': 23}\n",
      "name： shiromanta1020 ／フォロワー数： 768166\n",
      "date： 2019-12-27 19:17 ／ツイートID： 1210505003737026563\n",
      "RT数： 19628 ／favorite数： 86393\n",
      "リプライ数： 21 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "コミックマーケットでは深夜来場は認めておりません。絶対に深夜来場をしないようにお願いします。すみやかにお帰り下さい。 #C97 \n",
      "\n",
      "【判定:negative】　　極性表現数 {'positive': 70, 'negative': 99}\n",
      "name： comiketofficial ／フォロワー数： 221336\n",
      "date： 2019-12-27 19:15 ／ツイートID： 1210504343675260930\n",
      "RT数： 5492 ／favorite数： 4704\n",
      "リプライ数： 3 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "==========\n",
      "【公式HP】\n",
      "「刀剣乱舞 大演練」2020年8月 東京ドームにて開催決定のお知らせを追加しました！\n",
      "\n",
      "\n",
      "【判定:positive】　　極性表現数 {'positive': 58, 'negative': 56}\n",
      "name： musical_touken ／フォロワー数： 248567\n",
      "date： 2019-12-27 19:03 ／ツイートID： 1210501433478410242\n",
      "RT数： 22938 ／favorite数： 31222\n",
      "リプライ数： 41 ／RTコメント数(上限１００）： 100\n",
      "\n",
      "\n",
      "↓↓↓positiveサンプル↓↓↓\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Name</th>\n",
       "      <th>Full_text</th>\n",
       "      <th>Judge</th>\n",
       "      <th>Posi_score</th>\n",
       "      <th>Nega_score</th>\n",
       "      <th>Followers</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1210710961771859968</td>\n",
       "      <td>2019-12-28 08:56</td>\n",
       "      <td>kimetsu_off</td>\n",
       "      <td>【鬼滅の刃コラボ中！】\\nローソン国際展示場駅前店では1日限定で「鬼滅の刃」コラボを実施中で...</td>\n",
       "      <td>positive</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>959187</td>\n",
       "      <td>https://t.co/TgagYYCcAU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1210709023726526464</td>\n",
       "      <td>2019-12-28 08:48</td>\n",
       "      <td>takuya_hyon</td>\n",
       "      <td>朝から気分悪くしてごめんなさい。\\nはっきり申し上げます。\\n飲み屋のモラルやマナーを知らな...</td>\n",
       "      <td>positive</td>\n",
       "      <td>182</td>\n",
       "      <td>130</td>\n",
       "      <td>662586</td>\n",
       "      <td>https://t.co/BeaCWjpNg4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1210705650491113472</td>\n",
       "      <td>2019-12-28 08:34</td>\n",
       "      <td>bs_ponta</td>\n",
       "      <td>若月健矢選手、立花理香さん\\n\\nご結婚おめでとうございます！\\n末長くお幸せに✨\\n\\nバ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>288626</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1210703193405046786</td>\n",
       "      <td>2019-12-28 08:25</td>\n",
       "      <td>arashi5official</td>\n",
       "      <td>ONE PIECEと僕たち嵐がコラボレーションさせていただいた、新曲「A-RA-SHI：Re...</td>\n",
       "      <td>positive</td>\n",
       "      <td>118</td>\n",
       "      <td>36</td>\n",
       "      <td>2221569</td>\n",
       "      <td>https://t.co/hHobubpb16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1210702646509588480</td>\n",
       "      <td>2019-12-28 08:22</td>\n",
       "      <td>RiccaTachibana</td>\n",
       "      <td>【ご報告】この度、みなさまにご報告したいことができました。ぜひご覧いただけますと幸いです。</td>\n",
       "      <td>positive</td>\n",
       "      <td>117</td>\n",
       "      <td>13</td>\n",
       "      <td>175131</td>\n",
       "      <td>https://t.co/hR8m5IHoBD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Id              Date             Name  \\\n",
       "0  1210710961771859968  2019-12-28 08:56      kimetsu_off   \n",
       "1  1210709023726526464  2019-12-28 08:48      takuya_hyon   \n",
       "2  1210705650491113472  2019-12-28 08:34         bs_ponta   \n",
       "3  1210703193405046786  2019-12-28 08:25  arashi5official   \n",
       "4  1210702646509588480  2019-12-28 08:22   RiccaTachibana   \n",
       "\n",
       "                                           Full_text     Judge Posi_score  \\\n",
       "0  【鬼滅の刃コラボ中！】\\nローソン国際展示場駅前店では1日限定で「鬼滅の刃」コラボを実施中で...  positive         20   \n",
       "1  朝から気分悪くしてごめんなさい。\\nはっきり申し上げます。\\n飲み屋のモラルやマナーを知らな...  positive        182   \n",
       "2  若月健矢選手、立花理香さん\\n\\nご結婚おめでとうございます！\\n末長くお幸せに✨\\n\\nバ...  positive         67   \n",
       "3  ONE PIECEと僕たち嵐がコラボレーションさせていただいた、新曲「A-RA-SHI：Re...  positive        118   \n",
       "4     【ご報告】この度、みなさまにご報告したいことができました。ぜひご覧いただけますと幸いです。   positive        117   \n",
       "\n",
       "  Nega_score Followers                     link  \n",
       "0         16    959187  https://t.co/TgagYYCcAU  \n",
       "1        130    662586  https://t.co/BeaCWjpNg4  \n",
       "2          3    288626                     None  \n",
       "3         36   2221569  https://t.co/hHobubpb16  \n",
       "4         13    175131  https://t.co/hR8m5IHoBD  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "↓↓↓negativeサンプル↓↓↓\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Name</th>\n",
       "      <th>Full_text</th>\n",
       "      <th>Judge</th>\n",
       "      <th>Posi_score</th>\n",
       "      <th>Nega_score</th>\n",
       "      <th>Followers</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1210688744660975616</td>\n",
       "      <td>2019-12-28 07:27</td>\n",
       "      <td>comiketofficial</td>\n",
       "      <td>【注意喚起！】寝ている人から財布等を抜き取る犯罪が発生しているという連絡が警察からありました...</td>\n",
       "      <td>negative</td>\n",
       "      <td>61</td>\n",
       "      <td>104</td>\n",
       "      <td>221336</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1210504343675260930</td>\n",
       "      <td>2019-12-27 19:15</td>\n",
       "      <td>comiketofficial</td>\n",
       "      <td>コミックマーケットでは深夜来場は認めておりません。絶対に深夜来場をしないようにお願いします。...</td>\n",
       "      <td>negative</td>\n",
       "      <td>70</td>\n",
       "      <td>99</td>\n",
       "      <td>221336</td>\n",
       "      <td>https://t.co/5WYAt8yOap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Id              Date             Name  \\\n",
       "0  1210688744660975616  2019-12-28 07:27  comiketofficial   \n",
       "1  1210504343675260930  2019-12-27 19:15  comiketofficial   \n",
       "\n",
       "                                           Full_text     Judge Posi_score  \\\n",
       "0  【注意喚起！】寝ている人から財布等を抜き取る犯罪が発生しているという連絡が警察からありました...  negative         61   \n",
       "1  コミックマーケットでは深夜来場は認めておりません。絶対に深夜来場をしないようにお願いします。...  negative         70   \n",
       "\n",
       "  Nega_score Followers                     link  \n",
       "0        104    221336                     None  \n",
       "1         99    221336  https://t.co/5WYAt8yOap  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "↓↓↓fire_tweetサンプル↓↓↓\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Name</th>\n",
       "      <th>Full_text</th>\n",
       "      <th>Judge</th>\n",
       "      <th>Posi_score</th>\n",
       "      <th>Nega_score</th>\n",
       "      <th>Followers</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Id, Date, Name, Full_text, Judge, Posi_score, Nega_score, Followers, link]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "csvへの書き出しが完了しました。新規データ数31、全データ数：308\n",
      "サンプルが0件の場合は、15分後に再度実行すると取得できる場合があります。\n",
      "fire_tweetは出現率が非常に低いです。\n"
     ]
    }
   ],
   "source": [
    "# 指定日のツイートを取得（API制限のため取得できるのは約一週間前のものまで）\n",
    "day = '2019-12-28'\n",
    "# リクエスト制限対応：True:リクエスト上限に達したら15分待機ののちツイート取得続行/ False:待機せずcsv取得\n",
    "reload = True\n",
    "\n",
    "#除外ワード\n",
    "exclud_words = \"配信スタート ＃キャンペーン　リツイートキャンペーン WWWWWWWWW\"\n",
    "\n",
    "#その他設定可能パラメータ\n",
    "#リプライをprint（print_rep = True/Fals), 最低RT数(RT_count = 5000)\n",
    "\n",
    "GT = Get_Twitter(day, reload, exclud_words)\n",
    "GT.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ２）データセットの前処理\n",
    "　・正規表現、ストップワード除去など\n",
    " \n",
    " #### 参考サイト\n",
    "Pythonで全角・半角記号をまとめて消し去る　http://prpr.hatenablog.jp/entry/2016/11/23/Python%E3%81%A7%E5%85%A8%E8%A7%92%E3%83%BB%E5%8D%8A%E8%A7%92%E8%A8%98%E5%8F%B7%E3%82%92%E3%81%BE%E3%81%A8%E3%82%81%E3%81%A6%E6%B6%88%E3%81%97%E5%8E%BB%E3%82%8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.6/site-packages (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.6/site-packages (from gensim) (1.13.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.6/site-packages (from gensim) (0.19.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.6/site-packages (from gensim) (1.11.0)\n",
      "Requirement already satisfied: smart_open>=1.2.1 in /opt/conda/lib/python3.6/site-packages (from gensim) (1.5.3)\n",
      "Requirement already satisfied: boto>=2.32 in /opt/conda/lib/python3.6/site-packages (from smart_open>=1.2.1->gensim) (2.48.0)\n",
      "Requirement already satisfied: bz2file in /opt/conda/lib/python3.6/site-packages (from smart_open>=1.2.1->gensim) (0.98)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from smart_open>=1.2.1->gensim) (2.18.4)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->smart_open>=1.2.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->smart_open>=1.2.1->gensim) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->smart_open>=1.2.1->gensim) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->smart_open>=1.2.1->gensim) (2018.1.18)\n",
      "Requirement already satisfied: lightgbm in /opt/conda/lib/python3.6/site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from lightgbm) (1.13.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from lightgbm) (0.19.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from lightgbm) (0.19.1)\n",
      "Requirement already satisfied: natto-py in /opt/conda/lib/python3.6/site-packages (0.9.0)\n",
      "Requirement already satisfied: cffi in /opt/conda/lib/python3.6/site-packages (from natto-py) (1.10.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi->natto-py) (2.18)\n",
      "Requirement already satisfied: emoji in /opt/conda/lib/python3.6/site-packages (0.5.4)\n"
     ]
    }
   ],
   "source": [
    "#必要なツールをインストール(初回のみ実行)\n",
    "! pip install gensim\n",
    "! pip install natto-py\n",
    "! pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ツイートデータを学習用に整形\n",
    "from natto import MeCab\n",
    "#import MeCab\n",
    "import re\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import emoji\n",
    "import neologdn\n",
    "import urllib.request\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "class For_Model():\n",
    "    \n",
    "    def __init__(self, data, columns, out_file, mode, text, similar = None):\n",
    "        self.mecab = MeCab.Tagger(\"-Owakati\")\n",
    "        self.data = data\n",
    "        self.columns = columns\n",
    "        self.out_file = out_file\n",
    "        self.mode = mode\n",
    "        self.text = text\n",
    "        self.similar = str(similar)\n",
    "\n",
    "    #データを読み込む\n",
    "    def Load_tweets(self):        \n",
    "        df = pd.read_csv(self.data, usecols = self.columns)\n",
    "        print(\"読み込んだツイート\", df.shape)\n",
    "        \n",
    "        #３０w以下のtweet行を削除\n",
    "        index = []\n",
    "        for i in range(len(df)):\n",
    "            text = df.iloc[i, 2]\n",
    "            text = re.sub('https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-…]+', \"\", text)\n",
    "            text = re.sub('http?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-…]+', \"\", text)\n",
    "            df.iloc[i, 2] = text\n",
    "            if len(text) < 30:\n",
    "                index.append(i)\n",
    "        df_tweet = df.drop(df.index[index])\n",
    "        df_tweet = df_tweet.reset_index(drop=True)\n",
    "        \n",
    "        #判定用テキストをリストの最後に追加\n",
    "        tweets = []\n",
    "        for i in df_tweet[self.text]:\n",
    "            tweets.append(i)\n",
    "        if self.similar == None:\n",
    "            pass\n",
    "        else:\n",
    "            tweets.append(self.similar)\n",
    "        return df_tweet, tweets\n",
    "\n",
    "    def Stop_Words(self):\n",
    "        # ストップワードをダウンロード\n",
    "        url = 'http://svn.sourceforge.jp/svnroot/slothlib/CSharp/Version1/SlothLib/NLP/Filter/StopWord/word/Japanese.txt'\n",
    "        urllib.request.urlretrieve(url, './output/stop_word.txt')\n",
    "\n",
    "        with open('./output/stop_word.txt', 'r', encoding='utf-8') as file:\n",
    "            stopwords = [word.replace('\\n', '') for word in file.readlines()]\n",
    "\n",
    "        #追加ストップワードを設定（助詞や意味のない平仮名１文字）\n",
    "        add_words = ['あ','い','う','え','お','か','き','く','け','こ','さ','し','す','せ','そ','た','ち','つ','て','と',\n",
    "                     'な','に','ぬ','ね','の','は','ひ','ふ','へ','ほ','ま','み','む','め','も','や','ゆ','よ',\n",
    "                     'ら','り','る','れ','ろ','わ','を','ん','が','ぎ','ぐ','げ','ご','ざ','じ','ず','ぜ','ぞ',\n",
    "                     'だ','ぢ','づ','で','ど','ば','び','ぶ','べ','ぼ','ぱ','ぴ','ぷ','ぺ','ぽ',\n",
    "                     'くん','です','ます','ました','そして','でも','だから','だが','くらい','その','それ','かも',\n",
    "                     'あれ','あの','あっ','そんな','この','これ','とか','とも','する','という','ござい',\n",
    "                     'ので','なんて','たら', 'られ','たい','さて','てる','ください','なる','けど','でし',\n",
    "                     'じゃん','だっ','なっ','でしょ', 'ある','って','こんな','ねえ'\n",
    "                    ]\n",
    "        stopwords = stopwords + add_words\n",
    "        return stopwords\n",
    "\n",
    "    def Tokenizer(self, text, stopwords):\n",
    "\n",
    "        words = []\n",
    "        text = self.mecab.parse(text)\n",
    "        text = text.split(' ')\n",
    "        for j in range(len(text)):\n",
    "            if text[j] not in stopwords:\n",
    "                words.append(text[j])\n",
    "        return words\n",
    "\n",
    "    def remove_emoji(self, text):\n",
    "        return ''.join(c for c in text if c not in emoji.UNICODE_EMOJI)\n",
    "\n",
    "    #記号削除\n",
    "    def format_text(self, text):\n",
    "        text = unicodedata.normalize(\"NFKC\", text)  # 全角記号を半角へ置換\n",
    "        # 記号を消し去るための魔法のテーブル作成\n",
    "        table = str.maketrans(\"\", \"\", string.punctuation  + \"「」、。・*`+-|?#!()\\[]<>=~/\")\n",
    "        text = text.translate(table)\n",
    "        return text\n",
    "\n",
    "    def main(self):\n",
    "        tweets_num = 0\n",
    "        stopwords = self.Stop_Words()\n",
    "        df_tweet, tweets = self.Load_tweets()\n",
    "        #ツイートを分かち書きしてcsvに出力(モード'a'はデータ追加、モード'w'は新規作成)\n",
    "        with open('./output/' + self.out_file, self.mode) as f:\n",
    "            for i in tweets:\n",
    "                tweets_num += 1\n",
    "                i = neologdn.normalize(i)\n",
    "                i = re.sub('\\n', \"\", i)\n",
    "                i = re.sub(r'[!-~]', \"\", i)#半角記号,数字,英字\n",
    "                i = re.sub(r'[︰-＠]', \"\", i)#全角記号\n",
    "                i = self.format_text(i)#記号削除\n",
    "                i = re.sub(r'[【】●ㅅ●Ф☆✩︎♡→←▼①②③④⑤『』ω《》∠∇∩♪∀◞ཀCщ≧≦ ́◤◢■◆★※↑↓〇◯○◎⇒▽◉Θ♫♬〃“”◇ᄉ⊂⊃д°]', \"\", i)\n",
    "                #i = re.sub(r'[!-~、。‥…？！〜「」｢｣:：“”【】※♪♩♫♬『』→↓↑《》〈〉[]≧∇≦・゜・●ㅅ●´Д´°ω°•ω•★＊☆♡（）✔Θ∀´∀｀˘ω˘‼бωб￣▽￣◉→←▼①②③④⑤]', \"\", i)\n",
    "                i = self.remove_emoji(i)\n",
    "                i = self.Tokenizer(i, stopwords)\n",
    "                i = ' '.join(i) #リストを文字列に変換\n",
    "                i = str(i)\n",
    "                f.write(i)\n",
    "\n",
    "        print('CSV出力完了：'+ self.out_file)\n",
    "        with open('./output/' + self.out_file) as f:\n",
    "             wakati = f.read()\n",
    "\n",
    "        print(\"学習用データに追加したツイート数：\", tweets_num)\n",
    "        print()\n",
    "        print(\"分かち書きサンプル\\n\", wakati)\n",
    "        return df_tweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前処理の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "読み込んだツイート (308, 6)\n",
      "CSV出力完了：train_buzz.txt\n",
      "学習用データに追加したツイート数： 254\n",
      "\n",
      "分かち書きサンプル\n",
      " 絶対 断ら ない 評判 病児保育 助成金 下り 赤字 出し 閉鎖 全国 病児保育 赤字 運営 おり 東海 キッズケア 助成金 求め 署名 集め 助成金 下りる あり ませ 社会保障 税金 使わ ませ \n",
      "全国 皆さん どうか 皆様 お力 貸し 早く 娘 助け 家族 揃っ 笑顔 クリスマス 新年 迎え 娘 目撃 情報 娘 繋がる 些細なこと 連絡 連絡先 大月 警察 暑 電話 もしくは 最寄り 警察 署 拡散希望 小倉 美咲 \n",
      "歴史 さんざん 他国 料理 魔 改造 我が国 寿司 ポリス どど 片腹痛い あらゆる 文化 文化 独自 解釈 いい イノベーション 生む 思っ しかし ヘルシンキ 〈 クリスマス トッピング • バナナ 巻き寿司 〉 寛容 試さ いる \n",
      "すん ごい フォースリープツイッター 人気 半信半疑 夜 粒 食べ 昨日 めちゃ ぐっすり 眠れ 例える なら 旅行 気持ち良く 遊び 疲れ 夜 睡眠 クオリティ しかも 味 まろやか ミルク チョコ 好み すぎる 目安 一日 粒 摂 れる \n",
      "アニメ 期 制作 決定 いたし 期 視聴 応援 くださっ いる 皆様 本当に ありがとう 向け 決意 誓う 空 クロム ゲン 新 カット 実写 実験 による スペシャル 映像 公開 引き続き よろしく お願 石 ドクターストーン 期 \n",
      "ガンダム まで フレーム 意識 構造 なく モノコック 構造 っぽい 設計 よく 動き まで 無い 可動 エッチ ポーズ 決まり 賛否 アイテム ない 面白い 設計 触る べき 各地 売り切れ 見かけ 買っ 損 ない \n",
      "ある日 祖父母 行っ 何故か 大 号泣 何事 理由 聞い 祖父 ぁさ ケーキ あげ たく 秘密 買い 行っ 叱ら 祖母 ぃ 突然 なく 心配 双方 泣き ゃくっててななんなんだこの 可愛い 生き物 衝撃 \n",
      "年月日 昼 時時 テレビ朝日 ミュージックステーション ウルトラ ミュージカル 刀剣乱舞 刀剣男士 出演 決定 住まい 地域 テレビ番組表 確認 刀 ミュ \n",
      "ユニクロ パーカー チャック 音 良い 知っ ほしく チャック 音 使っ 曲 作りました 着心地 普通 \n",
      "金曜 ジェジェミケランジェロ ぶち アガる 大前提 公開 完成 ヒプマイ いつも 溜まり場 アーイ \n",
      "パパ活 女子 貧乏 ばかり 思っ いる 多い けれど 親 高級 物 与え 不自由 なく 育ち 大学生 途端 いきなり 自活 しろ 言わ 時給 買える ない 言い出す 子育て 失敗 親 生み出し 怪物 結構 割合 存在 いる \n",
      "ねぇ すごい 衝撃 まで 食べ ない 国民 存在 ない 思っ たなん 関西 しか 売れ ない らしい 全体 販売 金額 近畿 府県 だって まじ 関西 出身 事実 信じ られる \n",
      "インタビュー 挑戦 しよ 成功 失敗 分かれ道 なく 失敗 連続 成功 一本道 言っ 成功 ともかく として 思っ 図 \n",
      "煙草 風 リップ めっちゃ 可愛く ない 既存 煙草 パッケージ オマージュ 全体的 パケ買い しまう レベル デザイン すき 封 開ける 細身 リップ 種類 入っ 箱 持っ てれ 色々 メイク 対応 出来 ちゃう しかも リップ デザイン 煙草 たく 良き \n",
      "農家 切実 お願い 白菜 黒い 食べ 食べ 食べ 黒い ポリフェノール 急激 寒さ あたる 発生 生理現象 凍結 ない 環境 対抗 甘み 美味しい ぜひ 召し上がっ \n",
      "コスメティック ブランド コラボレーション 詳細 近日 公開予定 西島隆弘 楽しみ 皆様 ひさし ️ \n",
      "ねずみ ポケモン ピカチュウ でんきタイプ ポケモン グッズ 年月 日水 祝 登場 ゃあああああああ 歴代 大 集結 新年会 \n",
      "待た メインビジュアル 完成 麒麟 くる 長谷川博己 明智光秀 \n",
      "ご飯 出 くる いい 待っ 顔 そもそも ありません \n",
      "日本 美し 感じる 場所 縦 写真 タップ お願い ‍ ️ \n",
      "コカ • コーラ 許さ ない 九州 檸檬 堂 いい 国民 騙す 味覚 記憶 正しかっ いもち ゃんただしかったよお 振り込む 箱 送っ 欲しい \n",
      "いえ アマゾンのレビュー あんまり クソ 中華 業者 詐欺 レビュー まくっ 日本 レビュー 見る いう のに いつのまにか 変わっ ありがとう アマゾン \n",
      "実は 創作 たま モチベーション この世 ない 仕方 なく 作っ わかる いる かしら 既に この世 確実 動かし ない 分かっ くれる 絶対 いる \n",
      "同僚 女性 息子 仮面ライダー ハマっ ライダー 同士 喧嘩 悲しく ない 泣く 味方 仲良く 協力 怪物 だけ 戦う シリーズ あり ませ 中古 玩具 入り やす 以内 作品 助かり 相談 ライダー オタク 皆さん 助け 下さい \n",
      "イベント 配信 情報 明日 メンテナンス 終了 より シーズン イベント 大奥 花 園 配信 いたし 江戸 パーク 依頼 により 公演 行う しかし 公演 テーマ 大奥 判明 腹 くくっ た人 姫 将軍 臨む ーエースリー \n",
      "さきほど 漁師 珍しい 白い ナマコ 獲 連絡 あり 当館 持っ いただき まるで 漂白 白さ マナマコ 突然変異 思わ 白色 珍しく 稀 しか 発見 ませ 特別展 会場 明日 展示 予定 是非 ごらん \n",
      "わかっ しか ない 場所 置く いる 男性 防ぐ 無理 心して みる \n",
      "いつも 応援 くださっ いる 皆様 大切 お知らせ バーチャル 事務所 年月日 をもちまして 活動 終了 いただく 運び なり 詳しく 確認 \n",
      "男の子 女の子 いじめ られる 矯正 べき おかしな 考え方 小学校 同級生 妹 影響 リカちゃん人形 好き 男の子 いじめ なかっ 背 高く 太っ 少し 馬鹿 れる 大 暴れ やはり 趣味 嗜好 容姿 より 何より 暴力 大切 \n",
      "攻める なぁ クリスマス 一挙 放送 \n",
      "お知らせ あんさんぶるスターズ ショート 公開 本日 サインパネルプレゼント 対象 ツイート 詳細 サイト ご覧 あん スタサインプレゼント 朱桜司 月永レオ 瀬名泉 朔間凛月 鳴上嵐 \n",
      "ふたご座流星群 流れ星 連発 本日 未明 撮影 動画 流星 写っ いる 部分 つなげ 実際 スピード 再生 茨城県 にて 撮影 \n",
      "大切 お知らせ 本 日日日 京セラドーム大阪 行わ 模様 チャンネル 初 独占 放送 れる なり メンバー 最新 メッセージ 届き 初 公開 ぜひ \n",
      "毎年 ロシア 開催 れる 大規模 サバゲー もう 色々 やばい っす \n",
      "使っ コドーム 種類 使う タイプ に対する 個人 偏見 \n",
      "なぜ クレカ 会社 お客様 寄り添う リボ払い 変える 発想 \n",
      "ものすごく 簡単 基準 表紙 著者 顔写真 載っ 本 出さ ない これだけ 驚く ほど 上がる \n",
      "弁護士事務所 過払い そういう ばかり 飲食店 無断 キャンセル 裁判 任せ イラスト 無断転載 裁判 任せ 映画館 スマホ 使う いる 裁判 任せ そういう ガンガン 流し くれ 世の中 よく なり \n",
      "あんまり にも お客さん 来 なく 早くも 廃業 メニュー 看板 出して たり 試行錯誤 怖い じゃ ない 怪しい じゃ ない フラッと 入っ くれ いい \n",
      "損保ジャパン お断り 病院 みつけ まぁ 酷い だろ ねぇ \n",
      "今日 近隣 スーパー ない 税務署 査察 入っ 大騒ぎ しかも ターゲット 青果 んで 思っ ゆず わかり みかん 親戚 鍋物 いい 香り アレ 冬至 柚子湯 オススメ 食品 じゃ ない 軽減税率 対象外 うわー めんどくさい ️ \n",
      "クラス はいる 関わっ いけ ない 陰 キャ 大人 しまっ 末路 \n",
      "さっき 日本人 観光客 レンタカー 歳歳 前後 禁止 区域 タバコ 吸っ 注意 えら いう 神主 言わ れる 時代 なり 注意 逆ギレ 大人 増え それでも 注意喚起 しない いけ 立場 辛い \n",
      "一般家庭 不要 自由 持 ちく ださいっ たり ウチ 近所 特殊メイク 造形 会社 レベル 違う 昼 出て 深夜 \n",
      "姉 鮭 焼い 忘れ 灼熱 鮭 でき つい 撮っ しまっ 供養 \n",
      "酷い 当たり屋 出くわし 前輪 激突 わざとらしく 倒れ込ん アピール 悪質 幸い 動画 撮影 被害 なく 犯人 暗がり 逃走 いっ コイツ 良く 現れる 常習犯 られる \n",
      "税金 投入 自転車 専用 ペイント レーン 作りました 自転車 走れ ませ \n",
      "高校 ころ 友人 カーネルおじさん リボン 手足 しか 見え ない 一言 しか 見え なく 呪い かかっ しまっ 全員 かかっ しまえ いい \n",
      "ウスタビガ 羽化 初めて 足 バタバタ よっ こら っしょ 出 くるん もふもふ あわせ たまり ませ 本当は 繭 出口 もふもふ 毛 見え 始め 目撃 録 間に合わ なかっ ウスタビガ いい もふもふ \n",
      "野生 ヌオー 囲ま 人生 ポケモン 剣 盾 \n",
      "ツイッターランド お嬢様 ミーム 吹き荒れ 書い 叙述トリック お嬢様 読ん 欲しい \n",
      "妹 ラーメンズ 思い出せ ない コント 僕 どんな 服 色 妹 白 僕 じゃあ 雀 だろ 背景 青 ギリジン 髪結 セリフ だけ 分かる 妹 ラーメンズ 検索 アプリ てぇ \n",
      "先日 行わ 神社 消防 訓練 消防士 火事 おき まず 優先 行動 べき 禰宜 御神体 出仕 御神体 巫女 御神体 消防士 自身 参拝者 身 安全 消防士 どん引き 顔 忘れ ませ 申し訳 あり ませ \n",
      "メタリカ ギタリスト 前座 務め イラク ヘビメタ バンド ギタリスト ギター プレゼント ヘビメタ イスラム教 禁じ おり 彼ら 死刑 覚悟 バンド活動 勇気 称え 男気 泣け \n",
      "日本中 感動 渦 巻き起こし ドラえもん スクリーン 帰っ くる ドラえもん 年月日 公開 \n",
      "朗報 勢力図 公開 帝国 独立 大東亜共栄圏 構成 中国 全土 攻略 模様 \n",
      "落としもの 落とし 財布 より 落とし あかん やろ 内幸町 駅員 落とし物 として 届け おき 落とし主 見つかる 願っ \n",
      "持っ 葉 食べ 終え 葉 取っ 再び 食べ 始める エゾモモンガ \n",
      "動画 ただ 単に 大型 悪者 だけ そもそも 撮影 車 追越車線 ブロック 悪質 すぎ 煽り運転 \n",
      "職場 今日 タイト スカート セーター きれいな 色 メイク 変え 最近 ランチ パン 多い 顔 合わせる 私について 言及 くる 女性 女性 退職 申し訳ない ホッ いる 監視 不快 \n",
      "つぐ 雷 兄弟 拗ら 結果 救済 ルート 妄想 捏造 無限城 戦後 鬼 まだ いる 世界線 \n",
      "待望 最新作 放送 まで 週間 水曜どうでしょう 最新作 放送開始 \n",
      "天皇 すら 人間 宣言 のに ただ 客 神様 ねぇ だろ ボケ ナス 大逆罪 共 \n",
      "鈴木武蔵 代表 初ゴール ネズミ ネコ 追い かけっこ \n",
      "寒い 地域 のに 黒 タイツ さえ 履く 認め ない 校則 変えよ 生徒 親 含め 全校 生徒 アンケート 集め 割 賛成 票 貰っ 関わら 大 無能 校長 変える 理由 見当たら ない 一言 校則 変更 認め なかっ 事案 特集 \n",
      "日本 アニメ業界 ディズニー 低 予算 高品質 作品 作っ なぜ できる 強 秘密 迫り アニメーター 最低賃金 時給 絵 書い 生活 でき ない 親 仕送り バイト 頼っ いる 業界 強 なく 弱 \n",
      "友人 キバナ ポケモン 勘違い キバナ ポケモン じゃ ありません ‍ ️ \n",
      "脱がし 着付け うわっ デオキシス やん やん \n",
      "上司 お酌 丁寧 断る \n",
      "キャラクターデザイン 担当 いただい 津田穂波 氏 より 豊 前江 桑名 江 松井 江 ゲーム 実装 記念 描き 下ろし イラスト 頂き 篭手 切江 豊 前江 桑名 江松 井江 入る イベント 秘宝 里 楽器 集め 年月日 まで 開催 △ △ 刀剣乱舞 とうらぶ \n",
      "退院 報告 ホームページ ご覧 \n",
      "デジモンアドベンチャー 絆 公開 予告映像 解禁 大人 パートナーデジモン 姿 消し しまう 葛藤 末 選ん 彼ら だけ 答え 最後 進化 ー 太一 最後 物語 劇場 見届け デジモンラスエボ \n",
      "ちょっと 早め メリークリスマス より \n",
      "スマホ 慣れ ない 年寄り 選ん いい 楽々 スマホ 買わ れる 僕ら 使い方 分から ない 使い方 聞か 教え あげ ませ 設定 アプリ 一覧 出す 一苦労 マジで 々 スマホ やめ 使い方 誰か 聞く つもり なら 絶対 買っ ダメ \n",
      "テレビ 子ども 泣い 妻 家事 離せ ない 時夫 子ども 泣い では なく こういう ママ じゃ ない 泣き 止ま ない 言え 妻 イラッと ませ 言っ めちゃめちゃ イラッと 泣き 止ま なく やる \n",
      "若者 車 入れ 自動車税 つい 重量 税 つい 取得 税 つい 自賠責 つい 任意保険 つい 駐車場 代 つい ガソリン 代 つい 若者 死ん しまっ \n",
      "女児 レイプ おじさん 実名 顔出し 出演 レイプ 被害者 会い \n",
      "パパ活 話題 出る 西原理恵子 女の子 生き いく 覚え ほしい 思い出す イキ 何より 幸せ わかる 媚び 売っ たり 下手 出る なら 稼い 自由 使う よっぽど 楽しい 他人 死ぬ 程 のどぐろ 食い \n",
      "右足 舐める 瞬間 たまら 可愛さ 慌て シャッター 切っ 可愛さ 真逆 瞬間 切り取っ しまっ \n",
      "すごい モヤモヤ 推し 誕生日 〝 生誕 〟 つかう 故人 推し に対して 失礼 説 誤解 口うるさい 思わ れる しれ ませ しまっ \n",
      "マスク 咳 見る 感染者 撃ち殺せ アイツ まだ 人間 じゃ ない 馬鹿野郎 殺ら なきゃ 大事 まで 感染 れる 可能性 だって 迷う 引き金 引け 畜生 感染者 気持ち マスク しや がり 下さい \n",
      "ユウリ ホップ 夜 カレー 作る フォロワー 減 覚悟完了 \n",
      "拡散希望 福岡県飯塚市 旧 頴田町 迷い 犬 保護 柴犬 とても 大人しく 賢い 女の子 赤い 皮 しっかり 首輪 現在 顔 腫瘍 出来 いる 為 鼻 耳 悪い 様子 探し ご主人様 些細な 情報 助かり 続く \n",
      "ピアニスト 妻 トイピアノ 付い 説明書 容赦なく 捨てよ せっかく やから 一応 みよ 言う なんか キレ 気味 弾き 始め 途中 調 変わっ アドリブ なんか すごい \n",
      "真っ黒 イーブイ 仕方 なく 保護者 ブラッキー \n",
      "悲報 外国人 話しかけ とっさ 言っ ベンキョウ しろ 日本語 返さ ダメージ 消え ない \n",
      "ジャンプフェスタ 発表 あり 怪物事変 アニメ なり 本当に ありがとう \n",
      "サイゼリヤ おき 羊 串 食っ 瞬間 池袋北口 お前 お前 お前 池袋 名店 聚福 楼 味 じゃ お前 カジュアル 日本全国 名店 味 届け しや お前 うめ えな ディアボラソース つけ 更に うめ やん オリジナル 超え \n",
      "アニメ ワールドトリガー 待望 新 シーズン 製作 決定 いつも 応援 くださっ いる 皆様 本当に ありがとう 今後 続報 期待 トリガーオンワールドトリガー \n",
      "アマゾン アレクサ 地球 人間 死ん 良い 持ち主 自殺 促す 年月日 エキサイトニュース 内容 ともかく エラー 調査 すで 修正 ディストピア とても 好き \n",
      "アニメ 遊戯王 周年 節目 飾る シリーズ 遊戯王 放送 決定 主人公 シリーズ 初 小学生 デュエルルールラッシュデュエル 登場 放送 年月 詳細 チェック 遊戯王 \n",
      "カピバラ ガチ 水槽 泳い 水遊 園 \n",
      "夫 胃がん 治す 医学的根拠 ない 治療 多額 お金 注ぎ込ん 轟 言葉 子ども 新聞 読み なさい 本 読み なさい 言わ 育ち 信頼 でき ない 情報 溢れ いる 思っ ませ 本当に 重く 受け止める べき 思う \n",
      "小 息子 料理 漫画 ハマっ いつも 晩御飯 食べる とう うわ ああああああ いい ながら 全裸 ピーマン 肉 詰め だけ キミ 舐め 悪い 審査員 風 食べ 味 うわ あああああああ 叫ん 全裸 なり \n",
      "では ありがとう 言葉 見せる きれいな 結晶 作る ほぼ 完全 否定 いる 卒論 締切 プリンタ 壊れる かなり 信じ いる \n",
      "面接官 君 出身地 僕 おもちゃのまち 面接官 真面目 答え 下さい メルヘン チック 地名 ない 不採用 \n",
      "のとじま水族館 見れ 今週末 ダイオウイカ 特別展示 らしい \n",
      "デマ 注意 クリスマスプレゼント ネクタイ オススメ デマ 流れ 絶対 信用 ない 本当に 望ん いる 名誉 戦死 \n",
      "グランツーリスモ クラウン 追加 黒 クラウン 車列 つくり ませ オンライン 呼びかけ すぐ 実現 笑っ \n",
      "今日 イブイブ イーブイ 配布 ちゃい よろしく ポケモンだいすきクラブ 嫁 \n",
      "おしらせ 年月 日月 午前 より 更新 データ 配信 致し 詳しい 更新 内容 ページ ご覧 \n",
      "憧れ 続け グランプリ 全て 出し きれ 長い間 かまいたち グランプリ 優勝 信じ 応援 くれ 皆さん すい ませ まだまだ 精進 漫才 恩返し いき ミルクボーイ 本当に おめでとう めちゃくちゃ 面白かっ 皆さん 本当にありがとうございました \n",
      "新 情報 事前登録 キャンペーン 企画 実施中 フォロー ヒプマイスクラッチバトル 特典 詳細 公式サイト アクセス 記念 ゲーム 登場 寂 雷 ショット 初 公開 ヒプマイヒプマイ \n",
      "羽生 負け じゃなくて 宇野 勝っ いい \n",
      "グロ 画像 見せ しまっ しれ 申し訳ない \n",
      "お知らせ あんさんぶるスターズ ショート 公開 本日 終わら ない シンフォニア サインパネルプレゼント 対象 ツイート 詳細 サイト ご覧 あん スタサインプレゼント 天祥院英智 日々樹渉 姫宮桃李 伏見弓弦 \n",
      "終わっ 決勝 選ぶ 辛かっ 人情 かまいたち 勝た あげ たかっ 自信 怯え 共存 文句なし 漫才 去年 足り なかっ 部分 ただ ミルクボーイ 受け方 半端 なかっ 人情 私の思い出 選ぶ 失礼 思い ミルクボーイ 押し 辛い 今夜 寝 ない \n",
      "色鉛筆 禰豆 描き 上手い 思っ アート \n",
      "ミルクボーイ 優勝 おめでとう 上顎 ひっつき にくい ふた 最中 グランプリ ミルクボーイ からし蓮根 面白かっ \n",
      "先程 見逃し しまっ みそ うそ 篇 公開 本立て どうぞ どん兵衛 どん 子ぎつね グランプリ \n",
      "盛り上がっ 歌丸 芸人 に対する 考え 貼っ おき \n",
      "オリジナル 敗北 ヒーロー 再生 突破 本当に ありがとう こう やっ 聴い もらえ 思う なんだか 胸 熱く 来る あり これから ころん よろしく ∧∧ ๑๑ もんげー \n",
      "最新情報 公式サイト チェック \n",
      "緊急 豚汁 入れる 芋 さつまいも 豚汁 メジャー 思っ 福岡 香川 レシピ ググっ あんまり 引っかから なく ショック 受け アンケート 協力 \n",
      "帰ろ マンション 入り口 タコ焼き だろ 散っ 散っ 事象 より タコ焼き に対して タコ 多 すぎる 具材 運ん 既に 球体 生地 おかしい 矛盾 なり すぎ 帰れ なく \n",
      "世界中 嵐 起こす 彼ら 切り取る ドキュメンタリー 彼ら なぜ 活動 休止 思っ いる 最後 ドキュメンタリー ネトフリオリジナルドキュメンタリーシリーズ より 全世界 独占配信 開始 嵐 大みそか 嵐 \n",
      "前半 カワウソ クリスマスイブ \n",
      "街 出会っ いきなり ライトセイバー 渡し 戦っ \n",
      "実家 お宝 年前 サンタ 掛け軸 戦時中 飾る 禁止 どてら 着 特に 最高 ️ \n",
      "クズ 子ども ダメ 言っ いる モノ 勝手 売る 親 \n",
      "アポストロフィ 入れ 表記 間違い 文章 乱れ飛ぶ 本日 実は 間違い じゃ ない 雑学 毎年 定期 アップ おり \n",
      "カップル わぁ 夜景 キレイだ ねっ やっ 大体 社畜 光っ だけ やから 感謝 \n",
      "相葉 お誕生日おめでとう よき 一年 なり これから よろしくお願いします 相葉雅紀 誕生 祭 相葉雅紀 誕生 祭 相葉雅紀 誕生 祭 マサキ 誕生日 \n",
      "時分 確保 ー じゃ ない 野津山 なり ٩ᐛو パ ァ これから ハートフルデイズ 過ごし 思い з ありがとう よろしく \n",
      "最大 ガチャチケット 周年 記念 大 拡散 キャンペーン 実施 ️ ツイート ガチャチケット × プレゼント ️ 上限 チケット より プレゼント 配布 応募 規約 必読 \n",
      "初めて ご挨拶 ファン 皆様 むけ 初めて 挨拶 動画 ご覧 動画 \n",
      "いつも 本当に ありがとう 沢山 ツイート 頂け とても 光栄 思い これから ゆるく 更新 よろしくお願いします \n",
      "保育園 優しい サンタ 来る 教わっ らしい 本日 風呂 入り ながら 意地悪 サンタ ほしい 意地悪 友達 言っ おり 慈愛 大き 眩ん 気絶 \n",
      "クリスマス音楽祭 放送 まもなく 登場 皆さん パフォーマンス 見どころ 聞き 生放送 \n",
      "発売決定 アニメ 浦島坂田船 日常 年月日 発売 初回限定 版 特典 通常版 明日 月日 より 店舗 予約 受付 開始 店舗 によって 受付 異なり \n",
      "明日 クリスマスイヴ 居 ない 悪い お前 \n",
      "クリスマス音楽祭 放送 まもなく 登場 皆さん 本番 直前 意気込み いただき 生放送 \n",
      "なぜ 幼児 チッチャイヤツチッチャイヤツ コンクリートポンプ車 スケール やっと わかっ サンタさん 間違え なく よかっ \n",
      "クリスマス音楽祭 放送 まもなく 登場 皆さん 本番 直前 意気込み いただき 生放送 \n",
      "さと ワンマンライブ グッズ 遂に 公開 かわいいいいいいい リハーサル 遂に 大詰め 最高 思い出 しよ \n",
      "助け 虚偽 いっ 逃げ 妻子 おいかける お父さん 支援 動き あり はすみとしこ 妻 でっちあげ 子ども 連れ去っ 連れ去り 漫画 書い 維新の会 関連 父親 団体 自民党 議員 深く 関わっ 立法 \n",
      "ブラック企業大賞 トレンド 上がっ ブラック企業 マップ 日本列島 津々浦々 ドクロマーク 埋まっ \n",
      "得意げ めっちゃ 食う 太ら ない 笑 キロ 笑笑 そこら 女子 より 軽い 思う 笑 言っ 筋肉 ない 言っ あからさま 不 機嫌 \n",
      "部下 退職 申し出 受け 説得 余地 考える 管理職 多い 驚く まで わかっ ない ほぼ 全て 相談 なく 報告 事前 相談 ない 負け 確定 いる まで 立場 聞い 貰え だけ 人として 信頼 なかっ \n",
      "小学 いじめる 中学 まじ ゴミ 消えろ \n",
      "僕 正直 言っ 初めて スターウォーズ 感想 コレ かの 有名 スターウォーズ 中学生 マーベル ダークナイト 触れ 世代 恐らく 刺さら ない \n",
      "飲み会 煩い 帰る 独身 こういう 愚痴 でる 結婚しない 言い だし 違う 家庭 大好き オヤジ オバサン として 楽しい 帰る 言い にくい 本当に 家庭 状況 危機 話題 ませ \n",
      "冬休み 給食 なくなり もし 子供 クリスマス お正月 らしい でき ない 困り 遠慮なく 無料 食堂 利用 クリスマス らし さは なく 申し訳ない えび フライ 喜ば れる 思い もちろん 大人 だけ 利用 いただけ お持ち帰り でき \n",
      "代代 代 就職氷河期 世代 笑っ いる ありません 皆さん デジタルネイティブ 言わ のに 学校 スマホ 禁止 匿名 パソコン 人台 無い 環境 課金 ゲー 動画 だけ 勉強 使わ もらえ 世界 読解力 負け いっ デジタル 氷河期世代 \n",
      "シロ 憧れ 女性 三谷 まみ 役 宮沢りえ 章 立て 物語 章 登場 憧れ 三谷 まみ 興奮 抑え ない シロ ケンジ 放送 楽しみ コメント 頂き ぜひ チェック \n",
      "安い まずい 思っ いる こういう じつは 食 疎い 安い 安い なり うまく 高い 高い なり うまい である 上等 料理 当てる 飯 食っ いる ない しあわせになるために 飯 食っ いる 少年 母親 より ずっと あわ \n",
      "最近 毛 アルトリア 髪 ハマっ やり方 まとめ まで 長く なく ある程度 髪の毛 出来る 必要 ゴム ヘアピン ピン リボン 髪の毛 満足 巻け ない クソ 不器用 三つ 編み さえ 出来れ 一人 以内 作れる 髪型 是非 \n",
      "日本語 英語 中国語 和 了 モンゴル語 アイヌ語 シュメール 語 アラビア語 クリンゴン語 \n",
      "ロック 写真 撮ら れる 無理矢理 写り こん くる ジャックブラック 躍動感 \n",
      "賃金 上げ 会社 潰れる 言う けっこう いる どの 会社 潰れる ギリギリ 高い 賃金 労働者 支払っ いる 思っ かね ねー だろ 労働者 出し 渋っ 経営者 株主 懐 入っ \n",
      "戦時中 怖い話 血 すする メモ帳 短い 下手 ホラー映画 より 怖い クトゥルフ ちょっと 読ん ほしい \n",
      "開催決定 あらき しゅーず センラ めいちゃん 最優先 チケット 受付 抽選 受付期間 受付 \n",
      "クルマ社会 電車 社会 境目 だろ 思い 簡単 可視 国勢調査 データ より 男性 通勤 使う 交通手段 位 塗り 分け 複数回答 例えば 駅 まで 車 駅 電車 自家用車 電車 両方 カウント れる 注意 \n",
      "伊藤詩織 勝訴 判決 下し 素晴らしい 判決 書い 東京地裁 裁判官 今後 どう みな 忘れないで 注目 続けよ 皆 気づか ない 不当 左遷 れる 恐れ 思う \n",
      "有馬記念 ミニ データ 田代まさし 違法薬物 逮捕 枠 番 アメリカンボス 着 田代まさし 違法薬物 逮捕 枠 番 ゼンノロブロイ 着 田代まさし 違法薬物 逮捕 枠 番 ヴィクトワールピサ 着 田代まさし 違法薬物 逮捕 枠 番 スカーレット カラー 着 \n",
      "ああ ついに タイ より 日本 コスト 低い 時代 来 日本 失わ まざまざ 実感 デフレ \n",
      "カード 決済 手数料 いただい クレカ 決済 手数料 請求 違法 のに 手数料 だくと 旨 記載 いる 大丈夫 制度 知ら なかっ 念の為 カード会社 確認 忙しい サービス \n",
      "クローズアップ現代 出演 語る 酷い 偏向報道 どういう やり方 どの 切り取ら れる 皆さん 知っ もらい 本当に 酷い 傷つい 偏向報道 被害者 語る \n",
      "ヒーリング っ プリキュア 情報 公式サイト 新 情報 追加 メインキャストキービジュアル 主題歌 情報 さらに 告知 映像 公開 詳しく \n",
      "ヒーリング っ プリキュア キャスト 決定 キュアグレース 悠木碧 キュアフォンテーヌ 依田菜津 キュアスパークル 河野ひより ラビリン 加隈亜衣 ペギタン 武田華 ニャトラン 金田アキ ラテ 白石晴香 日朝 \n",
      "路上 突如 はじまる 喧嘩 突然 ピザ 丸ごと 持っ 男性 現れ 平和 世界 誕生 \n",
      "小学生 体力 低下 特に 小 男子 っていう ニュース 役所 原因 スマホゲーム 求め いる そもそも 公園 子供 声 騒音 れる 不 寛容 社会 わざわざ 遊ぼ 思わ ない 球技 禁止 公園 多い \n",
      "納得 でき ない 絵 好き くれ 欲しい 思っ くれる いる 幸せ \n",
      "ビースターズ 期 制作 決定 皆さま 声援 応え 期 制作 決定 放送 時期 新しく 登場 キャラクター キャスト 今後 随時発表 頂き これから 原作 舞台 アニメ 宜しく お願い \n",
      "会社 不愉快 思い 押す スタンプカード 久々 押し \n",
      "誕生日 だー さー これから よろしく ねー 人人 人人 人人 人人 そら まる 大群 ̄̄ うれ ぴー ️️️️️ \n",
      "速報 クロちゃん カエデ 連呼 だけ のに なぜ 面白い 水曜日のダウンタウン \n",
      "誕生日 お知らせ 本日 影片みか 誕生日 限定 ログイン ボーナス として ダイヤ プレゼント フラワーボックス 作っ ボイス ストーリー 開放 でき 詳細 アプリ お知らせ ご覧 影片みか 誕生 祭 \n",
      "お題 箱 期 為 悪戦苦闘 ながら クリスマス 準備 ちゃう 兵長 殴り 書き ぐち ゃぐちゃですみませんありがとうございました \n",
      "次回 月日 新年 最初 テーマ バ 美 肉 略語 ご存じですか ねほりんぱほりん \n",
      "最新刊 カバー 公開 本日 クリスマス 来年 月日 同時 発売 呪術 廻 戦 コミックス 最新巻 巻 カバー イラスト 公開 メリークリスマス \n",
      "ガラス 製品 入っ 段ボール 円周率 おそらく 割れ ない \n",
      "術 知名度 ランキング 位 螺旋 丸 位 千鳥位火遁豪火球 術 術 知名度 ランキング 位 潜 影 蛇 位 砂漠 葬送 位 穢土 転生 \n",
      "福岡県福岡市薬院 駅 ソフトクリーム 専門店 バンブルビー ハート リボン ステッキ トッピング できる フラワー ソフトクリーム \n",
      "すと ぷり お知らせ メリークリスマス 明日 今年 ラスト すと ぷり リレー 生放送 開催決定 詳細 明日 放送中 公開 楽しみ \n",
      "セブンイレブン 新 システム 1 煙草 買う レジ タッチパネル 欲しい 銘柄 タッチ 2 棚 光っ タバコ 店員 取り出す 3 お金 払う \n",
      "定期的 呟い 断捨離 コツ 年間 袖 を通して いない 服 ときめく なく ただただ 爆音 流し 歌い ながら つい ゴミ袋 ぶち込む これだけ 無い 困っ まで あり ませ 何とか 笑 \n",
      "最後 ちょっと 下がり すぎ ハンドル 操作 プロ すぎる 33 \n",
      "児童 残し 給食 持ち帰っ 教諭 処分 国民 税金 選挙 区民 土産 持た 首相 放置 ラテ 注い 会社員 逮捕 国民 税金 選挙 区民 饗応 首相 放置 捜査 書類 破棄 警察官 処分 公文書 大量 改竄 たり シュレッダー 政権 放置 書い 嫌 くる \n",
      "イオン マスク 禁止 従業 人嫌 がる わかる インフル 出 停止 薬効 元気 イオン 遊ばせ 来 凄く 多い 店員 媒介 なら ない 全店 マスク 奨励 理解 下さい アナウンス れる 余程 良い イオン マスク 禁止 撤回 \n",
      "お客様 言い 店員 マスク ほしく ない なら お客様 くれ 言う ポイントカード 有無 答え キャッシュ 決済 払 無言 スマホ だけ レジ 置く 会計 イヤホン 外さ ない こういう 言っ 聞こえ ない 言う 権利 ない マスク 禁止 \n",
      "教諭 横領 せい 生徒 足り なく なら ともかく 廃棄 予定 残飯 持っ 帰っ 通報 失職 ちょっと 総額 どのみち ゴミ ぶっちゃけ 損し ない 現代社会 不 寛容 如実 出 \n",
      "悲報 タコ 人間 茹で られる ぐらい なら 逝く 遺言 残し 茹で 上がる \n",
      "メイドカフェ びえとにありがちなことお 帰り なさい 主人 さま なく 帰り なさい 同志 オプション 労働 服 着 れる メニュー 共産党員 食事 労働者 兵士 食事 収容 食事 種類 店内 問題 行動 起こす 粛清 れる 隣 中華料理店 仲 悪い \n",
      "アヘン 原料 料理 ケシ 殻 混入 常連客 増やし たかっ 中国 \n",
      "サンタ 制度 終了のお知らせ \n",
      "年明け アニメ チェック 絶対 見る ハイキュー めちゃ コレ 戦国武将 犬 転生 声優さん 凄く 豪華 ️ 超大型 新人 声優 ️ てえ なまえ \n",
      "払っ プレゼント 買っ わし 夜勤 明け ブルブル 震え ながら デッキ 小麦粉 振りかけ わし やし サンタ おじさん 感謝 いい さま 俄然 信じ いる 娘 喜ぶ 顔 見れる なら 幸せ メリークリスマス おやすみなさい \n",
      "コンビニ 駐車場 のんびり 火の手 あがっ くそ びびっ カメラ 回し ながら 誰か 叫び ながら 近づい 助け っ 声 聞こえ ツレ 敷地内 突入 子供 女性 運び出し 煙 吸っ 頭 痛い 吉成 火事 \n",
      "メリ ィ クリ スマ アアアアアアアアアア ァ ァ ァ ァ ァ ァ ァ ァ ァ ァ アアアアアアアアアア ァ ァ ァ ァ ァ ァ ァ ァ ァ ァ アアアアアアアアアア ァ ァ ァ ァ ァァァァァァアアアアアアアコマンドーニューマスター 吹替 版 公開中 順次 ロードショー \n",
      "ゾンビ 理性 失っ 本能 行動 パターン 大体 ゾンビ 一日中 布団 歩 動こう ない ゾンビ 出て 人間 食べよ 思っ かったるい 戸棚 ポテチ 食べ 夕飯 済ませ ゾンビ ない パニック 起き なそ \n",
      "オリオン座 ベテルギウス 急 暗く 太陽 倍 恒星 水素 元素変換 終わり 炭素 赤色巨星 なり 炭素 ネオン ネオン 鉄 終了 爆発 ネオン 反応 急激 収縮 暗く 爆発 間近か \n",
      "結構 大 事件 予感 のに いつも 疑惑 だけ 大騒ぎ 野党 黙り なぜ 秋元司 議員 収賄 立件 参入 絡み 現金 受領 疑い \n",
      "睡眠 について 病院 先生 聞い 1基 本 若い人 最低 睡眠 必要 2時間 睡眠 酒杯 飲ん でる 状態 等しい 3 睡眠 削っ 影響 ない 思っ 数年 集中力 体力 驚く ほど 低下 4時間 睡眠 精神面 落ち込む 寝 ましょ \n",
      "技術 全て 外注 出して コストダウン 流行 自社 開発 しない 技術力 落ち 外注 頼ん 正しく でき いる 判定 でき ない 外注 依頼 仕様 作れ ない そもそも 作れる 分から なく 頼め ない 壊滅 状態 陥っ 企業 続出 \n",
      "ポケモンソードシールドクリスマス ワイルド エリア 天候 全て 雪 ロマンチック 仕様 ポケモン 剣 盾 \n",
      "おい 錦糸町 ホーム 彼氏 バイバイ 女い お前 彼氏 大 イキリ やめ とけ \n",
      "クリスマス音楽祭 放送 再び 登場 皆さん 本番 直前 見どころ 聞き 生放送 \n",
      "寒く 缶 コーンスープ 飲む 人たち 教え あげ 飲み 少し 凹ま せる 粒 めっちゃ 出 流体力学 基づい 超 正攻法 攻略 法なん 粒 めっちゃ 出 \n",
      "ついに 不登校 英単語 なり 原因 子供 個人 なく 日本 学校 システム はっきり 書か 個人 人権 侵害 世界 現実 視点 \n",
      "大黒摩季 記者 二人 いる 不幸 別れ 失礼 質問 子供 いない 夫婦 不幸 聞こえる 言葉 気をつけ た方 いい 返し かっけ ぇ ー 通り 子供 いない 可哀想 不幸 構図 おかしい \n",
      "最近 娘 省略 ない 寸劇 遊ん いる お父さん 絶対 省略 ない として 有名 省略 ない さすが デジタルバーサタイルディスク すごーい ほんとに 省略 ない 省略 ない \n",
      "昔 現象 恐れ 山 妖怪 譚 よく 山 絶対 食料 残せ 歩き 続け いる 急 重く たり 頭 モヤ かかっ 餓鬼 つい いる 食べ物 入れる 祓え 正体 低血糖 \n",
      "雑誌 売れ行き 出版 科学研究所 調査 \n",
      "今週 ご覧 いただき ありがとう 来年 森高千里 熊本 コンサート 密着 さらに 来 年月 デビュー 総勢 音楽 トーク 来年 結成 周年 インタビュー 来年 楽しみ \n",
      "一気 コール 大好き すぎ 頭から 離れ ない 笑 グランプリ すゑひろがりず すえひろがり \n",
      "やべっち プレゼント チャレンジ 日本代表 橋岡大樹 上田 綺 世 小川航基 遠藤渓太 サイン 入り ユニフォーム ツイート 以内 フォロー リツイート 抽選 プレゼント 引用 リツイート 希望 選手 記入 当選者 月日 まで 連絡 \n",
      "やべっち プレゼントチャレンジフットサル 対決 両 チーム サイン 入り ユニフォーム ツイート 以内 フォロー リツイート 抽選 プレゼント 引用 リツイート 希望 チーム 記入 当選者 月日 まで 連絡 \n",
      "やべっち プレゼント チャレンジ 五輪 オールスターズ 選手 サイン 入り シューズ ツイート 以内 フォロー リツイート 抽選 プレゼント 引用 リツイート 希望 選手 記入 当選者 公式アカウント 月日 まで 連絡 \n",
      "中国 北東部 農場 地元 ギャング アフリカ豚コレラ 感染 広げる ドローン 使っ 病原菌 落と 農場 オーナー 強力 ジャミング 機器 防ご 飛行場 注意 受けて 争い 発覚 紙 記事 状況 カオス すぎ \n",
      "いじめられる側 原因 ない じゃ なく いじめられる側 原因 として いじめ いけ ない 原因 ない いじめられる側 原因 いじめ ない 言い 逃れ でき ちゃう \n",
      "上皇 まだ 存命 のに 急 国民 誕生日 祝わ なく かわいそう 思う 休み ましょ \n",
      "同棲 信用 出来 ない 言わ キャッシュカード 渡し ひと月 使わ \n",
      "改めて 最終話 まで 過去 アンク 言葉 改めて アンク として 魂 吹き込み オーズ 大切 くださる 皆様 ただ メダル 塊 生かし 頂けれ 嬉しく 思い \n",
      "ついに 本日 ️ サザンオールスターズ 楽曲 全曲 ストリーミング 配信スタート なり ️ サザン 全 シングル アルバム 加え メンバー ソロ 作品 一斉に 配信スタート なんと 曲 超え ️ サザン 音楽 と共に お過ごし 下さい \n",
      "ワールドトリガー 月日 まで 巻 無料 チャンス 滅多 ない 友達 誘っ 年末年始 一緒 読み ましょ ワールドトリガー \n",
      "荷 重かっ 以外 ゴチメンバー クビ 見届ける こんなに 辛い ケンティー 太鳳 本当に お疲れ様 終わっ 写真 撮ろ 言っ 明るく 振る舞っ くれ ゴチメンバー 優しさ 感動 本当に 最高 メンバー 写真 ケンティー 撮っ くれ \n",
      "ポチャッコ クッキー ふーん ふん 買い \n",
      "詩織 に関して もう 酒 飲ま ない 良い 少子化 進み リプ おじさん 限界 過ぎ 酒 飲む 性行為 認識 誤り だし 合意 無い 性行為 強姦 理解 危険 全て 間違え いる 君 もう 酒 飲ま ない 良い 決意 だけ 正しい \n",
      "山口 考える 性的 合意 どう いっ 質問 明確 性行為 合意 あり 答え 伊藤 さんご 本人 そういう 合意 言葉 質問 にも いと 答え 部分 質問 続 \n",
      "なんか バラエティ番組 有吉ジャポン スタッフ 理由 不明 ドール オーナー 接触 図っ いる らしい に対して オーナー 警戒 示し いる がさ あり 編集 いくら 切り取れる メディア どう 使わ れる 分かっ ない \n",
      "かんぽ 不祥事 ワロタ 日本郵政 訴状が届いていないので お答え でき ない お前 届ける \n",
      "鬼滅の刃 コラボ ローソン 国際展示場駅 では 限定 鬼滅の刃 コラボ 実施 キャラクタースタンディ ポスター 展示 また 入店 音 炭 治郎 禰 豆子 善 逸 伊之助 ボイス ランダム おり ぜひ チェック 鬼滅の刃 \n",
      "朝 気分 悪く ごめんなさい はっきり 申し上げ 飲み屋 モラル マナー 知ら ない 本当に 多 すぎる 文句 なら 来 なく 大丈夫 私たち ボランティア ない 年明け 言い たく ない 明ける 過去 まとめ 置い おき \n",
      "若月健矢 選手 立花理香 結婚 おめでとう 末長く 幸せ バファローズ 祝 ️ ポンタ \n",
      "僕たち 嵐 コラボレーション いただい 新曲 ミュージックビデオ 週間 リリース 嵐 \n",
      "報告 みなさま 報告 でき ぜひ ご覧 いただけ 幸い \n",
      "本 日月 竈門 禰豆 誕生 日本 鬼 あり ながら 鬼 殺 隊 所属 炭 治郎 自慢 妹 竈門 禰豆 誕生日 特別 祝し 禰豆 魅力 詰まっ ヘッダー プレゼント 守る 鬼 使う 禰豆 ヘッダー ぜひ 活用 \n",
      "鬼滅の刃 グッズ プレゼント 大 好評 シリーズ 累計 記念 鬼滅の刃 全巻 セット プレゼント 応募方法 フォローリツィート 応募 リプ 応募期間 月日 当選 にて お知らせ \n",
      "アニメーター 始め 初めて キャベツ 描い 妙 プレッシャー 炎炎ノ消防隊 \n",
      "弐 ノ 章 制作 放送 決定 壱 ノ 章 続編 アニメ 炎炎ノ消防隊 弐 ノ 章 制作 決定 さら 弐 ノ 章 ティザービジュアル 発表 炎 炎 炎 ますます 燃え 続け 炎炎ノ消防隊 弐 ノ 章 期待 炎炎ノ消防隊 弐 ノ 章 \n",
      "祝 月日 竈門 禰豆 誕生日 鬼滅の刃 登場キャラクター 主人公 竈門炭治郎 妹 物語 開始 歳歳 家族 慎ましく 幸せ 生活 送っ 突然 惨劇 により 鬼 変貌 しまう 喰らう 鬼 として 衝動 抑え込み ながら 炭 治郎 仲間 行動 \n",
      "グランブルーファンタジー 本日 より 放送 放送 記念 宝 晶 石 プレゼントグラブルアニメグラブル \n",
      "コミケ 会場 プライス カード 忘れ 落ち着い 机 チラシ 下さい 全て サークル 机 プライス カード 置い 不要 ごめんなさい \n",
      "ボーボボ アフロ 分かり やすい スターター セット 貼っ おき \n",
      "チュートリアル お世話 キャラ 実は 最強 裏 ボス っていう ゲーム \n",
      "ステ ウルトラ 生放送中 女々しく 周 お祝い 駆けつけ くれ なんと ボボボーボボーボボ ️ ボボボーボボーボボウルトラタモリステ \n",
      "クソワロ 女々しく 発売 人気キャラ 駆けつける ボボボーボボーボボ ステ 金爆 \n",
      "なにわ 男子 ありがとう アオハル ツアー 愛知 公演 ー コンサート 締めくくる でき ふぁ むのみなさんへ 最高 ありがとう なにわ 男子 報告 \n",
      "昨日 恩師 あり 恩人 あり ホンモノ 小栗旬 誕生 夜中 正装 会い 行き おめでとう ー のっ \n",
      "嵐 松潤 ゴーちゃん オス 聞か ブイ 松潤 思う ブイウルトラステウルトラゴー \n",
      "ノンストップ ストーリーライブキービジュアル ホロライブメンバー 描か いただき たおる だん デザイン 衣装 素敵 すぎる ライブ 楽しみ \n",
      "嵐 松潤 いつも 入っ いる 暑く ない 話しかけ くれ ブイ 正直 質問 意味 よく 分から なかっ とにかく お話 でき 本当に うれしかっ ブイウルトラステウルトラゴー \n",
      "ステ カメラ 初 登場 今日 テーマ 今年 番 盛り上がっ M ナゾ ナゾ メンバー 巻き込ん 大事 答え 森 本 今日 披露 くれ ウルトラ ステ \n",
      "可愛い 可愛い かずま ふじ 疲れ ハイロー \n",
      "ディズニー 限定 デザイン フォロー 投稿 リツイート ラッシュ ニスタハイパーシャープライナーパウダーインペンシル ミッキーマウス デザイン 抽選 当たる チャンス 応募 まで メイベリン \n",
      "ステ カメラ 初 登場 今日 テーマ 今年 番 盛り上がっ M 後輩 グループ 乱入 発展 方向性 改める 来年 期待 大 今日 ある日 願い 叶っ 披露 ウルトラ ステ \n",
      "鬼 手袋 編み 左手 ジャスト フィット 厚手 生地 かい 妖怪 退治 使える 今冬 マストアイテム \n",
      "刀剣乱舞 大 演 練 年月 東京ドーム にて 開催決定 \n",
      "先輩 ざい 後輩 描き 先輩 ざい 後輩 \n",
      "公式 刀剣乱舞 大 演 練 年月 東京ドーム にて 開催決定 お知らせ 追加 \n",
      "注意喚起 寝 いる 財布 抜き取る 犯罪 発生 いる 連絡 警察 あり 待機列 皆さん 声 掛け合っ 注意 残念 ながら コミケ 会期 連続 スリ 現行犯逮捕 起き お宝 資金 しっかり 管理 \n",
      "コミックマーケット 深夜 来場 認め おり ませ 絶対 深夜 来場 ない お願い すみやか 帰り 下さい \n",
      "イオン マスク 禁止 従業 人嫌 がる わかる インフル 出 停止 薬効 元気 イオン 遊ばせ 来 凄く 多い 店員 媒介 なら ない 全店 マスク 奨励 理解 下さい アナウンス れる 余程 良い イオン マスク 禁止 撤回 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#パラメータの設定\n",
    "\n",
    "#取得したデータのパス\n",
    "data = './output/buzz_tweet.csv'\n",
    "#取得したい列名\n",
    "columns = [\"Followers\", \"Full_text\",\"Favorite_count\",\"Posi_score\", \"Nega_score\",\"Judge\"]#[\"text\",\"favorites\"]\n",
    "#出力ファイル名\n",
    "out_file = \"train_buzz.txt\"\n",
    "#学習データの保存モード　'a'：追加／'w'：上書き\n",
    "mode = 'w'\n",
    "#ツイートテキストの列を指定\n",
    "text = \"Full_text\"\n",
    "#判定させたいツイート予定文書（類似度確認のため、データセット内にあるツイート文を使用）\n",
    "similar = \"イオンマスク禁止従業員の人嫌がるのわかるわ。\\\n",
    "インフルで出校停止中なんだけど薬効いて体元気だからイオン遊ばせに来た。みたいな事凄く多いんだよ。\\\n",
    "『店員が媒介にならないよう全店でマスク奨励してます。ご理解下さい』\\\n",
    "ってアナウンスされる方が余程良いのでイオンさん、マスク禁止撤回して\"\n",
    "\n",
    "FM = For_Model(data, columns, out_file, mode, text, similar)\n",
    "df_tweet = FM.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ３）予測モデルを生成\n",
    "　・データセットをDoc２vecで学習<br>\n",
    "\n",
    "#### 参考サイト\n",
    "fastTextとDoc2Vecのモデルを作成してニュース記事の多クラス分類の精度を比較する<br> https://qiita.com/kazuki_hayakawa/items/ca5d4735b9514895e197<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc２vec文書ベクトル用モデルに学習させたツイート数 254\n"
     ]
    }
   ],
   "source": [
    "#Doc2Vecモデルの学習\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "f = open('./output/train_buzz.txt','r')#空白で単語を区切り、改行で文書を区切っているテキストデータ\n",
    "\n",
    "#１文書ずつ、単語に分割してリストに入れていく[([単語1,単語2,単語3],文書id),...]こんなイメージ\n",
    "#words：文書に含まれる単語のリスト（単語の重複あり）\n",
    "# tags：文書の識別子（リストで指定．1つの文書に複数のタグを付与できる）\n",
    "#fにテキスト データをいれる\n",
    "trainings = [TaggedDocument(words = data.split(),tags = [i]) for i,data in enumerate(f)]\n",
    "#print(type(trainings))\n",
    "print(\"Doc２vec文書ベクトル用モデルに学習させたツイート数\",len(trainings))\n",
    "# print(trainings[:20])\n",
    "\n",
    "#文書ベクトル用ツイートテキストの学習\n",
    "model = Doc2Vec(\n",
    "    documents= trainings, \n",
    "    dm = 1, \n",
    "    vector_size=300, \n",
    "    window=10, \n",
    "    alpha = 0.05, \n",
    "    min_count=1, \n",
    "    sample = 0, \n",
    "    workers=4, \n",
    "    epochs = 50\n",
    ")\n",
    "\n",
    "#出力用ディレクトリ作成（存在しない場合のみ）\n",
    "def Make_Dir():\n",
    "    new_dir_path = 'model'\n",
    "    try:\n",
    "        os.makedirs(new_dir_path)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "# モデルのセーブ\n",
    "Make_Dir()\n",
    "model.save(\"./model/doc2vec.model\")\n",
    "\n",
    "# モデルのロード(モデルが用意してあれば、ここからで良い)\n",
    "m = Doc2Vec.load('./model/doc2vec.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ４）ツイート予定文章のネガポジ予測を返す\n",
    "　・データセットから、入力しておいたツイート予定文書と似ている文書を探す<br>\n",
    "・ネガポジスコア付きで、類似ツイート上位１０個を返す<br>\n",
    "#### 結果：成功。入力文書と同じツイート文が類似度１位に。ネガポジもデータズレなく表示できた"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== 判定したいツイート ===========\n",
      "\n",
      "イオンマスク禁止従業員の人嫌がるのわかるわ。インフルで出校停止中なんだけど薬効いて体元気だからイオン遊ばせに来た。みたいな事凄く多いんだよ。『店員が媒介にならないよう全店でマスク奨励してます。ご理解下さい』ってアナウンスされる方が余程良いのでイオンさん、マスク禁止撤回して\n",
      "\n",
      "======= 類似度上位１０（全254ツイート中） =======\n",
      "\n",
      "…………　類似ツイート1位：類似度 0.9934　…………\n",
      "\n",
      "イオンマスク禁止従業員の人嫌がるのわかるわ。\n",
      "\n",
      "インフルで出校停止中なんだけど薬効いて体元気だからイオン遊ばせに来た。\n",
      "みたいな事凄く多いんだよ。\n",
      "\n",
      "『店員が媒介にならないよう全店でマスク奨励してます。ご理解下さい』\n",
      "ってアナウンスされる方が余程良いのでイオンさん、マスク禁止撤回して\n",
      "\n",
      "【極性】： negative\n",
      "posi_score： 219.0 ／ nega_score： 257.0\n",
      "\n",
      "…………　類似ツイート2位：類似度 0.9563　…………\n",
      "\n",
      "マスクせずに咳してる人見ると、\n",
      "「感染者だ！撃ち殺せ！」\n",
      "「ですが！アイツはまだ人間じゃないですか！」\n",
      "「馬鹿野郎！ここで殺らなきゃ、俺達の大事な奴まで感染者にされる可能性だってあるんだ！迷うな！引き金を引け！」\n",
      "「畜生！感染者め！」\n",
      "みたいな気持ちになる。マスクしやがり下さい。\n",
      "\n",
      "【極性】： negative\n",
      "posi_score： 119.0 ／ nega_score： 213.0\n",
      "\n",
      "…………　類似ツイート3位：類似度 0.9296　…………\n",
      "\n",
      "お客様に言いたいのは、店員にマスクをしてほしくないなら、お客様がしてくれと言うことと、ポイントカードの有無も答えず、キャッシュ決済で払も無言でスマホだけレジ台に置く、会計時イヤホン外さない、こういう人は、「何言ってるか聞こえない」なんて言う権利ないからな！\n",
      "＃マスク禁止\n",
      "\n",
      "【極性】： negative\n",
      "posi_score： 105.0 ／ nega_score： 118.0\n",
      "\n",
      "…………　類似ツイート4位：類似度 0.9189　…………\n",
      "\n",
      "詩織さんに関して「もう女と酒を飲まない方が良い。これで少子化が進みそう」とリプしたおじさん、限界過ぎ。\n",
      "女と酒飲む＝性行為という認識が誤りだし、合意の無い性行為＝強姦だと理解してなさそうなのも危険。全てを間違えているが、君が”もう女と酒を飲まない方が良い”という決意だけは正しいよ。\n",
      "\n",
      "【極性】： negative\n",
      "posi_score： 123.0 ／ nega_score： 139.0\n",
      "\n",
      "…………　類似ツイート5位：類似度 0.9154　…………\n",
      "\n",
      "あんまりにもお客さん来なくて早くも廃業しそうなので、メニュー看板出してみたり試行錯誤中です 。\n",
      "\n",
      "怖い店じゃないですよ！\n",
      "怪しい店じゃないですよ！\n",
      "フラッと入ってくれていいんですよ！ \n",
      "\n",
      "【極性】： positive\n",
      "posi_score： 163.0 ／ nega_score： 66.0\n",
      "\n",
      "…………　類似ツイート6位：類似度 0.9131　…………\n",
      "\n",
      "スマホに慣れてないお年寄りはiPhoneを選んだほうがいいです。楽々スマホとか買われると、僕らが使い方分からないので使い方を聞かれても教えてあげられません。設定とかアプリ一覧を出すのにも一苦労でした。マジで楽々スマホはやめて。使い方を誰かに聞くつもりなら絶対買っちゃダメ。\n",
      "\n",
      "【極性】： positive\n",
      "posi_score： 190.0 ／ nega_score： 157.0\n",
      "\n",
      "…………　類似ツイート7位：類似度 0.9092　…………\n",
      "\n",
      "コミックマーケットでは深夜来場は認めておりません。絶対に深夜来場をしないようにお願いします。すみやかにお帰り下さい。 #C97 \n",
      "\n",
      "【極性】： negative\n",
      "posi_score： 70.0 ／ nega_score： 99.0\n",
      "\n",
      "…………　類似ツイート8位：類似度 0.9076　…………\n",
      "\n",
      "いまテレビで『子どもが泣いてる→妻は家事で手が離せない→こんな時、夫は「子どもが泣いてるよ」ではなく「こういう時ママじゃないと泣き止まないんだよね〜」と言えば、妻をイラッとさせません』とか言ってるんですが！いや、めちゃめちゃイラッとするわ！泣き止まなくてもやるんだよ！！！！！！\n",
      "\n",
      "【極性】： negative\n",
      "posi_score： 115.0 ／ nega_score： 124.0\n",
      "\n",
      "…………　類似ツイート9位：類似度 0.9075　…………\n",
      "\n",
      "面接官「君の出身地は？」\n",
      "\n",
      "僕「おもちゃのまちです…」\n",
      "\n",
      "面接官「真面目に答えて下さいwそんなメルヘンチックな地名があるはずないでしょww不採用！」 \n",
      "\n",
      "【極性】： positive\n",
      "posi_score： 41.0 ／ nega_score： 27.0\n",
      "\n",
      "…………　類似ツイート10位：類似度 0.9035　…………\n",
      "\n",
      "得意げに\n",
      "「俺めっちゃ食うのに太らないんだよね笑\n",
      "48キロ笑笑、そこらへんの女子より軽いと思うわ笑」\n",
      "とか言ってる男がいたので\n",
      "「筋肉がないからだね。」\n",
      "って言ったらあからさまに不機嫌になってました。\n",
      "\n",
      "【極性】： negative\n",
      "posi_score： 122.0 ／ nega_score： 137.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#類似判定と類似している上位10件の文書を出力\n",
    "\n",
    "top10 = m.docvecs.most_similar(len(trainings) - 1)\n",
    "\n",
    "print(\"=========== 判定したいツイート ===========\\n\")\n",
    "print(similar)\n",
    "\n",
    "print()\n",
    "print(\"======= 類似度上位１０（全{}ツイート中） =======\".format(len(trainings)))\n",
    "print()\n",
    "for i in range(len(top10)):\n",
    "    score = top10[i]\n",
    "    index = int(score[0])\n",
    "    similar_score = score[1]\n",
    "    tweet = df_tweet[\"Full_text\"]\n",
    "    judge = df_tweet[\"Judge\"]\n",
    "    posi_score = df_tweet[\"Posi_score\"]\n",
    "    nega_score = df_tweet[\"Nega_score\"]\n",
    "    print(\"…………　類似ツイート{}位：類似度 {:.4g}　…………\".format((i+1), similar_score))\n",
    "    print()\n",
    "    print(tweet[index])\n",
    "    print()\n",
    "    print(\"【極性】：\", judge[index])\n",
    "    print(\"posi_score：\",posi_score[index], \"／\", \"nega_score：\", nega_score[index])\n",
    "\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# その他試みたこと\n",
    "断念、または精度が全く良くない。覚書として記録"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## １）文章ベクトルを特徴量としたネガポジ予測モデル\n",
    "　・文章ベクトルとフォロワー数を特徴量X、ネガポジスコアを目的変数yとしたデータを学習<br>\n",
    "　・文章ベクトルはDoc２vecとTf-idfの２種を作成<br>\n",
    "　・ツイート予定文書を入力してネガポジスコアを予測する<br>\n",
    "　・試した予測モデル<br>\n",
    "　・MultiOutputRegressor、SVRのrbf と　SVRの線形、lightgbm、ランダムフォレスト<br>\n",
    "#### 結果：精度が低すぎて断念<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2vecで文章ベクトル取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ベクトル化するセンチメントスコア付きデータ数： 308\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Followers</th>\n",
       "      <th>Full_text</th>\n",
       "      <th>Nega_score</th>\n",
       "      <th>Posi_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6800.0</td>\n",
       "      <td>君、すごい食い方やな\\n https://t.co/yRTGvd43wT</td>\n",
       "      <td>31.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1564.0</td>\n",
       "      <td>絶対断らないと評判の病児保育室、助成金下りず2億円の赤字を出し閉鎖\\n\\n全国に2886カ所...</td>\n",
       "      <td>148.0</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2217.0</td>\n",
       "      <td>全国の皆さんへ\\nどうか皆様のお力を貸してください。\\n\\n１日も早く娘を助けたいです。\\n...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3756.0</td>\n",
       "      <td>o0( 歴史上、さんざん他国の料理を魔改造してきた我が国が「寿司ポリス」などどは片腹痛い！あ...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7363.0</td>\n",
       "      <td>百合関係図です。 https://t.co/hZxIYOsSag</td>\n",
       "      <td>58.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Followers                                          Full_text  Nega_score  \\\n",
       "0     6800.0               君、すごい食い方やな\\n https://t.co/yRTGvd43wT        31.0   \n",
       "1     1564.0  絶対断らないと評判の病児保育室、助成金下りず2億円の赤字を出し閉鎖\\n\\n全国に2886カ所...       148.0   \n",
       "2     2217.0  全国の皆さんへ\\nどうか皆様のお力を貸してください。\\n\\n１日も早く娘を助けたいです。\\n...        50.0   \n",
       "3     3756.0  o0( 歴史上、さんざん他国の料理を魔改造してきた我が国が「寿司ポリス」などどは片腹痛い！あ...        85.0   \n",
       "4     7363.0                   百合関係図です。 https://t.co/hZxIYOsSag        58.0   \n",
       "\n",
       "   Posi_score  \n",
       "0        75.0  \n",
       "1       168.0  \n",
       "2       129.0  \n",
       "3       137.0  \n",
       "4        82.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Doc2vecでベクトル化\n",
    "from natto import MeCab\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df_buzz = pd.read_csv('./output/buzz_tweet.csv',\n",
    "                      usecols = [\"Full_text\", \"Posi_score\", \"Nega_score\", \"Followers\"])\n",
    "#.to_csv('./output/for_training.csv', mode = \"a\", index = False, header = None)\n",
    "#pd.read_csv('./output/fire_buzz_tweet.csv', usecols = [\"Full_text\", \"Judge\", \"Sentiment\"]).to_csv('./output/for_training.csv', mode = \"a\", index = False, header = None)\n",
    "print(\"ベクトル化するセンチメントスコア付きデータ数：\", len(df_buzz))\n",
    "display(df_buzz.head())\n",
    "\n",
    "#doc2vecでベクトル化\n",
    "for_training = df_buzz['Full_text']\n",
    "#print(for_training)\n",
    "vector_tweet = []\n",
    "for i in for_training:\n",
    "    i = m.infer_vector(i)\n",
    "    vector_tweet.append(i)\n",
    "\n",
    "df_vector = pd.DataFrame(data = vector_tweet)\n",
    "\n",
    "# print(\"Doc2vecベクトル\")\n",
    "# display(df_vector.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idfでベクトル取得\n",
    "#### 参考サイト\n",
    "\n",
    "機械学習_サポートベクターマシーン_pythonで実装<br>\n",
    "https://dev.classmethod.jp/machine-learning/2017ad_20171214_svm_python/<br>\n",
    "Tf-idfベクトルってなんだ？<br> https://qiita.com/MasatoTsutsumi/items/5b0a140b1ecbdd0396e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(308, 2038)\n",
      "次元削減後の特徴量が5の時の説明できる分散の割合合計は0.04です\n",
      "次元削減後の特徴量が10の時の説明できる分散の割合合計は0.06です\n",
      "次元削減後の特徴量が50の時の説明できる分散の割合合計は0.2です\n",
      "次元削減後の特徴量が100の時の説明できる分散の割合合計は0.36です\n",
      "次元削減後の特徴量が500の時の説明できる分散の割合合計は1.0です\n",
      "次元削減後の特徴量が1000の時の説明できる分散の割合合計は1.0です\n"
     ]
    }
   ],
   "source": [
    "# 2-1.tf-idf計算\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def Stop_Words():\n",
    "    # ストップワードをダウンロード\n",
    "    url = 'http://svn.sourceforge.jp/svnroot/slothlib/CSharp/Version1/SlothLib/NLP/Filter/StopWord/word/Japanese.txt'\n",
    "    urllib.request.urlretrieve(url, './output/stop_word.txt')\n",
    "\n",
    "    with open('./output/stop_word.txt', 'r', encoding='utf-8') as file:\n",
    "        stopwords = [word.replace('\\n', '') for word in file.readlines()]\n",
    "\n",
    "    #追加ストップワードを設定（助詞や意味のない平仮名１文字）\n",
    "    add_words = ['あ','い','う','え','お','か','き','く','け','こ','さ','し','す','せ','そ','た','ち','つ','て','と',\n",
    "                 'な','に','ぬ','ね','の','は','ひ','ふ','へ','ほ','ま','み','む','め','も','や','ゆ','よ',\n",
    "                 'ら','り','る','れ','ろ','わ','を','ん','が','ぎ','ぐ','げ','ご','ざ','じ','ず','ぜ','ぞ',\n",
    "                 'だ','ぢ','づ','で','ど','ば','び','ぶ','べ','ぼ','ぱ','ぴ','ぷ','ぺ','ぽ',\n",
    "                 'くん','です','ます','ました','そして','でも','だから','だが','くらい','その','それ','かも',\n",
    "                 'あれ','あの','あっ','そんな','この','これ','とか','とも','する','という','ござい',\n",
    "                 'ので','なんて','たら', 'られ','たい','さて','てる','ください','なる','けど','でし',\n",
    "                 'じゃん','だっ','なっ','でしょ', 'ある','って','こんな','ねえ'\n",
    "                ]\n",
    "    stopwords = stopwords + add_words\n",
    "    return stopwords\n",
    "\n",
    "stopwords = Stop_Words()\n",
    "tfidfv = TfidfVectorizer(lowercase=True, stop_words=stopwords) # stop words処理\n",
    " \n",
    "tfv_vector_fit = tfidfv.fit(for_training)\n",
    "tfv_vector = tfv_vector_fit.transform(for_training)\n",
    "print(tfv_vector.shape) \n",
    "\n",
    "# 2-2.次元削減(「lsa」を使って次元削減を行う)\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# 2-2-1.パラメータの調整\n",
    "list_n_comp = [5,10,50,100,500,1000] # 特徴量を何個に削減するか、というパラメータです。できるだけ情報量を欠損しないで、かつ次元数は少なくしたいですね。\n",
    "for i in list_n_comp:\n",
    "    lsa = TruncatedSVD(n_components=i,n_iter=5, random_state = 0)\n",
    "    lsa.fit(tfv_vector) \n",
    "    tfv_vector_lsa = lsa.transform(tfv_vector)\n",
    "    print('次元削減後の特徴量が{0}の時の説明できる分散の割合合計は{1}です'.format(i,round((sum(lsa.explained_variance_ratio_)),2)))\n",
    "\n",
    "# 2-2-2.次元削減した状態のデータを作成\n",
    "# 上記で確認した「n_components」に指定した上で、次元削減（特徴抽出）を行う\n",
    "lsa = TruncatedSVD(n_components=1000, n_iter=5, random_state = 0) # 今回は次元数を1000に指定\n",
    "lsa.fit(tfv_vector)\n",
    "X_tf = lsa.transform(tfv_vector)\n",
    "# print()\n",
    "# print(\"次元削減後Tf-idfベクトル\\n\", X_tf.shape)\n",
    "# print(X_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "欠損値削除前データ (307, 4)\n",
      "\n",
      "Doc2vecベクトル\n",
      "X.shape (307, 301)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Followers</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6800.0</td>\n",
       "      <td>0.013712</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>-0.011958</td>\n",
       "      <td>-0.010011</td>\n",
       "      <td>0.030667</td>\n",
       "      <td>0.018747</td>\n",
       "      <td>-0.013943</td>\n",
       "      <td>0.009593</td>\n",
       "      <td>-0.002913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019474</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>-0.013615</td>\n",
       "      <td>0.001718</td>\n",
       "      <td>0.029068</td>\n",
       "      <td>0.021951</td>\n",
       "      <td>0.015445</td>\n",
       "      <td>-0.005926</td>\n",
       "      <td>-0.009584</td>\n",
       "      <td>-0.024975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1564.0</td>\n",
       "      <td>0.021855</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>-0.009026</td>\n",
       "      <td>-0.024573</td>\n",
       "      <td>0.014405</td>\n",
       "      <td>0.030817</td>\n",
       "      <td>-0.010246</td>\n",
       "      <td>0.027657</td>\n",
       "      <td>-0.004478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023794</td>\n",
       "      <td>0.003821</td>\n",
       "      <td>-0.010664</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>0.012792</td>\n",
       "      <td>0.008937</td>\n",
       "      <td>0.004685</td>\n",
       "      <td>0.006093</td>\n",
       "      <td>-0.023806</td>\n",
       "      <td>-0.024231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2217.0</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>-0.006724</td>\n",
       "      <td>-0.008196</td>\n",
       "      <td>-0.011883</td>\n",
       "      <td>0.033857</td>\n",
       "      <td>0.006988</td>\n",
       "      <td>-0.013092</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014613</td>\n",
       "      <td>0.004554</td>\n",
       "      <td>-0.003018</td>\n",
       "      <td>0.014777</td>\n",
       "      <td>0.030124</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.016303</td>\n",
       "      <td>-0.014497</td>\n",
       "      <td>0.002742</td>\n",
       "      <td>-0.015558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3756.0</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>0.006586</td>\n",
       "      <td>0.010837</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>0.013797</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>-0.012791</td>\n",
       "      <td>-0.001024</td>\n",
       "      <td>-0.005264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006826</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.018484</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.005455</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>-0.012708</td>\n",
       "      <td>0.001583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7363.0</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>-0.006778</td>\n",
       "      <td>-0.006213</td>\n",
       "      <td>-0.014475</td>\n",
       "      <td>0.028134</td>\n",
       "      <td>0.008578</td>\n",
       "      <td>-0.012496</td>\n",
       "      <td>0.006429</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012125</td>\n",
       "      <td>0.004307</td>\n",
       "      <td>-0.006882</td>\n",
       "      <td>0.009480</td>\n",
       "      <td>0.022597</td>\n",
       "      <td>0.028421</td>\n",
       "      <td>0.015285</td>\n",
       "      <td>-0.008094</td>\n",
       "      <td>-0.002776</td>\n",
       "      <td>-0.009579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Followers         0         1         2         3         4         5  \\\n",
       "0     6800.0  0.013712  0.001771 -0.011958 -0.010011  0.030667  0.018747   \n",
       "1     1564.0  0.021855  0.000419 -0.009026 -0.024573  0.014405  0.030817   \n",
       "2     2217.0 -0.000127 -0.006724 -0.008196 -0.011883  0.033857  0.006988   \n",
       "3     3756.0  0.006243  0.006586  0.010837  0.006348  0.013797  0.000452   \n",
       "4     7363.0  0.004367 -0.006778 -0.006213 -0.014475  0.028134  0.008578   \n",
       "\n",
       "          6         7         8    ...          290       291       292  \\\n",
       "0 -0.013943  0.009593 -0.002913    ...     0.019474  0.003289 -0.013615   \n",
       "1 -0.010246  0.027657 -0.004478    ...     0.023794  0.003821 -0.010664   \n",
       "2 -0.013092  0.004137  0.002084    ...     0.014613  0.004554 -0.003018   \n",
       "3 -0.012791 -0.001024 -0.005264    ...     0.007500  0.006826  0.003031   \n",
       "4 -0.012496  0.006429  0.001018    ...     0.012125  0.004307 -0.006882   \n",
       "\n",
       "        293       294       295       296       297       298       299  \n",
       "0  0.001718  0.029068  0.021951  0.015445 -0.005926 -0.009584 -0.024975  \n",
       "1  0.002451  0.012792  0.008937  0.004685  0.006093 -0.023806 -0.024231  \n",
       "2  0.014777  0.030124  0.030675  0.016303 -0.014497  0.002742 -0.015558  \n",
       "3  0.011547  0.018484  0.017857  0.005455  0.002538 -0.012708  0.001583  \n",
       "4  0.009480  0.022597  0.028421  0.015285 -0.008094 -0.002776 -0.009579  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tf-idfベクトル\n",
      "X_tf_idf.shape (307, 309)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Followers</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "      <th>301</th>\n",
       "      <th>302</th>\n",
       "      <th>303</th>\n",
       "      <th>304</th>\n",
       "      <th>305</th>\n",
       "      <th>306</th>\n",
       "      <th>307</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6800.0</td>\n",
       "      <td>0.289868</td>\n",
       "      <td>-0.000427</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>-0.002769</td>\n",
       "      <td>-1.424757e-16</td>\n",
       "      <td>-0.005925</td>\n",
       "      <td>-0.011368</td>\n",
       "      <td>-0.014004</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.008939e-07</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>-0.003888</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>2.827210e-18</td>\n",
       "      <td>-0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1564.0</td>\n",
       "      <td>0.172859</td>\n",
       "      <td>-0.000260</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>-0.001753</td>\n",
       "      <td>-6.100152e-16</td>\n",
       "      <td>-0.003930</td>\n",
       "      <td>-0.007584</td>\n",
       "      <td>-0.009409</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.420091e-07</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>-0.002029</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>-0.000057</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>-1.025210e-16</td>\n",
       "      <td>-0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2217.0</td>\n",
       "      <td>0.108238</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.001208</td>\n",
       "      <td>3.493364e-16</td>\n",
       "      <td>-0.002950</td>\n",
       "      <td>-0.005759</td>\n",
       "      <td>-0.007248</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.183614e-07</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>-0.001073</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-5.549815e-17</td>\n",
       "      <td>-0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3756.0</td>\n",
       "      <td>0.110438</td>\n",
       "      <td>-0.000167</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.001143</td>\n",
       "      <td>2.116256e-17</td>\n",
       "      <td>-0.002606</td>\n",
       "      <td>-0.005039</td>\n",
       "      <td>-0.006268</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.456683e-07</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>-0.001246</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>5.629822e-17</td>\n",
       "      <td>-0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7363.0</td>\n",
       "      <td>0.289868</td>\n",
       "      <td>-0.000427</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>-0.002769</td>\n",
       "      <td>1.624278e-18</td>\n",
       "      <td>-0.005925</td>\n",
       "      <td>-0.011368</td>\n",
       "      <td>-0.014004</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.008939e-07</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>-0.003888</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>8.386501e-17</td>\n",
       "      <td>-0.000027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 309 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Followers         0         1         2         3             4         5  \\\n",
       "0     6800.0  0.289868 -0.000427  0.000041 -0.002769 -1.424757e-16 -0.005925   \n",
       "1     1564.0  0.172859 -0.000260  0.000026 -0.001753 -6.100152e-16 -0.003930   \n",
       "2     2217.0  0.108238 -0.000168  0.000017 -0.001208  3.493364e-16 -0.002950   \n",
       "3     3756.0  0.110438 -0.000167  0.000017 -0.001143  2.116256e-17 -0.002606   \n",
       "4     7363.0  0.289868 -0.000427  0.000041 -0.002769  1.624278e-18 -0.005925   \n",
       "\n",
       "          6         7         8    ...              298       299       300  \\\n",
       "0 -0.011368 -0.014004  0.000940    ...    -5.008939e-07 -0.000008 -0.000028   \n",
       "1 -0.007584 -0.009409  0.000632    ...    -2.420091e-07 -0.000004 -0.000015   \n",
       "2 -0.005759 -0.007248  0.000488    ...    -1.183614e-07 -0.000002 -0.000008   \n",
       "3 -0.005039 -0.006268  0.000421    ...    -1.456683e-07 -0.000003 -0.000009   \n",
       "4 -0.011368 -0.014004  0.000940    ...    -5.008939e-07 -0.000008 -0.000028   \n",
       "\n",
       "        301       302       303       304       305           306       307  \n",
       "0  0.000955 -0.003888  0.000314 -0.000107  0.000044  2.827210e-18 -0.000027  \n",
       "1  0.000496 -0.002029  0.000166 -0.000057  0.000024 -1.025210e-16 -0.000015  \n",
       "2  0.000261 -0.001073  0.000089 -0.000031  0.000013 -5.549815e-17 -0.000008  \n",
       "3  0.000304 -0.001246  0.000102 -0.000036  0.000015  5.629822e-17 -0.000009  \n",
       "4  0.000955 -0.003888  0.000314 -0.000107  0.000044  8.386501e-17 -0.000027  \n",
       "\n",
       "[5 rows x 309 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "y.shape (307, 2)\n"
     ]
    }
   ],
   "source": [
    "#X、yデータを作成\n",
    "\n",
    "#Doc2vecのベクトルデータ\n",
    "print(\"欠損値削除前データ\", df_buzz.shape)\n",
    "print()\n",
    "\n",
    "#文書ベクトルを含んだdf\n",
    "df_buzz_vec = pd.concat([df_buzz, df_vector], axis=1)\n",
    "df_buzz_vec = df_buzz_vec.dropna(subset = [\"Followers\"])#欠損値行削除\n",
    "df_buzz_vec = df_buzz_vec.drop([ \"Full_text\", \"Nega_score\", \"Posi_score\"], axis=1)\n",
    "X = df_buzz_vec.values\n",
    "print(\"Doc2vecベクトル\")\n",
    "print(\"X.shape\", X.shape)\n",
    "display(df_buzz_vec.head())\n",
    "\n",
    "#tf-idfのベクトルデータ\n",
    "tf_df = pd.DataFrame(data = X_tf)\n",
    "tf_df = pd.concat([df_buzz, tf_df], axis=1)\n",
    "tf_df = tf_df.dropna(subset = [\"Followers\"])#欠損値行削除\n",
    "tf_df = tf_df.drop([ \"Full_text\", \"Nega_score\", \"Posi_score\"], axis=1)\n",
    "X_tf_idf = tf_df.values\n",
    "print(\"Tf-idfベクトル\")\n",
    "print(\"X_tf_idf.shape\", tf_df.shape)\n",
    "display(tf_df.head())\n",
    "\n",
    "#yデータ作成\n",
    "df_buzz = df_buzz.dropna(subset = [\"Followers\"])#y用に\"Followers\"の欠損行削除\n",
    "y = df_buzz.loc[:,['Posi_score', 'Nega_score']]#できればDateも特徴量に入れたい\n",
    "y_p = df_buzz['Posi_score']\n",
    "y_n = df_buzz['Nega_score']\n",
    "y = y.values\n",
    "print()\n",
    "print(\"y.shape\", y.shape)\n",
    "y_p = y_p.values\n",
    "y_n = y_n.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiOutputRegressorで複数の回帰¶\n",
    "#### 結果：D2vベクトルよりTf-idfがややマシ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正解\n",
      " [[ 171.  214.]\n",
      " [  65.   79.]\n",
      " [  87.   11.]\n",
      " [  91.   89.]\n",
      " [  95.   57.]\n",
      " [  48.   37.]\n",
      " [  20.   16.]\n",
      " [  18.   46.]\n",
      " [  59.   54.]\n",
      " [  64.  143.]\n",
      " [ 118.   36.]\n",
      " [  76.   46.]\n",
      " [  35.   23.]\n",
      " [  52.   15.]\n",
      " [  44.   30.]\n",
      " [  61.   46.]\n",
      " [  25.   27.]\n",
      " [  65.   43.]\n",
      " [  77.    5.]\n",
      " [  88.   99.]\n",
      " [ 122.  137.]\n",
      " [ 160.  144.]\n",
      " [  63.   29.]\n",
      " [ 118.  227.]\n",
      " [ 114.  173.]\n",
      " [  48.   39.]\n",
      " [ 114.   43.]\n",
      " [  40.   63.]\n",
      " [ 247.   91.]\n",
      " [ 119.  150.]\n",
      " [  87.   28.]\n",
      " [ 124.  102.]\n",
      " [  71.   58.]\n",
      " [  37.   49.]\n",
      " [  73.   59.]\n",
      " [ 128.  197.]\n",
      " [ 127.   89.]\n",
      " [ 180.   46.]\n",
      " [ 283.  219.]\n",
      " [  69.  137.]\n",
      " [ 102.   81.]\n",
      " [  38.   42.]\n",
      " [  45.   35.]\n",
      " [ 210.  169.]\n",
      " [ 186.  106.]\n",
      " [ 156.   20.]\n",
      " [  50.   19.]\n",
      " [ 146.   61.]\n",
      " [  92.   57.]\n",
      " [ 102.   29.]\n",
      " [  90.   19.]\n",
      " [ 197.    9.]\n",
      " [ 219.  257.]\n",
      " [ 117.   26.]\n",
      " [ 116.  142.]\n",
      " [ 179.   41.]\n",
      " [  92.   76.]\n",
      " [ 166.  107.]\n",
      " [ 190.  157.]\n",
      " [ 100.   79.]\n",
      " [ 149.   50.]\n",
      " [ 174.  134.]\n",
      " [  97.   78.]\n",
      " [ 141.   39.]\n",
      " [ 171.  121.]\n",
      " [ 205.   45.]\n",
      " [  90.  147.]\n",
      " [ 244.  126.]\n",
      " [  73.  119.]\n",
      " [  83.   55.]\n",
      " [ 120.   98.]\n",
      " [  53.   15.]\n",
      " [  80.   54.]\n",
      " [  93.  125.]\n",
      " [ 147.   72.]\n",
      " [ 100.   27.]\n",
      " [  31.   18.]\n",
      " [  94.   22.]\n",
      " [  46.   20.]\n",
      " [ 162.   81.]\n",
      " [ 165.   20.]\n",
      " [ 116.   83.]\n",
      " [ 116.   21.]\n",
      " [  93.   12.]\n",
      " [  82.   86.]\n",
      " [ 126.  124.]\n",
      " [  55.   59.]\n",
      " [  84.   24.]\n",
      " [ 112.   35.]\n",
      " [  40.   45.]\n",
      " [ 141.  131.]\n",
      " [  39.   48.]\n",
      " [  79.   49.]]\n",
      "\n",
      "[[  71.26223925   45.69641621]\n",
      " [  91.71150886  109.70124527]\n",
      " [  94.79999886   42.70446606]\n",
      " [ 106.26418186   55.05312126]\n",
      " [ 131.0492575    65.39831431]\n",
      " [  76.59846019   99.92106651]\n",
      " [  88.9802513    31.49987222]\n",
      " [  70.73016596   86.46873366]\n",
      " [  97.88720885   76.36038086]\n",
      " [  81.05516347   56.71423717]\n",
      " [ 104.93165324   98.70462279]\n",
      " [  71.48675833   50.19580375]\n",
      " [  87.41905943   49.1184276 ]\n",
      " [ 106.30873464   61.98777974]\n",
      " [ 105.54526068   79.64833124]\n",
      " [ 129.28451331  135.08782586]\n",
      " [  75.03558316   59.97923976]\n",
      " [ 123.53059715   79.15755312]\n",
      " [ 147.16404875   91.79043613]\n",
      " [ 113.6120413    47.84769971]\n",
      " [ 132.45604301  159.82913378]\n",
      " [ 182.92150429  123.49642596]\n",
      " [ 107.73837372   43.99699196]\n",
      " [  80.06525497   52.67901449]\n",
      " [  89.97177808   40.51336363]\n",
      " [  89.76415746   55.29775603]\n",
      " [  88.17766399   38.42610787]\n",
      " [  82.55557236   59.21466918]\n",
      " [  92.91478898   43.48128906]\n",
      " [  75.54629407   41.70973093]\n",
      " [ 114.00952563  143.69260366]\n",
      " [ 105.86878269   78.12191628]\n",
      " [  95.32562615   42.70261266]\n",
      " [  62.04062382   44.5857466 ]\n",
      " [ 135.06582489   63.05419559]\n",
      " [  93.81089545   47.27557892]\n",
      " [  68.62503965  117.5481493 ]\n",
      " [ 100.68791678   62.84631572]\n",
      " [ 121.11341852   49.37260842]\n",
      " [  82.49633509   80.56893292]\n",
      " [  87.07655069   87.09447147]\n",
      " [ 105.04107167   92.73915255]\n",
      " [ 180.85965592   31.74256093]\n",
      " [  85.64989514   60.29903073]\n",
      " [ 123.64724316   61.98113535]\n",
      " [ 102.58581221   64.59467258]\n",
      " [ 155.54295697  117.55423782]\n",
      " [ 123.85913205   39.79539467]\n",
      " [  78.50004608   50.45473159]\n",
      " [  67.8523264    61.17485024]\n",
      " [ 153.06747187  123.31403031]\n",
      " [  88.09289716   28.72146672]\n",
      " [  91.02419168   85.58530306]\n",
      " [  90.05721596   69.19184031]\n",
      " [  88.10542869   42.93434511]\n",
      " [  98.67119386   88.21313892]\n",
      " [ 123.88634144   85.32877573]\n",
      " [ 150.19763826   58.44545355]\n",
      " [ 121.88789904   81.04046467]\n",
      " [ 103.75540206   97.60850963]\n",
      " [ 155.07595135   44.78468914]\n",
      " [  94.07557506  180.70370375]\n",
      " [  80.29590794   40.88144926]\n",
      " [  63.69480911   13.54988375]\n",
      " [  73.18981456   40.77392671]\n",
      " [  82.84529731   54.87170082]\n",
      " [  81.80999994   54.5970552 ]\n",
      " [  95.35346045   50.39227201]\n",
      " [  98.30205639   67.69409873]\n",
      " [ 131.39641067   64.67760648]\n",
      " [  77.21064558   50.46999012]\n",
      " [  83.33831271   69.66959887]\n",
      " [  78.13011925   40.18466298]\n",
      " [ 115.01581123   77.84874516]\n",
      " [  79.8977288    53.96113971]\n",
      " [ 123.52632528   47.55507313]\n",
      " [  83.91764189   47.86202349]\n",
      " [ 100.59096979   31.4168314 ]\n",
      " [  65.64814479  115.50998029]\n",
      " [  96.98559789   77.8434905 ]\n",
      " [  83.90360581   44.52569079]\n",
      " [  67.35938062   47.82069773]\n",
      " [  70.22669448   47.7539324 ]\n",
      " [ 105.05591908   64.52622452]\n",
      " [ 102.78953779   84.53628998]\n",
      " [ 102.94048364   63.29468581]\n",
      " [  83.23932558   44.40393209]\n",
      " [ 165.09386708   91.6784006 ]\n",
      " [  73.98846273   30.53639194]\n",
      " [  98.55369911   51.65552908]\n",
      " [  63.97066487   46.8471433 ]\n",
      " [ 100.95391531   35.31656222]\n",
      " [ 127.58493462   46.35909289]]\n",
      "R ^ 2_score(1に近いほど良い）： -0.246399014493\n",
      "\n",
      "[[  56.10988451  124.00358339]\n",
      " [ 102.72473532   98.09745828]\n",
      " [  90.4822052    22.54133994]\n",
      " [  82.35930756   77.63741857]\n",
      " [ 149.30598029   35.22899358]\n",
      " [ 121.3267648    69.49452873]\n",
      " [  77.77021908   25.15683986]\n",
      " [  99.33579963   50.32201298]\n",
      " [  84.01427965   85.48879495]\n",
      " [ 106.44555318   67.98701946]\n",
      " [  61.18582205   33.51007615]\n",
      " [ 160.21848983  110.63923886]\n",
      " [ 115.83804127   31.57510478]\n",
      " [  67.95169744   51.41004225]\n",
      " [  96.42098804   73.87521195]\n",
      " [  86.19499476   98.94340795]\n",
      " [  88.79704719   40.6129563 ]\n",
      " [  68.90728205   94.63551394]\n",
      " [  81.2396573    73.57978337]\n",
      " [  75.55265981   30.65876756]\n",
      " [ 104.97964804   48.73698715]\n",
      " [ 151.42093641  106.97142043]\n",
      " [  81.32971334   57.21941546]\n",
      " [  90.23503145   37.25993559]\n",
      " [  98.41029291  104.54215726]\n",
      " [  85.07997357   83.91693575]\n",
      " [  91.83779976   18.15972409]\n",
      " [  82.35930756   72.10661391]\n",
      " [  78.94532448  131.51595521]\n",
      " [ 108.3171425    91.08478455]\n",
      " [  79.07010273   97.33731171]\n",
      " [ 102.10569305   92.22726801]\n",
      " [ 104.18334324   43.81024533]\n",
      " [  98.30208797   40.12601051]\n",
      " [  96.99834429   18.84525845]\n",
      " [  89.75655826   43.48204881]\n",
      " [  98.20291309  112.50201446]\n",
      " [  82.98660113   53.08332639]\n",
      " [  81.14228133   77.12649414]\n",
      " [ 100.90955001  109.65399865]\n",
      " [  96.81620247   89.13532318]\n",
      " [ 103.45954426   69.87597322]\n",
      " [  99.0227987    43.81024533]\n",
      " [ 115.37155716   55.69640837]\n",
      " [  84.71914276   81.36443663]\n",
      " [  93.51143812   43.81024533]\n",
      " [  76.61626328  118.01491645]\n",
      " [ 150.01787744   56.89868157]\n",
      " [  86.81027143   58.15667486]\n",
      " [  81.58874517   79.25325735]\n",
      " [  94.74322799   37.64069353]\n",
      " [ 187.64381734   51.31052878]\n",
      " [  59.16125156   93.46801525]\n",
      " [ 105.12183755   60.88887746]\n",
      " [  74.01151625   41.68969432]\n",
      " [  91.073461     44.12435875]\n",
      " [  85.78942704   71.18543401]\n",
      " [ 156.35169284   66.05900513]\n",
      " [ 127.49837911   81.72236481]\n",
      " [ 121.97688079   97.93254244]\n",
      " [ 152.87676656   63.78012545]\n",
      " [  84.92936073   96.85254375]\n",
      " [  86.2135018    54.41895904]\n",
      " [ 114.77106445   29.39521296]\n",
      " [ 110.21273958   83.92201358]\n",
      " [  85.25059814  101.85490453]\n",
      " [  94.22702008  119.1285799 ]\n",
      " [  88.34455447   62.9815933 ]\n",
      " [ 103.005502     72.24691666]\n",
      " [  73.60010311   72.45552212]\n",
      " [ 125.05298928   83.09869011]\n",
      " [ 111.55731514   50.66686896]\n",
      " [ 153.40175074   91.34466635]\n",
      " [  92.49897511   64.82794051]\n",
      " [ 140.03458631   68.82626804]\n",
      " [  66.84460554   22.79603647]\n",
      " [  83.81886851   43.2901331 ]\n",
      " [  88.40856674   40.68349325]\n",
      " [  91.91145142   55.77531646]\n",
      " [  90.4489353    37.52356712]\n",
      " [ 108.84322913   28.16162639]\n",
      " [ 115.37155716   44.30803427]\n",
      " [ 130.04064189  103.51044282]\n",
      " [  92.67840171   89.07854558]\n",
      " [  98.52692663  131.25224364]\n",
      " [  99.12103537  145.95052896]\n",
      " [  98.87368553   67.45496179]\n",
      " [  87.42323955   53.29089222]\n",
      " [  81.66113192   18.63339356]\n",
      " [ 118.51567517   77.74564094]\n",
      " [  85.68253719   63.92694861]\n",
      " [  90.95877236   46.18981038]\n",
      " [ 111.71456938  124.53237411]]\n",
      "R ^ 2_score(1に近いほど良い）： -0.0421250458745\n"
     ]
    }
   ],
   "source": [
    "#MultiOutputRegressorで複数の回帰\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#D2vベクトル\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.7, test_size=0.3, random_state=0)\n",
    "\n",
    "#X, y = make_regression(n_samples=10, n_targets=3, random_state=1)\n",
    "MOR = MultiOutputRegressor(GradientBoostingRegressor(random_state=0)).fit(X_train, y_train)\n",
    "y_pred = MOR.predict(X_test)\n",
    "score = MOR.score(X_test, y_test)\n",
    "\n",
    "print(\"正解\\n\", y_test)\n",
    "print()\n",
    "print(y_pred)\n",
    "print(\"R ^ 2_score(1に近いほど良い）：\", score)\n",
    "print()\n",
    "\n",
    "#X_tf tf-idfベクトルを使った予測\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tf_idf, y, train_size=0.7, test_size=0.3, random_state=0)\n",
    "\n",
    "MOR = MultiOutputRegressor(GradientBoostingRegressor(random_state=0)).fit(X_train, y_train)\n",
    "y_pred = MOR.predict(X_test)\n",
    "score = MOR.score(X_test, y_test)\n",
    "print(y_pred)\n",
    "print(\"R ^ 2_score(1に近いほど良い）：\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVRのrbf と　SVRの線形で予測\n",
    "#### 結果：予測値が全くダメ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF: RMSE（０に近いほど良い） 57.128553013108764 \n",
      "Linear: RMSE（０に近いほど良い） 12268.253334406958\n",
      "正解 [ 171.   65.   87.   91.   95.   48.   20.   18.   59.   64.  118.   76.\n",
      "   35.   52.   44.   61.   25.   65.   77.   88.  122.  160.   63.  118.\n",
      "  114.   48.  114.   40.  247.  119.   87.  124.   71.   37.   73.  128.\n",
      "  127.  180.  283.   69.  102.   38.   45.  210.  186.  156.   50.  146.\n",
      "   92.  102.   90.  197.  219.  117.  116.  179.   92.  166.  190.  100.\n",
      "  149.  174.   97.  141.  171.  205.   90.  244.   73.   83.  120.   53.\n",
      "   80.   93.  147.  100.   31.   94.   46.  162.  165.  116.  116.   93.\n",
      "   82.  126.   55.   84.  112.   40.  141.   39.   79.]\n",
      "rbf推定 [ 91.37999996  91.38000001  90.38265887  91.38000005  91.38000001\n",
      "  91.38000001  90.38915892  90.97596795  91.38000001  91.37995499\n",
      "  91.38000001  91.38019787  91.38000001  91.38000001  91.40725473\n",
      "  91.38000001  91.38000001  91.38000001  91.38000001  91.38000001\n",
      "  91.38000001  91.38000001  91.38000001  91.38000001  91.38000001\n",
      "  91.38000001  91.38000001  91.38000001  91.38000001  91.38000001\n",
      "  91.38000001  91.38000001  91.38000001  91.38000001  91.38000001\n",
      "  91.38000001  92.28279364  91.78207658  91.38000001  91.38000001\n",
      "  91.38000001  90.07494046  91.38000001  91.38000001  91.38000001\n",
      "  91.38000001  91.38000001  91.38000001  91.38000001  91.38000055\n",
      "  91.38000001  91.38000001  91.78283614  91.38000001  91.38000001\n",
      "  91.38000001  91.38000001  92.27534853  90.48245227  91.38000001\n",
      "  91.38000001  91.38029616  91.38000001  91.38000001  91.38000001\n",
      "  91.38000001  91.38000001  91.38000001  91.4614078   91.38000001\n",
      "  90.73741156  91.38000001  91.38000001  91.38000001  91.38000001\n",
      "  91.42270733  91.38000001  91.38000001  91.38000001  91.38000001\n",
      "  91.38000001  91.38000001  91.38000001  91.37999996  91.38000001\n",
      "  91.38000001  91.38000005  91.38000001  91.38000001  91.37835109\n",
      "  91.38000001  91.38000001  90.71817268]\n",
      "lin推定 [  8.40384604e+01  -5.90618235e+02  -2.58116680e+03  -6.02379412e+01\n",
      "  -1.47276291e+04   1.19685075e+02  -3.55877618e+04   1.21458935e+02\n",
      "   1.56135564e+02   1.05698308e+02  -8.26530797e+04   1.42186654e+02\n",
      "  -1.05962060e+03   1.00407959e+02   1.59824287e+02   1.64632328e+02\n",
      "  -3.67694065e+04  -2.31877102e+01  -1.88717109e+04  -3.44193834e+03\n",
      "  -1.09495531e+04  -3.18547885e+02  -1.35128463e+03   1.40570250e+02\n",
      "   3.51683901e+00  -2.80322624e+02  -1.27624147e+04  -7.91478538e+02\n",
      "  -3.97679937e+03  -2.95067154e+00  -6.06366379e+01  -4.21179964e+02\n",
      "  -4.08206463e+03  -1.26947803e+03  -1.79817928e+03  -2.82105971e+03\n",
      "   1.67322992e+02   1.28233795e+02  -1.81340146e+03  -7.25174357e+02\n",
      "   1.15898460e+02   1.51872291e+02  -2.84481329e+03  -5.36048446e+02\n",
      "  -5.90010088e+02  -1.93978781e+03  -4.63417525e+01  -4.70863820e+03\n",
      "  -2.80115209e+02   1.61277583e+02  -4.56079709e+03  -2.08441156e+03\n",
      "   1.66953691e+02  -3.05543546e+02  -3.46399075e+02  -1.17598834e+02\n",
      "  -3.81686633e+02   1.06940074e+02  -8.01263941e+01   2.47786544e+01\n",
      "  -1.77951269e+04   1.71167907e+02  -2.36603804e+02  -1.01024067e+04\n",
      "  -6.00843446e+02  -9.65152661e+01   1.39572879e+02  -1.69946419e+03\n",
      "   1.63759025e+02  -2.73768210e+01   1.66026403e+02  -4.27043330e+02\n",
      "   9.15874714e+01   1.18637411e+02  -4.24834155e+01  -4.63485067e+04\n",
      "  -9.17967700e+01  -7.52184740e+03   1.64561473e+02   6.62980820e+01\n",
      "  -1.01024661e+04  -5.59240240e+02  -2.73683797e+04  -1.01658418e+03\n",
      "  -1.47925545e+01   2.63113860e+01   1.28979842e+02   1.44972807e+02\n",
      "  -1.76870753e+03   1.53788671e+02  -2.34985248e+02   1.37011811e-01\n",
      "  -7.99922190e+01]\n"
     ]
    }
   ],
   "source": [
    "#ポジ、ネガ別々で予測する\n",
    "#SVRのrbf と　SVRの線形\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "#D2vベクトル(ポジのみ)\n",
    "X_train, X_test, y_p_train, y_p_test = train_test_split(\n",
    "    X, y_p, train_size=0.7, test_size=0.3, random_state=0)\n",
    "\n",
    "svr_rbf = SVR(kernel='rbf', C=1, gamma=0.1)\n",
    "svr_lin = SVR(kernel='linear', C=1)\n",
    "y_rbf = svr_rbf.fit(X_train, y_p_train)\n",
    "y_lin = svr_lin.fit(X_train, y_p_train)\n",
    "\n",
    "pred_rbf = svr_rbf.predict(X_test)\n",
    "pred_lin = svr_lin.predict(X_test)\n",
    "\n",
    "#精度\n",
    "\n",
    "# 相関係数計算\n",
    "rbf_corr = np.corrcoef(y_p_test, pred_rbf)[0, 1]\n",
    "lin_corr = np.corrcoef(y_p_test, pred_lin)[0, 1]\n",
    "\n",
    "# RMSEを計算（０に近いほど良い）\n",
    "rbf_rmse = sqrt(mean_squared_error(pred_rbf, y_p_test))\n",
    "lin_rmse = sqrt(mean_squared_error(pred_lin, y_p_test))\n",
    "\n",
    "print(\"RBF: RMSE（０に近いほど良い） {} \".format(rbf_rmse))\n",
    "print(\"Linear: RMSE（０に近いほど良い） {}\" .format(lin_rmse))\n",
    "print()\n",
    "print(\"正解\", y_p_test)\n",
    "print(\"rbf推定\", pred_rbf)\n",
    "print(\"lin推定\", pred_lin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightgbm\n",
    "#### 参考サイト\n",
    "\n",
    "Mercari Price Challenge -機械学習を使ったメルカリの価格予測 Ridge回帰 LightGBM\n",
    "\n",
    "http://rautaku.hatenablog.com/entry/2017/12/22/195649\n",
    "\n",
    "#### 結果：RMSEが0には程遠い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /opt/conda/lib/python3.6/site-packages (2.3.1)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from lightgbm) (0.19.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from lightgbm) (1.13.3)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from lightgbm) (0.19.1)\r\n"
     ]
    }
   ],
   "source": [
    "#必要なツールをインストール(初回のみ実行)\n",
    "! pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5000 rounds\n",
      "[500]\tvalid_0's rmse: 60.8761\n",
      "[1000]\tvalid_0's rmse: 61.0528\n",
      "[1500]\tvalid_0's rmse: 61.0861\n",
      "[2000]\tvalid_0's rmse: 61.0921\n",
      "[2500]\tvalid_0's rmse: 61.0933\n",
      "[3000]\tvalid_0's rmse: 61.0935\n",
      "[3500]\tvalid_0's rmse: 61.0936\n",
      "[4000]\tvalid_0's rmse: 61.0936\n",
      "[4500]\tvalid_0's rmse: 61.0936\n",
      "[5000]\tvalid_0's rmse: 61.0936\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's rmse: 54.7642\n",
      "RMSE（０に近いほど良い） 54.7641918682\n"
     ]
    }
   ],
   "source": [
    "#LightGBM を使った回帰予測(D2Vベクトル)\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def main():\n",
    "    #D2vベクトル(ポジのみ)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_p, train_size=0.7, test_size=0.3, random_state=0)\n",
    "\n",
    "    # データセットを生成する\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "    # LightGBM のハイパーパラメータ\n",
    "    lgbm_params = {\n",
    "        # 回帰問題\n",
    "        'objective': 'regression',\n",
    "        # RMSE (平均二乗誤差平方根) の最小化を目指す\n",
    "        'metric': 'rmse',\n",
    "    }\n",
    "\n",
    "    # 上記のパラメータでモデルを学習する\n",
    "    model = lgb.train(lgbm_params, lgb_train, \n",
    "                      valid_sets=lgb_eval, num_boost_round=8000, \n",
    "                      early_stopping_rounds=5000, verbose_eval=500)\n",
    "\n",
    "    # テストデータを予測する\n",
    "    y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "    # RMSE を計算する\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(\"RMSE（０に近いほど良い）\", rmse)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5000 rounds\n",
      "[500]\tvalid_0's rmse: 53.7358\n",
      "[1000]\tvalid_0's rmse: 53.7507\n",
      "[1500]\tvalid_0's rmse: 53.7513\n",
      "[2000]\tvalid_0's rmse: 53.751\n",
      "[2500]\tvalid_0's rmse: 53.751\n",
      "[3000]\tvalid_0's rmse: 53.7511\n",
      "[3500]\tvalid_0's rmse: 53.7511\n",
      "[4000]\tvalid_0's rmse: 53.7511\n",
      "[4500]\tvalid_0's rmse: 53.7511\n",
      "[5000]\tvalid_0's rmse: 53.7511\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's rmse: 53.5511\n",
      "RMSE（０に近いほど良い） 53.5511129593\n"
     ]
    }
   ],
   "source": [
    "#LightGBM を使った回帰予測（Tfーidfベクトル）\n",
    "\n",
    "def main():\n",
    "\n",
    "    #X_tf tf-idfベクトルを使った予測(ポジのみ)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_tf_idf, y_p, train_size=0.7, test_size=0.3, random_state=0)\n",
    "\n",
    "    # データセットを生成する\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "    # LightGBM のハイパーパラメータ\n",
    "    lgbm_params = {\n",
    "        # 回帰問題\n",
    "        'objective': 'regression',\n",
    "        # RMSE (平均二乗誤差平方根) の最小化を目指す\n",
    "        'metric': 'rmse',\n",
    "    }\n",
    "    \n",
    "    # 上記のパラメータでモデルを学習する\n",
    "    model = lgb.train(lgbm_params, lgb_train, \n",
    "                      valid_sets=lgb_eval, num_boost_round=8000, \n",
    "                      early_stopping_rounds=5000, verbose_eval=500)\n",
    "#     model = lgb.LGBMRegressor()\n",
    "#     model.fit(X_train, y_train)\n",
    "\n",
    "    # テストデータを予測する\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # RMSE を計算する\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(\"RMSE（０に近いほど良い）\",rmse)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ランダムフォレスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2(1に近いほど良い）: -0.147252936866\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#D2vベクトル\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.7, test_size=0.3, random_state=0)\n",
    "# ランダムフォレスト回帰オブジェクト生成\n",
    "rfr = RandomForestRegressor(n_estimators=100)\n",
    "# 学習の実行\n",
    "rfr.fit(X_train, y_train)\n",
    "# テストデータで予測実行\n",
    "predict_y = rfr.predict(X_test)\n",
    "# R2決定係数で評価\n",
    "r2_score = r2_score(y_test, predict_y)\n",
    "print(\"R^2(1に近いほど良い）:\", r2_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ２）ツイッターAPI制限への挑戦（データセットの拡大）\n",
    "　・古いツイートを大量取得できるパッケージを発見（通常は１週間程度しか遡れない）<br>\n",
    "#### 結果：取得データから反応ツイートの取得を試みたができなかった<br>\n",
    "\n",
    "### GetOldTweets3 0.0.11\n",
    "古いツイートをトークン申請なしで大量取得できるパッケージ<br>\n",
    "https://pypi.org/project/GetOldTweets3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#必要なツールをインストール(初回のみ実行)\n",
    "! pip install GetOldTweets3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#指定日のトップツイートを取得、'./output/toptweets.csv'に保存\n",
    "! GetOldTweets3 --lang ja  --toptweets  --querysearch \"\" --since 2019-2-10 --until 2019-2-11 --output './output/toptweets.csv'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
